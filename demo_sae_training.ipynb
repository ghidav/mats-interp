{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.lm_runner import language_model_sae_runner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"tiny-stories-1L-21M\"\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'Once', ' upon', ' a', ' time', ',', ' there', ' was', ' a', ' little', ' girl', ' named', ' Lily', '.', ' She', ' lived', ' in', ' a', ' big', ',', ' happy', ' little', ' girl', '.', ' On', ' her', ' big', ' adventure', ',']\n",
      "Tokenized answer: [' Lily']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.81</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.46</span><span style=\"font-weight: bold\">% Token: | Lily|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.81\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m13.46\u001b[0m\u001b[1m% Token: | Lily|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 20.48 Prob: 71.06% Token: | she|\n",
      "Top 1th token. Logit: 18.81 Prob: 13.46% Token: | Lily|\n",
      "Top 2th token. Logit: 17.35 Prob:  3.11% Token: | the|\n",
      "Top 3th token. Logit: 17.26 Prob:  2.86% Token: | her|\n",
      "Top 4th token. Logit: 16.74 Prob:  1.70% Token: | there|\n",
      "Top 5th token. Logit: 16.43 Prob:  1.25% Token: | they|\n",
      "Top 6th token. Logit: 15.80 Prob:  0.66% Token: | all|\n",
      "Top 7th token. Logit: 15.64 Prob:  0.56% Token: | things|\n",
      "Top 8th token. Logit: 15.28 Prob:  0.39% Token: | one|\n",
      "Top 9th token. Logit: 15.24 Prob:  0.38% Token: | lived|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Lily'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Lily'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "# Test the model with a prompt\n",
    "test_prompt(\n",
    "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\",\n",
    "    \" Lily\",\n",
    "    model,\n",
    "    prepend_space_to_answer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-484231a4-e0de\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-484231a4-e0de\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-0.020237978547811508, -6.104498863220215, -7.070311546325684, -7.073490142822266, -7.178879737854004, -7.389684677124023, -7.525315284729004, -7.588573455810547, -7.763055801391602, -8.224309921264648], [-1.1883893013000488, -3.4683852195739746, -3.4808287620544434, -3.4896111488342285, -3.500030994415283, -3.554358959197998, -4.017881870269775, -4.030544757843018, -4.298159122467041, -4.418168544769287], [-2.9201290607452393, -3.379486322402954, -3.4266788959503174, -3.531764268875122, -3.956162691116333, -4.256065368652344, -4.443942070007324, -4.4448394775390625, -4.559991836547852, -4.583307266235352], [-0.9917522668838501, -2.928676128387451, -3.2575316429138184, -3.317981243133545, -3.4740567207336426, -3.6419081687927246, -3.8674941062927246, -3.868630886077881, -3.8917040824890137, -4.005284786224365], [-0.037123147398233414, -4.683361530303955, -4.9722676277160645, -5.854288578033447, -5.9421305656433105, -6.388034343719482, -6.3940815925598145, -6.498584270477295, -6.593432903289795, -7.8692545890808105], [-0.23486259579658508, -2.3354179859161377, -2.947497606277466, -5.052804470062256, -5.078576564788818, -5.102746486663818, -5.116313457489014, -5.737276554107666, -5.768456935882568, -5.893773555755615], [-0.44884783029556274, -2.076716423034668, -3.433588981628418, -3.645073890686035, -3.7033796310424805, -4.046278953552246, -4.097006797790527, -4.209780693054199, -4.518967628479004, -4.961886405944824], [-0.4609467387199402, -2.7377679347991943, -3.158902883529663, -3.686795949935913, -4.416429042816162, -4.448527812957764, -4.571945667266846, -4.669140338897705, -4.695371150970459, -4.748204708099365], [-0.9866101741790771, -1.8349759578704834, -2.460031270980835, -2.511583089828491, -3.1156270503997803, -3.419478178024292, -3.5203635692596436, -3.8049819469451904, -4.003089904785156, -4.258264541625977], [-1.3091926574707031, -1.633901596069336, -1.78680419921875, -2.631612777709961, -3.4602813720703125, -3.615842819213867, -4.020046234130859, -4.093286514282227, -4.177457809448242, -4.309240341186523], [-1.9952350854873657, -2.55653715133667, -2.645555019378662, -2.8948235511779785, -3.11043119430542, -3.3945651054382324, -3.7311148643493652, -3.8203349113464355, -3.967912197113037, -4.026367664337158], [-1.0431095361709595, -1.959466576576233, -3.0507731437683105, -3.4215006828308105, -3.48012113571167, -3.4898486137390137, -3.6020045280456543, -4.332496166229248, -4.492417812347412, -4.517611026763916], [-1.5123934745788574, -2.020272731781006, -2.22328519821167, -2.2493205070495605, -3.376523494720459, -3.92171049118042, -3.9798388481140137, -4.199243068695068, -4.265368938446045, -4.6615891456604], [-3.188736915588379, -3.192061424255371, -3.4252281188964844, -3.494192123413086, -3.7325897216796875, -3.7353057861328125, -3.735713005065918, -3.833963394165039, -4.233694076538086, -4.265708923339844]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\",\", \" Tim\", \" bird\", \"!\", \" little\", \" Lily\", \" Tom\", \"!\\\"\", \" Max\", \" tree\"], [\" cat\", \" a\", \" bird\", \" little\", \" I\", \"\\n\", \" dog\", \" but\", \" frog\", \" sw\"], [\" are\", \" I\", \" was\", \" do\", \" fast\", \" big\", \" did\", \" to\", \" he\", \" old\"], [\" you\", \" we\", \" they\", \" the\", \" Lily\", \" your\", \" I\", \" Tim\", \" friends\", \" those\"], [\"?\\\"\", \" today\", \"?\", \" and\", \".\", \",\", \" doing\", \" going\", \" up\", \"?\\\".\"], [\"?\\\"\", \" this\", \" today\", \"?\", \" here\", \" a\", \" it\", \" these\", \".\", \" in\"], [\"?\\\"\", \"?\", \" great\", \" so\", \" job\", \" puzzle\", \" task\", \" very\", \".\", \" amazing\"], [\"\\ufffd\", \" You\", \" I\", \" It\", \" We\", \" Can\", \"\\n\", \" This\", \" Do\", \" Are\"], [\"'m\", \" am\", \" want\", \" like\", \" know\", \" have\", \" love\", \" can\", \" just\", \" hope\"], [\" a\", \" so\", \" very\", \" trying\", \" going\", \" an\", \" looking\", \" just\", \" making\", \" playing\"], [\" good\", \" hungry\", \" enjoying\", \" a\", \" tired\", \" proud\", \" happy\", \" excited\", \" busy\", \" glad\"], [\" the\", \" it\", \" this\", \" my\", \" a\", \" your\", \" playing\", \" some\", \" these\", \" myself\"], [\" meal\", \" food\", \" day\", \" ice\", \" sandwich\", \" delicious\", \" new\", \" dance\", \" cake\", \" time\"]], \"correctTokenRank\": [1718, 0, 675, 0, 0, 6, 1, 1, 2, 0, 23, 2, 5, 10036], \"correctTokenLogProb\": [-13.814948081970215, -1.1883893013000488, -8.445575714111328, -0.9917522668838501, -0.037123147398233414, -5.116313457489014, -2.076716423034668, -2.7377679347991943, -2.460031270980835, -1.3091926574707031, -4.860561847686768, -3.0507731437683105, -3.92171049118042, -17.039505004882812]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f4adab063d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
    "\n",
    "# Let's make a longer prompt and see the log probabilities of the tokens\n",
    "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")\n",
    "# hover on the output to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f788bedf15a4f09afb2385124c9fd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-52e1e87c-bc6a\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-52e1e87c-bc6a\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Once\", \" upon\", \" a\", \" time\", \" there\", \" was\", \" a\", \" spider\", \".\", \" He\", \" was\", \" walking\", \" around\", \" a\", \" room\", \" filled\", \" with\", \" junk\", \".\", \" He\", \" looked\", \" in\", \" the\", \" junk\", \" until\", \" he\", \" found\", \" something\", \" special\", \".\", \" He\", \" twisted\", \" it\", \" and\", \" made\", \" things\", \" slow\", \".\", \"\\n\", \"\\n\", \"The\", \" spider\", \" liked\", \" to\", \" sort\", \" junk\", \".\", \" He\", \" liked\", \" to\", \" sit\", \" there\", \" and\", \" sort\", \" the\", \" pieces\", \".\", \" He\", \" sorted\", \" the\", \" pieces\", \" into\", \" two\", \" into\", \" piles\", \".\", \" One\", \" pile\", \" was\", \" for\", \" most\", \" of\", \" the\", \" pieces\", \",\", \" but\", \" they\", \" were\", \" all\", \" blended\", \" together\", \".\", \"\\n\", \"\\n\", \"The\", \" finishing\", \" sorting\", \" the\", \" junk\", \" and\", \" soon\", \" it\", \" looked\", \" like\", \" a\", \" soft\", \" chair\", \".\", \" They\", \" were\", \" both\", \" so\", \" happy\", \".\", \"\\n\", \"\\n\", \"They\", \" all\", \" laughed\", \" as\", \" they\", \" sorted\", \" the\", \" rest\", \" of\", \" the\", \" junk\", \" back\", \" into\", \" the\", \" room\", \".\", \" It\", \" was\", \" slow\", \" into\", \" the\", \" organized\", \" room\", \",\", \" with\", \" plenty\", \" of\", \" clean\", \" clothes\", \",\", \" and\", \" everyone\", \" was\", \" happy\", \".\", \" It\", \" would\", \" sort\", \" them\", \" back\", \" into\", \" the\", \" box\", \" until\", \" it\", \" was\", \" complete\", \".\", \"\\n\", \"\\n\", \"The\", \" slow\", \" all\", \" of\", \" the\", \" room\", \" had\", \" a\", \" really\", \" neat\", \" space\", \" to\", \" sleep\", \".\", \" And\", \" they\", \" all\", \" lived\", \" happily\", \" ever\", \" after\", \".\", \"\\n\", \"<|endoftext|>\", \" him\", \" always\", \" played\", \" with\", \" the\", \" truck\", \" and\", \" chim\", \"neys\", \" by\", \" making\", \" them\", \" happy\", \".\", \"\\n\", \"Summary\", \":\", \" A\", \" slow\", \" and\", \" neat\", \" little\", \" circle\", \" named\"], \"topKLogProbs\": [[-0.020237978547811508, -6.104497909545898, -7.070315361022949, -7.073488235473633, -7.1788787841796875, -7.389683723449707, -7.525317192077637, -7.5885772705078125, -7.763050079345703, -8.224308967590332], [-0.372489869594574, -1.827528953552246, -4.3061370849609375, -4.838803291320801, -4.989402770996094, -5.1117401123046875, -5.187068939208984, -5.250604629516602, -5.662858963012695, -5.694143295288086], [-0.005904730875045061, -5.495633602142334, -7.522153377532959, -8.207719802856445, -8.449649810791016, -8.90707778930664, -9.541242599487305, -9.691887855529785, -10.111766815185547, -10.492300033569336], [-0.011737688444554806, -6.031045913696289, -7.209378242492676, -7.243843078613281, -7.747928619384766, -7.977005958557129, -8.321712493896484, -8.35726547241211, -8.502359390258789, -8.701475143432617], [-0.1878184974193573, -1.8141651153564453, -5.624242782592773, -6.579645156860352, -7.822257995605469, -8.386683464050293, -8.49909496307373, -8.57803726196289, -8.823796272277832, -8.960565567016602], [-0.1264190971851349, -2.645172119140625, -3.1745872497558594, -6.024099349975586, -7.541318893432617, -7.569219589233398, -8.077939987182617, -8.21709156036377, -8.48302936553955, -9.587562561035156], [-0.03639727830886841, -3.455592393875122, -7.27968168258667, -8.3013277053833, -8.35352611541748, -8.62311840057373, -9.154557228088379, -9.191892623901367, -9.372963905334473, -9.443217277526855], [-1.9747376441955566, -2.187880039215088, -2.9020028114318848, -3.7193284034729004, -4.078258037567139, -4.157901287078857, -4.167422771453857, -4.588374614715576, -4.697912693023682, -4.710133075714111], [-0.7586244344711304, -1.26846444606781, -2.390195369720459, -3.219043254852295, -3.3320822715759277, -3.6511435508728027, -3.837693691253662, -4.300088405609131, -5.247912883758545, -6.5150885581970215], [-0.4660787284374237, -2.2149152755737305, -2.2785959243774414, -2.3450002670288086, -4.081721305847168, -4.778900146484375, -5.131242752075195, -5.235945701599121, -5.277421951293945, -5.684287071228027], [-0.45198941230773926, -2.4925243854522705, -2.4966251850128174, -2.6491425037384033, -2.9339325428009033, -3.9481499195098877, -5.368659019470215, -5.832919120788574, -5.842637062072754, -5.967827796936035], [-0.7345106601715088, -1.6512548923492432, -2.8677656650543213, -3.531412363052368, -4.124162673950195, -4.287372589111328, -4.469099044799805, -4.486846923828125, -4.536376953125, -4.733287811279297], [-0.9918490648269653, -1.227620244026184, -2.261075019836426, -2.4541120529174805, -3.00791072845459, -4.3717451095581055, -4.536786079406738, -4.866276741027832, -5.113099098205566, -5.188464164733887], [-1.2764413356781006, -1.7406976222991943, -1.9239270687103271, -2.0206658840179443, -2.855365514755249, -2.9071481227874756, -3.193368673324585, -3.780423879623413, -4.051046371459961, -4.48908805847168], [-1.7163517475128174, -3.028409242630005, -3.099168062210083, -3.100966691970825, -3.239060640335083, -3.354039430618286, -3.37762188911438, -3.7571346759796143, -3.8919079303741455, -4.033038139343262], [-1.1834821701049805, -1.3256769180297852, -1.8477258682250977, -2.4209413528442383, -3.140162467956543, -3.4627199172973633, -4.159920692443848, -4.345791816711426, -4.4661760330200195, -4.805354118347168], [-0.0004503904783632606, -8.88076400756836, -9.252815246582031, -9.725547790527344, -10.459877014160156, -10.53018569946289, -10.741151809692383, -10.88709831237793, -11.372947692871094, -11.854360580444336], [-1.9460322856903076, -2.4115169048309326, -2.43994402885437, -3.402817487716675, -3.5451743602752686, -3.716933012008667, -3.8017852306365967, -3.833791494369507, -4.231011390686035, -4.260258674621582], [-0.10771898180246353, -3.3526206016540527, -3.594510555267334, -4.673869609832764, -5.612313747406006, -5.71136999130249, -5.839099407196045, -5.994603633880615, -6.580464839935303, -6.69442892074585], [-0.4609256982803345, -2.6674647331237793, -2.7231802940368652, -3.2586188316345215, -3.431933879852295, -3.856563091278076, -4.09491491317749, -4.183221340179443, -4.30014181137085, -4.456501483917236], [-1.232911229133606, -1.8937808275222778, -2.17667293548584, -2.361538887023926, -2.7878923416137695, -3.140589714050293, -3.7654428482055664, -4.133305549621582, -4.371035575866699, -4.485285758972168], [-0.9435145854949951, -1.930931806564331, -2.526867628097534, -2.7035815715789795, -3.282353162765503, -3.283005475997925, -3.4051215648651123, -3.589886426925659, -3.6664226055145264, -3.732468366622925], [-1.2032361030578613, -1.9440655708312988, -2.0320706367492676, -2.8293709754943848, -2.8828301429748535, -2.9960789680480957, -3.074514865875244, -3.5140576362609863, -4.140833377838135, -4.413968563079834], [-1.5908252000808716, -1.640767216682434, -2.4643564224243164, -2.9000425338745117, -2.9739294052124023, -3.158907890319824, -3.646122932434082, -3.770522117614746, -4.015324592590332, -4.090481758117676], [-0.7573732137680054, -2.227405071258545, -2.569568157196045, -2.745299816131592, -2.7914557456970215, -3.4810938835144043, -3.8249316215515137, -3.828273296356201, -4.071824550628662, -4.84181547164917], [-0.11450029909610748, -3.2464945316314697, -4.194759845733643, -4.258148670196533, -4.638155460357666, -4.787071704864502, -5.320206165313721, -5.379618167877197, -5.5835747718811035, -6.593653202056885], [-0.201736181974411, -1.991037130355835, -4.6167826652526855, -5.211459636688232, -5.24158239364624, -5.436156749725342, -5.7677531242370605, -5.79610013961792, -6.355733394622803, -6.439666271209717], [-0.6085736751556396, -1.2467858791351318, -2.8528249263763428, -3.9374616146087646, -4.188743591308594, -4.424552917480469, -4.597158432006836, -4.869903564453125, -5.040346145629883, -5.152210235595703], [-1.6954941749572754, -2.260714054107666, -2.3136658668518066, -2.511749744415283, -2.892012119293213, -3.0047478675842285, -3.099438190460205, -3.3263192176818848, -3.405277729034424, -3.7383713722229004], [-0.29978570342063904, -2.2666683197021484, -3.5971298217773438, -3.873004913330078, -3.9359703063964844, -4.0702972412109375, -4.14332389831543, -4.67607307434082, -4.725215911865234, -5.345605850219727], [-0.47300946712493896, -1.8919280767440796, -2.580811023712158, -3.4927258491516113, -3.5696301460266113, -3.6821179389953613, -4.224514484405518, -5.017174243927002, -5.082836627960205, -5.477535724639893], [-2.242152452468872, -2.243708848953247, -2.4093754291534424, -2.6723625659942627, -3.0166313648223877, -3.1129982471466064, -3.182257890701294, -3.2592194080352783, -3.4990341663360596, -3.602973222732544], [-0.5307212471961975, -1.800534725189209, -2.2667174339294434, -3.318755626678467, -3.5555548667907715, -3.6026816368103027, -4.098805904388428, -6.147458553314209, -6.161387920379639, -6.319016933441162], [-1.274881362915039, -1.5943183898925781, -2.0426673889160156, -2.458669662475586, -2.927532196044922, -3.615671157836914, -3.7297935485839844, -4.053905487060547, -4.060312271118164, -4.189733505249023], [-2.0947515964508057, -2.280853509902954, -2.522594690322876, -2.824232339859009, -3.1732447147369385, -3.218517541885376, -3.227602243423462, -3.5086348056793213, -3.5515024662017822, -3.643036127090454], [-0.6834957599639893, -1.6434013843536377, -2.5832302570343018, -2.99993634223938, -3.640631914138794, -3.7260258197784424, -4.066159248352051, -4.2944231033325195, -4.407708168029785, -4.996977806091309], [-1.068657398223877, -2.327850818634033, -2.860081195831299, -2.981323719024658, -3.0579724311828613, -3.1614537239074707, -3.361238956451416, -3.3947949409484863, -4.06017541885376, -4.2652459144592285], [-0.5955834984779358, -1.805473804473877, -1.8772892951965332, -3.8389973640441895, -4.124748706817627, -4.245871067047119, -4.687920093536377, -4.876356601715088, -5.000824451446533, -5.205310344696045], [-0.9311010241508484, -1.743154764175415, -2.2934553623199463, -2.39699387550354, -2.7292158603668213, -2.9120333194732666, -4.096284866333008, -4.122966766357422, -4.422369003295898, -4.901161193847656], [-0.03866378962993622, -4.021915435791016, -5.098794937133789, -6.029912948608398, -6.8840179443359375, -6.96173095703125, -6.966239929199219, -6.9822893142700195, -7.049455642700195, -7.323245048522949], [-0.5724437236785889, -1.7974460124969482, -3.2936885356903076, -3.3090693950653076, -3.348658323287964, -3.5956523418426514, -4.142022132873535, -4.285662651062012, -4.558588027954102, -4.991050720214844], [-0.43097275495529175, -3.353231191635132, -3.3893239498138428, -3.6484391689300537, -3.677701711654663, -3.8064534664154053, -3.951873540878296, -4.507903575897217, -4.521569728851318, -4.596717357635498], [-0.9357486367225647, -3.072598934173584, -3.3073973655700684, -3.5338683128356934, -3.58906888961792, -3.615905284881592, -3.7535529136657715, -3.8459525108337402, -3.937591075897217, -4.016770839691162], [-0.9496457576751709, -1.0313775539398193, -2.5366952419281006, -3.6231000423431396, -4.135053634643555, -4.371538162231445, -4.464853286743164, -4.534177780151367, -4.861804962158203, -5.000082015991211], [-2.4693524837493896, -2.4696271419525146, -2.7138783931732178, -2.9293057918548584, -3.1644818782806396, -3.2143476009368896, -3.217761754989624, -3.344625234603882, -3.4814889430999756, -3.5332391262054443], [-0.6352620124816895, -1.5421242713928223, -3.1652188301086426, -3.2522835731506348, -3.4591546058654785, -3.8675789833068848, -4.078880786895752, -4.134256839752197, -5.028637409210205, -5.1598896980285645], [-0.49126970767974854, -2.8880019187927246, -3.1876063346862793, -3.3880362510681152, -3.5691123008728027, -3.774453639984131, -3.9069838523864746, -4.323056697845459, -4.3560004234313965, -4.641788005828857], [-0.18188579380512238, -2.14322566986084, -4.768258094787598, -5.256833076477051, -5.5856523513793945, -5.622570037841797, -5.8085432052612305, -6.182488441467285, -6.251117706298828, -6.392146110534668], [-1.8848991394042969, -1.9025592803955078, -2.2515792846679688, -2.2652530670166016, -3.2152633666992188, -3.563323974609375, -3.6293163299560547, -3.650604248046875, -3.7303504943847656, -3.781656265258789], [-0.8335361480712891, -1.6585750579833984, -2.054872512817383, -3.2020092010498047, -3.4994277954101562, -4.110202789306641, -4.500486373901367, -4.615697860717773, -4.682697296142578, -4.779567718505859], [-1.6465157270431519, -1.7093247175216675, -2.408064842224121, -2.4457216262817383, -2.570418357849121, -3.130833625793457, -3.35910701751709, -3.995358467102051, -4.054015159606934, -4.268790245056152], [-1.0440216064453125, -1.1884193420410156, -1.811422348022461, -3.0390396118164062, -3.896991729736328, -4.189140319824219, -4.314661026000977, -4.602756500244141, -4.628839492797852, -4.782508850097656], [-0.32031911611557007, -2.765231132507324, -3.1656675338745117, -3.51900577545166, -3.919642448425293, -3.9704065322875977, -4.075278282165527, -4.21059513092041, -4.588995933532715, -4.738570213317871], [-0.5803281664848328, -2.4826548099517822, -2.8393328189849854, -2.8580191135406494, -4.038272857666016, -4.040321350097656, -4.303960800170898, -4.433465957641602, -4.459627151489258, -4.658674240112305], [-0.6470537781715393, -2.134364128112793, -2.6647520065307617, -3.1664342880249023, -3.174197196960449, -3.629794120788574, -4.402125358581543, -4.464753150939941, -4.597878456115723, -4.726447105407715], [-0.7142124772071838, -1.8221473693847656, -3.0411720275878906, -3.1755714416503906, -3.507244110107422, -3.635265350341797, -3.6383895874023438, -4.117767333984375, -4.559561729431152, -4.899532318115234], [-0.782444417476654, -1.4452977180480957, -3.437490940093994, -3.652834415435791, -3.6605610847473145, -3.7038216590881348, -3.745169162750244, -3.864635944366455, -3.878950595855713, -4.0339035987854], [-0.3114766478538513, -2.5330018997192383, -3.3751001358032227, -3.4793272018432617, -3.62978458404541, -3.8605737686157227, -4.506922721862793, -4.896285057067871, -5.254350662231445, -5.4001874923706055], [-1.5387799739837646, -1.969999074935913, -2.348846197128296, -2.40854811668396, -2.8312489986419678, -3.1335065364837646, -3.1842000484466553, -3.2620198726654053, -3.7803685665130615, -3.787893056869507], [-0.782846212387085, -2.339586019515991, -2.393064260482788, -2.624166250228882, -3.3630616664886475, -3.426725149154663, -3.9544484615325928, -4.54095458984375, -4.599390029907227, -4.642538070678711], [-1.4243627786636353, -2.6613125801086426, -2.6939892768859863, -2.79075288772583, -2.863720417022705, -3.4962315559387207, -3.5098977088928223, -3.782982349395752, -3.9340291023254395, -4.154804706573486], [-1.2258808612823486, -1.8922321796417236, -2.159764528274536, -2.1955196857452393, -2.272235155105591, -3.535578966140747, -3.7134029865264893, -3.9615395069122314, -3.990149736404419, -4.245285987854004], [-1.1254186630249023, -1.8033723831176758, -2.15908145904541, -2.51674747467041, -2.8250608444213867, -3.0060930252075195, -3.3119077682495117, -3.41835880279541, -4.357325553894043, -4.914328575134277], [-0.12261990457773209, -3.344177484512329, -3.909219980239868, -4.723209857940674, -4.740173816680908, -5.102135181427002, -5.477623462677002, -5.537933826446533, -6.028250217437744, -6.168945789337158], [-0.570478618144989, -2.3801958560943604, -2.7066214084625244, -2.823183298110962, -3.2640745639801025, -3.3201982975006104, -3.6104013919830322, -3.987205743789673, -4.966428756713867, -4.975250244140625], [-0.21563000977039337, -2.3617711067199707, -3.119694232940674, -4.3975911140441895, -4.7734150886535645, -4.795956134796143, -5.192764759063721, -5.8423542976379395, -5.865114688873291, -6.185911655426025], [-0.6500698328018188, -1.4745231866836548, -2.3653616905212402, -3.0275473594665527, -3.245063304901123, -4.614879131317139, -4.976603984832764, -5.11249303817749, -5.316869258880615, -5.325681209564209], [-0.15613678097724915, -2.874770402908325, -3.330085039138794, -4.64375638961792, -5.701911449432373, -5.733388423919678, -5.98706579208374, -6.2641825675964355, -6.342139720916748, -6.371951580047607], [-0.20562273263931274, -3.361697196960449, -3.5208845138549805, -4.042965888977051, -4.287407875061035, -4.688412666320801, -4.742781639099121, -5.303084373474121, -5.342041969299316, -5.430293083190918], [-0.655595600605011, -2.5936009883880615, -3.036578893661499, -3.432685613632202, -3.6498963832855225, -3.789581060409546, -4.3899688720703125, -4.489762306213379, -4.510251998901367, -4.520327568054199], [-1.4555418491363525, -1.9998266696929932, -2.962139368057251, -3.5547735691070557, -3.5679447650909424, -3.7380754947662354, -3.818396806716919, -3.9249956607818604, -3.955240488052368, -4.009503364562988], [-0.12847380340099335, -3.72715425491333, -4.690124988555908, -4.795675754547119, -4.957061290740967, -5.1756978034973145, -5.973581790924072, -6.201857089996338, -6.461302280426025, -6.5097432136535645], [-1.0573594570159912, -1.4621217250823975, -2.0168683528900146, -2.136932134628296, -4.061605453491211, -4.235626220703125, -4.678764343261719, -4.720481872558594, -4.793169021606445, -4.807212829589844], [-0.5258836150169373, -1.8715200424194336, -3.6398515701293945, -3.672238349914551, -4.416860580444336, -4.777207374572754, -4.814068794250488, -4.860919952392578, -4.868714332580566, -5.145398139953613], [-0.8594402074813843, -1.979488730430603, -2.230469226837158, -2.5824971199035645, -2.773315906524658, -3.0553479194641113, -3.2310967445373535, -3.7666993141174316, -4.620426654815674, -4.654819965362549], [-1.500698208808899, -1.6482774019241333, -1.7808362245559692, -2.0567665100097656, -2.9010467529296875, -3.1575260162353516, -3.3298683166503906, -3.492795944213867, -3.998523712158203, -4.180652618408203], [-1.2152063846588135, -1.2267076969146729, -2.431619882583618, -2.741760492324829, -2.9079878330230713, -3.4196207523345947, -4.189538955688477, -4.3297576904296875, -4.515722274780273, -4.591217041015625], [-0.849854052066803, -1.3907475471496582, -3.133955478668213, -3.241692066192627, -3.7641091346740723, -3.9976162910461426, -4.184763431549072, -4.187624454498291, -4.23093843460083, -4.424013614654541], [-1.3299978971481323, -1.657718539237976, -2.453094482421875, -2.821369171142578, -2.8518123626708984, -3.013113021850586, -3.379650115966797, -3.9113998413085938, -4.591862678527832, -4.683681488037109], [-0.6054354310035706, -2.5872621536254883, -3.4764509201049805, -3.527390480041504, -3.7318735122680664, -3.977585792541504, -4.009612083435059, -4.2464189529418945, -4.297215461730957, -4.418768882751465], [-0.3024566173553467, -2.715183973312378, -3.0723235607147217, -3.183995008468628, -3.3102195262908936, -4.3131818771362305, -4.772168159484863, -4.998579978942871, -5.043766975402832, -5.654562950134277], [-0.4709051847457886, -1.8362711668014526, -3.065601348876953, -3.893495559692383, -3.962902069091797, -4.034795761108398, -4.052011489868164, -4.0797576904296875, -4.440252304077148, -4.48725700378418], [-1.0554325580596924, -1.6851913928985596, -1.7411987781524658, -1.8436424732208252, -3.528582811355591, -4.077834129333496, -4.699028015136719, -4.803894996643066, -4.994866371154785, -5.068514823913574], [-0.010174315422773361, -5.455196857452393, -5.716516971588135, -7.284708499908447, -8.469237327575684, -9.132493019104004, -9.186749458312988, -9.198753356933594, -9.304278373718262, -9.316041946411133], [-0.32709017395973206, -2.7468042373657227, -3.1255483627319336, -3.6804399490356445, -3.9940290451049805, -4.1617326736450195, -4.325743675231934, -4.734047889709473, -4.881260871887207, -4.937150001525879], [-0.5593985915184021, -2.629100799560547, -3.621997833251953, -3.961920738220215, -4.017690658569336, -4.250523567199707, -4.387651443481445, -4.401155471801758, -4.423235893249512, -4.797849655151367], [-0.8818385601043701, -1.8415019512176514, -1.913771390914917, -3.0971343517303467, -3.420544385910034, -3.9839532375335693, -4.618077278137207, -4.651125907897949, -4.964594841003418, -5.203094482421875], [-1.0852166414260864, -1.3865453004837036, -2.7891178131103516, -3.0657596588134766, -3.4644298553466797, -3.5614452362060547, -3.657094955444336, -3.807371139526367, -3.9503917694091797, -4.411800384521484], [-0.827427864074707, -0.9601659774780273, -3.341843605041504, -3.6185121536254883, -4.065487861633301, -4.975527763366699, -5.061715126037598, -5.223860740661621, -5.3478546142578125, -5.692278861999512], [-1.446197271347046, -2.0438973903656006, -2.756274938583374, -2.7947938442230225, -2.8916738033294678, -2.9102113246917725, -2.9244325160980225, -3.044738531112671, -3.469712972640991, -3.8899552822113037], [-0.4252226948738098, -2.6832258701324463, -3.686372995376587, -3.7462503910064697, -3.960390329360962, -4.183899402618408, -4.355861186981201, -4.4999260902404785, -4.85048246383667, -4.886314868927002], [-0.8111516833305359, -2.1035826206207275, -2.7859747409820557, -2.8038713932037354, -3.0588324069976807, -3.0941755771636963, -3.5164988040924072, -3.5726606845855713, -3.7950384616851807, -4.277276992797852], [-0.23560383915901184, -2.7563252449035645, -3.487133502960205, -3.6118245124816895, -3.677206516265869, -4.3597588539123535, -5.063221454620361, -5.29020357131958, -5.9177632331848145, -5.929758548736572], [-0.9488503336906433, -2.3010365962982178, -2.6723477840423584, -3.20377516746521, -3.30423903465271, -3.421344518661499, -3.446927785873413, -3.7610414028167725, -3.9291951656341553, -3.9316117763519287], [-0.6007412672042847, -1.760334849357605, -2.733757972717285, -3.0894556045532227, -3.397059440612793, -3.890986442565918, -4.346501350402832, -4.701512336730957, -4.813841819763184, -5.178643226623535], [-2.5581257343292236, -3.007972002029419, -3.1642467975616455, -3.3278648853302, -3.385786294937134, -3.3887503147125244, -3.6081860065460205, -3.653336763381958, -3.6846163272857666, -3.788940668106079], [-1.0771520137786865, -2.2495877742767334, -2.555083990097046, -2.6864430904388428, -3.084022283554077, -3.3284966945648193, -3.363952398300171, -3.9571340084075928, -4.200963020324707, -4.219753265380859], [-0.10170501470565796, -3.679622173309326, -3.8428263664245605, -4.141343593597412, -5.109914302825928, -5.116368770599365, -5.565465450286865, -5.877635478973389, -5.95454740524292, -6.6282477378845215], [-0.6361016631126404, -2.0634374618530273, -2.2341928482055664, -3.003424644470215, -3.5511274337768555, -3.6034231185913086, -4.118346214294434, -4.489731788635254, -4.844149589538574, -4.848526954650879], [-0.9419487714767456, -1.884337306022644, -2.357560157775879, -3.486660957336426, -3.499955177307129, -3.542038917541504, -4.12215518951416, -4.272015571594238, -4.282788276672363, -4.315560340881348], [-0.833315908908844, -1.2579584121704102, -2.5551671981811523, -3.6419477462768555, -3.980116844177246, -4.353732109069824, -4.405303001403809, -4.803292274475098, -5.063229560852051, -5.337943077087402], [-0.8654143810272217, -1.6230475902557373, -2.4079749584198, -2.9580485820770264, -3.2135226726531982, -4.069060325622559, -4.6213579177856445, -4.742510795593262, -4.797989845275879, -5.014334678649902], [-0.8675547242164612, -1.3309125900268555, -2.0205907821655273, -3.355149269104004, -3.5470151901245117, -4.649008750915527, -4.717623710632324, -4.732705116271973, -4.980111122131348, -5.2496538162231445], [-1.5347001552581787, -1.563567876815796, -1.750476598739624, -2.0305001735687256, -2.271148443222046, -2.475421667098999, -3.560434103012085, -3.7030084133148193, -5.028776168823242, -5.165227890014648], [-0.6970078349113464, -1.7072370052337646, -1.950326681137085, -2.9310758113861084, -3.757953405380249, -3.8115193843841553, -4.159398555755615, -4.746877193450928, -4.760190486907959, -5.219987392425537], [-0.03742186352610588, -4.305934429168701, -5.037238597869873, -5.54622220993042, -5.711963176727295, -6.093726634979248, -6.679194927215576, -6.968835353851318, -7.383838176727295, -7.8680853843688965], [-0.5237892866134644, -2.4051122665405273, -2.4235429763793945, -3.1208791732788086, -3.6163110733032227, -3.991549491882324, -4.1717939376831055, -4.183836936950684, -4.252875328063965, -4.582341194152832], [-1.9532699584960938, -2.3177223205566406, -2.5335311889648438, -2.624002456665039, -2.6670379638671875, -3.2210044860839844, -3.261167526245117, -3.278909683227539, -3.4652576446533203, -3.497060775756836], [-1.2806642055511475, -2.164214849472046, -2.7283742427825928, -2.8842275142669678, -3.0920121669769287, -3.2588555812835693, -3.365365743637085, -3.544908285140991, -3.682492971420288, -3.7144429683685303], [-0.1760004609823227, -2.9844415187835693, -3.5375802516937256, -3.776262044906616, -3.9981935024261475, -4.602800369262695, -4.808908462524414, -5.401514053344727, -5.415399551391602, -6.049806594848633], [-0.15745578706264496, -2.0027658939361572, -5.441956043243408, -6.754589557647705, -7.479969501495361, -7.671387195587158, -7.8017659187316895, -8.007423400878906, -8.090444564819336, -8.409492492675781], [-1.140855073928833, -1.9862244129180908, -3.1551029682159424, -3.385188341140747, -3.5877087116241455, -3.6351406574249268, -3.6748039722442627, -3.8705780506134033, -3.9106857776641846, -3.9637444019317627], [-0.22303339838981628, -3.0873351097106934, -3.9341883659362793, -4.013881206512451, -4.3182597160339355, -4.404643535614014, -4.479945659637451, -4.608375072479248, -4.609189510345459, -4.624701976776123], [-0.595439612865448, -1.0846383571624756, -3.9593541622161865, -4.3437018394470215, -5.079135417938232, -5.391104221343994, -5.476014614105225, -5.583083629608154, -5.607390880584717, -5.9217000007629395], [-0.039599210023880005, -4.759308815002441, -5.6090593338012695, -5.655495643615723, -6.22946834564209, -6.376365661621094, -6.387084007263184, -6.4675493240356445, -6.558198928833008, -7.116313934326172], [-0.07649119943380356, -2.8088767528533936, -4.876303672790527, -6.842316627502441, -7.461092948913574, -7.493584632873535, -7.554814338684082, -8.303929328918457, -8.31019115447998, -8.420816421508789], [-0.2642212510108948, -2.287137985229492, -3.887693405151367, -4.305654525756836, -4.480884552001953, -4.893165588378906, -5.377313613891602, -5.500247955322266, -5.5776567459106445, -5.679662704467773], [-0.6162712574005127, -2.0369560718536377, -2.198014497756958, -3.190039873123169, -3.2023746967315674, -4.1477556228637695, -4.299847602844238, -4.343939781188965, -4.498215675354004, -4.63149356842041], [-0.8072007894515991, -1.1995958089828491, -2.444941997528076, -2.557746410369873, -3.4661478996276855, -4.055373668670654, -4.751632213592529, -4.8445143699646, -5.398915767669678, -5.573670864105225], [-1.251315712928772, -1.3312965631484985, -2.881091594696045, -2.885913372039795, -3.0963339805603027, -3.145820140838623, -3.6308531761169434, -3.8169474601745605, -3.825639247894287, -4.015115261077881], [-1.2452659606933594, -2.0008277893066406, -2.1845436096191406, -3.197805404663086, -3.9670276641845703, -4.025581359863281, -4.1551513671875, -4.351055145263672, -4.425878524780273, -4.485324859619141], [-0.05521513894200325, -3.505530595779419, -4.4869818687438965, -6.17988920211792, -6.415524959564209, -6.741382122039795, -6.872823238372803, -7.119658946990967, -7.248612880706787, -7.392798900604248], [-0.9638047218322754, -1.8959832191467285, -2.0098347663879395, -2.723534107208252, -2.8915181159973145, -3.0648083686828613, -3.5940423011779785, -3.984632968902588, -4.317099094390869, -4.3828301429748535], [-0.08196064829826355, -4.201423645019531, -4.278446197509766, -4.807193756103516, -4.926309585571289, -5.0081024169921875, -5.587053298950195, -5.607856750488281, -5.964365005493164, -6.358406066894531], [-1.430243968963623, -1.9422926902770996, -2.3814024925231934, -2.7157111167907715, -3.206042766571045, -3.6723361015319824, -3.8313708305358887, -3.8765101432800293, -4.023900508880615, -4.054467678070068], [-1.0042181015014648, -1.8478994369506836, -1.935856819152832, -2.395857810974121, -2.5508317947387695, -4.010575294494629, -4.092883110046387, -4.175789833068848, -4.213690757751465, -4.698088645935059], [-0.6625797748565674, -2.6769649982452393, -3.006535768508911, -3.0220253467559814, -3.092463731765747, -3.2022812366485596, -3.2882511615753174, -4.116515159606934, -4.126570701599121, -4.177669525146484], [-1.7280833721160889, -2.0345332622528076, -3.012990713119507, -3.0192229747772217, -3.0378921031951904, -3.1710097789764404, -3.70517897605896, -3.8250739574432373, -4.005156517028809, -4.121149063110352], [-1.5550811290740967, -1.8572680950164795, -1.9707915782928467, -2.2014529705047607, -3.3364932537078857, -3.545252561569214, -3.6028430461883545, -3.666496992111206, -3.7435967922210693, -4.085556983947754], [-0.9011191129684448, -1.6193064451217651, -1.7239550352096558, -2.7421302795410156, -3.998319625854492, -4.3865509033203125, -4.549520492553711, -4.587421417236328, -4.958257675170898, -5.19795036315918], [-1.0010614395141602, -2.0109148025512695, -2.6809396743774414, -3.305495262145996, -3.3199243545532227, -3.868435859680176, -4.013791084289551, -4.231315612792969, -4.253802299499512, -4.427040100097656], [-1.3229587078094482, -1.6000087261199951, -2.2567718029022217, -2.7688491344451904, -3.45051646232605, -3.6220710277557373, -3.801243543624878, -4.305453300476074, -4.3986005783081055, -4.399232864379883], [-0.00549010606482625, -6.317204475402832, -7.288287162780762, -7.549118995666504, -8.01862621307373, -8.4180326461792, -9.216572761535645, -9.316540718078613, -9.321256637573242, -9.525583267211914], [-2.0420706272125244, -2.222910165786743, -2.554870843887329, -2.718313455581665, -2.9658634662628174, -3.0400707721710205, -3.221834421157837, -3.327066659927368, -3.7013466358184814, -3.8804638385772705], [-2.189513683319092, -2.2404913902282715, -2.2822623252868652, -2.4475436210632324, -2.7800726890563965, -2.836850643157959, -3.685319423675537, -3.7545809745788574, -3.8218626976013184, -3.916532039642334], [-0.97615647315979, -1.5555517673492432, -1.6227877140045166, -2.973076105117798, -2.9771502017974854, -3.8388426303863525, -4.139097213745117, -4.455348968505859, -4.787355422973633, -5.055047988891602], [-0.09975278377532959, -4.303038120269775, -4.73810338973999, -5.33581018447876, -5.359869480133057, -5.498288631439209, -6.66531229019165, -6.70690393447876, -6.728174686431885, -6.7446417808532715], [-1.9361764192581177, -2.0443172454833984, -3.079237937927246, -3.3759946823120117, -3.4071435928344727, -3.775236129760742, -3.791637420654297, -3.848905563354492, -4.056096076965332, -4.157917022705078], [-0.8961080312728882, -1.8488363027572632, -2.2981162071228027, -2.384042263031006, -3.086577892303467, -3.839942455291748, -4.017472743988037, -4.0320868492126465, -4.056491374969482, -4.330857753753662], [-0.585811972618103, -1.8040584325790405, -2.760735034942627, -3.4288887977600098, -3.8036980628967285, -4.545301914215088, -4.6124043464660645, -4.669256687164307, -4.680698871612549, -4.751720905303955], [-0.22058653831481934, -2.5621984004974365, -2.872007131576538, -3.7604939937591553, -4.289951324462891, -5.208578109741211, -5.387563705444336, -5.80859375, -5.817144393920898, -6.64763069152832], [-0.4972251355648041, -1.6521152257919312, -2.5977747440338135, -3.0311129093170166, -4.484898090362549, -4.5408101081848145, -4.6047139167785645, -4.625484943389893, -4.923006534576416, -5.720226764678955], [-0.49559077620506287, -1.7687078714370728, -3.8507542610168457, -4.396620273590088, -4.66143274307251, -4.741535663604736, -4.883690357208252, -4.920642375946045, -5.035902500152588, -5.063978672027588], [-1.8951056003570557, -2.3488142490386963, -2.4325220584869385, -2.6009409427642822, -2.822553873062134, -3.058077096939087, -3.357034921646118, -3.4181482791900635, -3.7318003177642822, -3.896250009536743], [-0.8945516347885132, -2.7019896507263184, -2.721108913421631, -3.123134136199951, -3.3570914268493652, -3.4708781242370605, -3.6581740379333496, -3.830958843231201, -3.998971462249756, -4.035985469818115], [-1.6914972066879272, -2.0762248039245605, -2.086740016937256, -2.245818614959717, -2.6602206230163574, -3.0233054161071777, -3.6579928398132324, -3.869851589202881, -3.9677844047546387, -4.063497066497803], [-0.44924065470695496, -2.6737680435180664, -2.8284597396850586, -2.867537498474121, -3.2199583053588867, -3.7311315536499023, -4.450644493103027, -4.71640682220459, -4.869519233703613, -4.877806663513184], [-0.8413788080215454, -1.9444881677627563, -2.5688300132751465, -3.1668105125427246, -3.4283671379089355, -3.665565013885498, -3.9570822715759277, -3.984494686126709, -4.0779643058776855, -4.155885219573975], [-1.4556021690368652, -2.2714762687683105, -2.362283229827881, -2.709092617034912, -2.778695583343506, -3.0957865715026855, -3.1053404808044434, -3.9748988151550293, -4.016513347625732, -4.112964153289795], [-0.6481733322143555, -2.01511287689209, -2.582228660583496, -2.938693046569824, -3.2649412155151367, -4.097519874572754, -4.129607200622559, -4.179995536804199, -4.507414817810059, -4.614991188049316], [-1.1556315422058105, -1.2156481742858887, -1.867743968963623, -3.0759196281433105, -3.4868884086608887, -3.8209662437438965, -4.114680767059326, -4.276937007904053, -4.4411139488220215, -4.887624263763428], [-0.035400524735450745, -4.439023971557617, -5.577425003051758, -5.906843185424805, -6.285999298095703, -6.287355422973633, -6.474281311035156, -6.58885383605957, -7.078563690185547, -7.138481140136719], [-1.617669701576233, -2.296384334564209, -2.388514995574951, -2.4130988121032715, -2.5439352989196777, -2.839747905731201, -3.058040142059326, -3.537950038909912, -3.6580214500427246, -4.064004421234131], [-0.18858753144741058, -2.994547128677368, -3.1590769290924072, -3.1985952854156494, -4.404860019683838, -5.405409336090088, -5.5273213386535645, -5.9114251136779785, -6.1630635261535645, -6.270044803619385], [-0.17246674001216888, -2.2433133125305176, -4.30071496963501, -4.358871936798096, -4.915041446685791, -5.426397800445557, -5.783308506011963, -5.9648919105529785, -6.594923496246338, -6.796768665313721], [-0.9581502676010132, -1.0814508199691772, -1.2938379049301147, -6.236751079559326, -7.349776744842529, -9.941277503967285, -9.951763153076172, -10.356420516967773, -10.397640228271484, -10.51446533203125], [-0.22755968570709229, -3.08943510055542, -3.4486308097839355, -3.6904139518737793, -4.350924968719482, -4.762969493865967, -4.804656505584717, -4.933658123016357, -5.030837535858154, -5.110015392303467], [-0.7238706350326538, -1.771375060081482, -2.440478801727295, -3.16347074508667, -3.336757183074951, -4.019174098968506, -4.392858028411865, -4.4541916847229, -4.518796443939209, -4.759829044342041], [-1.293716311454773, -2.162466049194336, -2.174325942993164, -2.785268783569336, -3.604978561401367, -3.654285430908203, -3.723285675048828, -3.8848323822021484, -3.896817207336426, -4.316555976867676], [-1.5065253973007202, -1.5596259832382202, -1.5922645330429077, -2.522472858428955, -2.5448670387268066, -3.767916202545166, -3.854830265045166, -3.9166407585144043, -4.224215030670166, -4.256690502166748], [-0.04625729098916054, -4.274925708770752, -4.879955768585205, -5.462500095367432, -5.536526203155518, -5.549591541290283, -6.851017475128174, -7.136401653289795, -7.3355631828308105, -7.375492572784424], [-1.0375906229019165, -2.507843494415283, -3.081291675567627, -3.2457032203674316, -3.4243807792663574, -3.4870705604553223, -3.653109073638916, -3.793017864227295, -4.028090953826904, -4.177260875701904], [-0.5705754160881042, -2.308397054672241, -2.8435304164886475, -2.9831254482269287, -4.250707149505615, -4.639197826385498, -4.7776312828063965, -4.8161845207214355, -4.877395153045654, -4.911942958831787], [-1.3863743543624878, -1.7360695600509644, -1.835835337638855, -2.3570146560668945, -3.1713647842407227, -3.5778398513793945, -4.05135440826416, -4.143620491027832, -4.595599174499512, -4.703303337097168], [-1.373749017715454, -2.2509844303131104, -2.349531412124634, -2.5509588718414307, -2.587829828262329, -3.288259744644165, -3.336221933364868, -3.447937250137329, -3.7494184970855713, -4.069387435913086], [-1.566068410873413, -1.7916638851165771, -1.8762147426605225, -2.3924310207366943, -2.505574941635132, -2.79013991355896, -3.280473470687866, -3.830991506576538, -3.9393022060394287, -4.1910400390625], [-0.9888092875480652, -1.402414083480835, -2.9784066677093506, -3.100118398666382, -3.7206132411956787, -3.871175527572632, -4.085200786590576, -4.196155071258545, -4.533019542694092, -4.770186901092529], [-1.13639235496521, -1.4325730800628662, -2.3566815853118896, -2.4291207790374756, -2.969590902328491, -3.332366704940796, -3.492013692855835, -4.029882431030273, -4.151882171630859, -4.320981979370117], [-2.3077821731567383, -2.4290285110473633, -2.782048225402832, -2.892136573791504, -2.924405097961426, -3.112307548522949, -3.2512426376342773, -3.363314628601074, -3.436077117919922, -3.4619674682617188], [-0.4920291304588318, -2.024690628051758, -2.6776866912841797, -2.7924327850341797, -3.5056724548339844, -3.5659332275390625, -4.358697891235352, -4.881866455078125, -5.295969009399414, -5.331159591674805], [-1.2425388097763062, -2.272676944732666, -2.4268136024475098, -2.4347004890441895, -2.71036958694458, -3.180626392364502, -3.3274712562561035, -3.332136631011963, -3.5968270301818848, -3.6858582496643066], [-2.0533509254455566, -2.1139492988586426, -2.238996982574463, -2.283539295196533, -2.3431992530822754, -2.779257297515869, -2.8822312355041504, -3.4386258125305176, -3.4622368812561035, -3.5548272132873535], [-0.47193631529808044, -2.092257499694824, -2.8229780197143555, -2.8755388259887695, -3.139693260192871, -4.635710716247559, -4.82974910736084, -4.944108009338379, -4.992344856262207, -5.440817832946777], [-0.14269927144050598, -3.154191017150879, -4.279221534729004, -4.76778507232666, -5.201611518859863, -5.209322929382324, -5.6631879806518555, -5.760859489440918, -5.772459983825684, -5.791775703430176], [-0.00815656129270792, -6.158596992492676, -6.776188850402832, -7.149710655212402, -7.220009803771973, -7.513840675354004, -7.961094856262207, -8.157120704650879, -8.210515022277832, -9.045172691345215], [-0.025035038590431213, -4.373446464538574, -5.047564506530762, -6.727477073669434, -6.832606315612793, -7.102675437927246, -8.022212028503418, -8.137343406677246, -8.454867362976074, -8.477961540222168], [-0.0005930095794610679, -8.843927383422852, -9.228729248046875, -10.118206024169922, -10.398306846618652, -10.767189025878906, -11.015617370605469, -11.185441970825195, -11.268600463867188, -11.33733081817627], [-0.26140275597572327, -1.8168436288833618, -3.536616086959839, -3.791292905807495, -5.697935581207275, -5.714958667755127, -6.807859897613525, -6.85734224319458, -6.951633930206299, -8.016900062561035], [-0.021868286654353142, -4.126526355743408, -6.18467378616333, -6.577676296234131, -8.09056568145752, -8.592785835266113, -9.109074592590332, -9.295903205871582, -9.521232604980469, -9.634790420532227], [-0.30139362812042236, -1.351833462715149, -6.731637954711914, -8.630481719970703, -10.888561248779297, -10.944355010986328, -11.566093444824219, -12.037769317626953, -12.538137435913086, -12.961289405822754], [-1.7881377516459906e-06, -14.364757537841797, -15.52951717376709, -15.666141510009766, -15.679590225219727, -16.38982582092285, -16.488739013671875, -16.871431350708008, -16.976917266845703, -17.009119033813477], [-2.3224666118621826, -3.3944127559661865, -3.5956246852874756, -3.797154188156128, -3.8768813610076904, -3.8978583812713623, -3.928795576095581, -4.045086860656738, -4.163166046142578, -4.212312698364258], [-2.545231342315674, -2.5533413887023926, -2.5728535652160645, -2.757559299468994, -3.1844210624694824, -3.237239360809326, -3.3407254219055176, -3.53037691116333, -3.5586905479431152, -3.5639185905456543], [-0.9088610410690308, -2.0517406463623047, -2.2086029052734375, -2.811960220336914, -3.1872711181640625, -3.578279495239258, -3.9985408782958984, -4.034473419189453, -4.140157699584961, -4.331024169921875], [-0.7093198299407959, -1.3315141201019287, -2.336503744125366, -2.630258321762085, -4.395963668823242, -4.806282043457031, -5.394186019897461, -5.693682670593262, -5.816768646240234, -5.893012046813965], [-3.53407883644104, -3.6428568363189697, -3.711928606033325, -3.7453081607818604, -3.873140573501587, -4.057618141174316, -4.074853897094727, -4.089373588562012, -4.15434455871582, -4.330026626586914], [-0.9078052639961243, -2.1823394298553467, -2.394821882247925, -2.603955030441284, -3.3880927562713623, -3.8005759716033936, -3.8053042888641357, -3.809105634689331, -4.087407112121582, -4.3294878005981445], [-1.933510184288025, -2.9139838218688965, -3.0599865913391113, -3.1160807609558105, -3.2958388328552246, -3.5592751502990723, -3.6166653633117676, -3.7133564949035645, -3.767514705657959, -3.838498592376709], [-0.8373547196388245, -1.1958599090576172, -1.4572124481201172, -4.583560943603516, -5.702604293823242, -5.870412826538086, -5.93589973449707, -6.249223709106445, -6.779117584228516, -6.957937240600586], [-1.9734289646148682, -2.132875680923462, -2.271436929702759, -2.377451181411743, -2.5762083530426025, -2.914226770401001, -3.1239511966705322, -3.5308945178985596, -3.7544949054718018, -4.254095077514648], [-1.6139057874679565, -2.930103302001953, -3.1899681091308594, -3.5480833053588867, -3.5578737258911133, -3.631312370300293, -3.998213768005371, -4.1391401290893555, -4.144331932067871, -4.304666519165039], [-0.8909848928451538, -2.585568904876709, -2.6268134117126465, -2.8050246238708496, -3.237273693084717, -3.3593859672546387, -3.367457866668701, -3.7869372367858887, -4.156163692474365, -4.3951945304870605], [-2.171121597290039, -2.2278690338134766, -2.32568359375, -2.7392807006835938, -3.246933937072754, -3.395308494567871, -3.566441535949707, -3.900796890258789, -3.9623565673828125, -3.9678173065185547], [-0.27238547801971436, -2.0229005813598633, -3.5072107315063477, -4.092101097106934, -4.726639747619629, -4.844346046447754, -4.899807929992676, -5.274807929992676, -5.4926042556762695, -5.696812629699707], [-0.05068284645676613, -3.972271680831909, -5.245936393737793, -5.386862754821777, -5.638373374938965, -6.049596786499023, -6.616394996643066, -7.4312896728515625, -7.4971771240234375, -7.507089614868164], [-0.28167083859443665, -1.7536003589630127, -3.144427537918091, -4.058299541473389, -4.736945629119873, -5.930068492889404, -8.867984771728516, -10.067056655883789, -10.406657218933105, -11.17859172821045], [-1.0609570381348021e-05, -13.489243507385254, -13.755928039550781, -13.79176139831543, -13.880733489990234, -14.227691650390625, -14.264202117919922, -14.59422779083252, -14.63396167755127, -14.759981155395508], [-0.4706292152404785, -2.741302967071533, -2.8914761543273926, -4.332835674285889, -4.465321063995361, -4.5308451652526855, -4.611640453338623, -4.704295635223389, -4.79633092880249, -4.805044651031494], [-1.8389887809753418, -3.136481761932373, -3.285163402557373, -3.7364325523376465, -3.7711596488952637, -3.7825675010681152, -3.8949294090270996, -3.9570116996765137, -4.064433574676514, -4.0901713371276855], [-0.9599233269691467, -2.6870064735412598, -2.8849434852600098, -3.4361138343811035, -3.767977237701416, -3.8259854316711426, -4.052595615386963, -4.112389087677002, -4.226521015167236, -4.373791217803955], [-1.539384365081787, -1.8348917961120605, -3.4136176109313965, -3.452949047088623, -3.5647521018981934, -3.5673880577087402, -3.579576015472412, -3.7346396446228027, -3.7785258293151855, -3.8780760765075684], [-2.2780985832214355, -2.6929678916931152, -2.900298595428467, -3.4762892723083496, -3.519313335418701, -3.6735892295837402, -3.6737637519836426, -3.744438648223877, -3.901101589202881, -3.9223685264587402], [-1.7902175188064575, -2.0978879928588867, -2.389349937438965, -2.563277244567871, -2.687506675720215, -2.732855796813965, -3.031914710998535, -3.996767997741699, -4.083949089050293, -4.12277889251709], [-2.7433362007141113, -2.907536029815674, -2.9570279121398926, -2.9577584266662598, -3.1004281044006348, -3.325803279876709, -3.6363892555236816, -3.8191628456115723, -3.848233699798584, -3.9220614433288574]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\" upon\", \" there\", \",\", \" the\", \" she\", \" on\", \" he\", \" day\", \" in\", \" night\"], [\" a\", \" an\", \" the\", \" one\", \" time\", \" some\", \" upon\", \" it\", \" two\", \" something\"], [\" time\", \" day\", \" night\", \" morning\", \" week\", \" Sunday\", \" long\", \" Wednesday\", \" dark\", \" little\"], [\",\", \" there\", \" in\", \" a\", \" was\", \" upon\", \".\", \" on\", \" the\", \" lived\"], [\" was\", \" were\", \" lived\", \",\", \" are\", \" a\", \" is\", \" there\", \" had\", \" wasn\"], [\" a\", \" an\", \" two\", \" something\", \" the\", \" some\", \" Tom\", \" one\", \" Jack\", \" three\"], [\" little\", \" girl\", \" boy\", \" big\", \" brave\", \" man\", \" small\", \" nice\", \" young\", \" happy\"], [\".\", \" who\", \" called\", \" named\", \" that\", \" in\", \",\", \" and\", \" living\", \" with\"], [\" He\", \" It\", \" The\", \" She\", \" His\", \" Every\", \" One\", \" In\", \" This\", \" Her\"], [\" was\", \" lived\", \" liked\", \" wanted\", \" had\", \" loved\", \" didn\", \" looked\", \" felt\", \" went\"], [\" very\", \" a\", \" so\", \" walking\", \" looking\", \" scared\", \" small\", \" always\", \" feeling\", \" brave\"], [\" through\", \" in\", \" along\", \" around\", \" down\", \" on\", \" across\", \" and\", \" near\", \" with\"], [\" in\", \" the\", \" looking\", \" and\", \",\", \" when\", \" his\", \" a\", \" outside\", \" on\"], [\" big\", \" lot\", \" house\", \" tree\", \" very\", \" small\", \" garden\", \" corner\", \" pond\", \" dark\"], [\" when\", \" and\", \".\", \",\", \" with\", \" looking\", \" in\", \" all\", \" full\", \" filled\"], [\" with\", \".\", \" up\", \" full\", \" by\", \" in\", \" to\", \" and\", \" filled\", \" from\"], [\" cob\", \" things\", \" toys\", \" lots\", \" a\", \" other\", \" food\", \" light\", \" webs\", \" junk\"], [\".\", \" and\", \",\", \"!\", \" in\", \" that\", \" food\", \" he\", \" from\", \" on\"], [\" He\", \" Suddenly\", \" The\", \" It\", \" One\", \" His\", \"\\n\", \" All\", \" Everywhere\", \" Every\"], [\" was\", \" wanted\", \" saw\", \" looked\", \" had\", \" liked\", \" thought\", \" found\", \" didn\", \" decided\"], [\" around\", \" at\", \" for\", \" up\", \" in\", \" all\", \" and\", \" very\", \" everywhere\", \" inside\"], [\" the\", \" every\", \" all\", \" and\", \" his\", \" a\", \" boxes\", \" amaz\", \" surprise\", \" wonder\"], [\" corner\", \" junk\", \" corners\", \" mirror\", \" closet\", \" room\", \" box\", \" cup\", \" dark\", \" window\"], [\" and\", \" box\", \",\", \" pile\", \" room\", \".\", \" boxes\", \" but\", \" he\", \" house\"], [\" he\", \" it\", \" the\", \" something\", \" a\", \" one\", \" his\", \" suddenly\", \" there\", \" someone\"], [\" found\", \" saw\", \" noticed\", \" spotted\", \" was\", \" heard\", \" came\", \" got\", \" discovered\", \" realized\"], [\" a\", \" something\", \" an\", \" the\", \" some\", \" one\", \" all\", \" another\", \" what\", \" it\"], [\" special\", \" that\", \" interesting\", \" very\", \" he\", \".\", \" strange\", \" amazing\", \" shiny\", \" new\"], [\".\", \" -\", \"!\", \" that\", \" in\", \" and\", \",\", \":\", \" \\u2013\", \" to\"], [\" It\", \" He\", \"\\n\", \" Inside\", \" There\", \" The\", \" \", \" A\", \" In\", \" When\"], [\" saw\", \" picked\", \" was\", \" opened\", \" decided\", \" found\", \" had\", \" put\", \" pulled\", \" thought\"], [\" it\", \" the\", \" and\", \" a\", \" his\", \" some\", \" around\", \" all\", \" leaves\", \" pieces\"], [\" and\", \" around\", \" into\", \" in\", \",\", \" with\", \" a\", \" all\", \" to\", \" on\"], [\" it\", \" saw\", \" found\", \" something\", \" tw\", \" looked\", \" a\", \" made\", \" started\", \" twisted\"], [\" a\", \" it\", \" something\", \" the\", \" his\", \" things\", \" all\", \" funny\", \" him\", \" lots\"], [\" with\", \" out\", \" that\", \" he\", \" all\", \" look\", \" like\", \".\", \" into\", \" in\"], [\".\", \",\", \" and\", \" so\", \" again\", \"!\", \" down\", \" until\", \" to\", \" -\"], [\" He\", \"\\n\", \" Then\", \" It\", \" \", \" The\", \" Suddenly\", \" But\", \" When\", \" There\"], [\"\\n\", \"The\", \"He\", \" \", \"Then\", \"Story\", \"It\", \"When\", \"Suddenly\", \"One\"], [\"The\", \"He\", \"Suddenly\", \"One\", \"When\", \"Then\", \"\\\"\", \"But\", \"It\", \"At\"], [\" spider\", \" bug\", \" man\", \" junk\", \" little\", \" old\", \" next\", \" boy\", \" cater\", \" monster\"], [\" was\", \" saw\", \" wanted\", \" thought\", \" started\", \" looked\", \" didn\", \" liked\", \" had\", \" kept\"], [\" to\", \" the\", \" it\", \" this\", \" having\", \" his\", \" junk\", \" being\", \" all\", \" playing\"], [\" explore\", \" look\", \" twist\", \" play\", \" take\", \" crawl\", \" make\", \" keep\", \" move\", \" watch\"], [\" things\", \" the\", \" his\", \" junk\", \" out\", \" all\", \" everything\", \" through\", \".\", \" it\"], [\".\", \",\", \"!\", \" and\", \" things\", \" into\", \" in\", \" with\", \" too\", \" so\"], [\" He\", \" It\", \" The\", \" One\", \" But\", \" Every\", \" She\", \" There\", \" Then\", \" When\"], [\" put\", \" sorted\", \" thought\", \" found\", \" made\", \" would\", \" picked\", \" liked\", \" decided\", \" added\"], [\" to\", \" the\", \" it\", \" how\", \" all\", \" his\", \" making\", \" looking\", \" finding\", \" this\"], [\" make\", \" sort\", \" keep\", \" look\", \" find\", \" put\", \" take\", \" twist\", \" fix\", \" work\"], [\" in\", \" on\", \" and\", \" down\", \" there\", \" around\", \" by\", \" outside\", \" at\", \" inside\"], [\" and\", \",\", \" all\", \".\", \" for\", \" in\", \" every\", \" too\", \" on\", \" with\"], [\" sort\", \" watch\", \" make\", \" look\", \" play\", \" move\", \" he\", \" work\", \" think\", \" keep\"], [\" things\", \" the\", \" all\", \" it\", \".\", \" his\", \" through\", \" everything\", \" and\", \" out\"], [\" things\", \" junk\", \" pieces\", \" items\", \" mess\", \" toys\", \" stuff\", \" rocks\", \" spider\", \" waste\"], [\".\", \" of\", \" and\", \" to\", \" by\", \" that\", \",\", \" into\", \" in\", \" he\"], [\" He\", \" One\", \" It\", \"\\n\", \" The\", \" Every\", \" But\", \" Then\", \" Sometimes\", \" His\"], [\" would\", \" sorted\", \" put\", \" liked\", \" was\", \" made\", \" thought\", \" found\", \" had\", \" even\"], [\" the\", \" all\", \" them\", \" it\", \" and\", \" his\", \" everything\", \" things\", \" until\", \" through\"], [\" pieces\", \" piles\", \" rocks\", \" cars\", \" junk\", \" big\", \" red\", \" toys\", \" things\", \" spider\"], [\" by\", \" and\", \" of\", \" into\", \",\", \" in\", \" one\", \".\", \" so\", \" together\"], [\" piles\", \" two\", \" a\", \" the\", \" different\", \" neat\", \" small\", \" one\", \" groups\", \" big\"], [\" piles\", \" neat\", \" groups\", \" big\", \".\", \",\", \" pieces\", \" and\", \" long\", \" small\"], [\" piles\", \" two\", \" neat\", \" different\", \" a\", \" groups\", \" small\", \" the\", \" big\", \" four\"], [\".\", \" and\", \",\", \" of\", \" -\", \":\", \" so\", \" too\", \"!\", \" until\"], [\" He\", \" One\", \"\\n\", \" Then\", \" The\", \" \", \" When\", \" As\", \" It\", \" Soon\"], [\" pile\", \" was\", \" day\", \" for\", \" piece\", \" piles\", \" side\", \" had\", \" room\", \" leaf\"], [\" was\", \" had\", \" for\", \" made\", \" looked\", \" fit\", \" even\", \" stayed\", \" would\", \" got\"], [\" for\", \" very\", \" made\", \" a\", \" big\", \" so\", \" sorted\", \" too\", \" round\", \" slow\"], [\" a\", \" the\", \" big\", \" hours\", \" his\", \" him\", \" special\", \" each\", \" pieces\", \" one\"], [\" of\", \" piles\", \" fun\", \" junk\", \" special\", \" pieces\", \" neat\", \" interesting\", \" in\", \" looked\"], [\" the\", \" all\", \" his\", \" them\", \" it\", \" a\", \" him\", \" this\", \" which\", \" what\"], [\" pieces\", \" junk\", \" piles\", \" things\", \" others\", \" pile\", \" house\", \" spider\", \" most\", \" other\"], [\".\", \" for\", \" he\", \",\", \" and\", \" when\", \" of\", \" that\", \" in\", \"!\"], [\" and\", \" one\", \" but\", \" a\", \" the\", \" he\", \" so\", \" when\", \" another\", \" while\"], [\" he\", \" the\", \" it\", \" then\", \" one\", \" they\", \" when\", \" soon\", \" something\", \" all\"], [\" were\", \" kept\", \" found\", \" had\", \" all\", \" did\", \" both\", \" weren\", \" didn\", \" still\"], [\" all\", \" too\", \" not\", \" both\", \" very\", \" so\", \" hard\", \" mixed\", \" still\", \" different\"], [\" mixed\", \" too\", \" sorted\", \" made\", \" different\", \" very\", \" fit\", \" so\", \" broken\", \" in\"], [\" together\", \" in\", \" into\", \" up\", \".\", \" and\", \" perfectly\", \" so\", \" with\", \"!\"], [\".\", \" and\", \" to\", \"!\", \" perfectly\", \" so\", \" in\", \" into\", \" the\", \" until\"], [\"\\n\", \" \", \" He\", \" The\", \" They\", \" It\", \" Then\", \" When\", \" Finally\", \" Soon\"], [\"\\n\", \"The\", \" \", \"He\", \"When\", \"Next\", \"Story\", \"After\", \"\\\"\", \"Then\"], [\"The\", \"He\", \"When\", \"After\", \"Suddenly\", \"\\\"\", \"Then\", \"Next\", \"Just\", \"Soon\"], [\" spider\", \" slow\", \" two\", \" junk\", \" bear\", \" man\", \" little\", \" pieces\", \" boy\", \" poor\"], [\" sort\", \" sorting\", \" sorted\", \" look\", \" was\", \" pile\", \" last\", \" looked\", \" quickly\", \" sorts\"], [\" the\", \" was\", \" and\", \",\", \" all\", \" junk\", \".\", \" made\", \" quickly\", \" started\"], [\" pieces\", \" junk\", \" piles\", \" pile\", \" mess\", \" slow\", \" puzzle\", \" things\", \" waste\", \" last\"], [\" was\", \".\", \" made\", \",\", \" pile\", \" and\", \" looked\", \" started\", \" quickly\", \" had\"], [\" the\", \" it\", \" soon\", \" sorting\", \" making\", \" then\", \" when\", \" was\", \" putting\", \" one\"], [\" the\", \" it\", \",\", \" they\", \" had\", \" found\", \" all\", \" there\", \" he\", \" enough\"], [\" was\", \" looked\", \" started\", \" had\", \" became\", \" made\", \" got\", \" began\", \" were\", \" felt\"], [\" like\", \" much\", \" really\", \" just\", \" very\", \" nice\", \" perfect\", \" great\", \" better\", \" so\"], [\" a\", \" it\", \" new\", \" the\", \" two\", \" they\", \" fun\", \" something\", \" so\", \" little\"], [\" big\", \" lot\", \" mess\", \" brand\", \" great\", \" good\", \" beautiful\", \" castle\", \" new\", \" rainbow\"], [\" blanket\", \",\", \" ball\", \" and\", \" toy\", \" bed\", \" t\", \" pillow\", \" pile\", \" cloud\"], [\".\", \"!\", \",\", \" and\", \" with\", \" to\", \" for\", \" was\", \" in\", \" of\"], [\" The\", \" He\", \" They\", \" It\", \" But\", \" Then\", \"\\n\", \" All\", \" Everyone\", \" She\"], [\" were\", \" looked\", \" both\", \" had\", \" found\", \" all\", \" smiled\", \" saw\", \" couldn\", \" sorted\"], [\" both\", \" so\", \" very\", \" happy\", \" all\", \" having\", \" excited\", \" proud\", \" surprised\", \" the\"], [\" very\", \" so\", \" happy\", \" proud\", \" excited\", \" surprised\", \" really\", \" smiling\", \" glad\", \" tired\"], [\" happy\", \" proud\", \" excited\", \" pleased\", \" surprised\", \" glad\", \" clean\", \" comfortable\", \" busy\", \" cozy\"], [\" and\", \".\", \"!\", \" with\", \" that\", \" to\", \",\", \" they\", \" when\", \" because\"], [\" They\", \"\\n\", \" The\", \" Now\", \" But\", \" Then\", \" \", \" It\", \" From\", \" He\"], [\"\\n\", \"The\", \"<|endoftext|>\", \"Summary\", \"They\", \"\\\"\", \" \", \"But\", \"Then\", \"Story\"], [\"The\", \"\\\"\", \"They\", \"But\", \"Then\", \"After\", \"When\", \"Suddenly\", \"\\ufffd\", \"From\"], [\" decided\", \" sat\", \" started\", \" looked\", \" smiled\", \" put\", \" kept\", \" hugged\", \" both\", \" had\"], [\" sat\", \" hugged\", \" smiled\", \" jumped\", \" had\", \" looked\", \" worked\", \" started\", \" took\", \" laughed\"], [\" and\", \",\", \" as\", \" together\", \".\", \" when\", \" at\", \" out\", \" until\", \" about\"], [\" they\", \" the\", \" it\", \" their\", \" each\", \" that\", \" much\", \" he\", \" hard\", \" soon\"], [\" sorted\", \" looked\", \" made\", \" sat\", \" jumped\", \" finished\", \" saw\", \" watched\", \" ran\", \" played\"], [\" the\", \".\", \" and\", \" it\", \" their\", \" things\", \" through\", \" all\", \" into\", \",\"], [\" junk\", \" pieces\", \" mess\", \" things\", \" piles\", \" pile\", \" room\", \" stuff\", \" broken\", \" books\"], [\" of\", \".\", \" and\", \" into\", \"s\", \" they\", \"ful\", \"ings\", \" together\", \"ers\"], [\" the\", \" their\", \" it\", \" everything\", \" each\", \" junk\", \" all\", \" things\", \" day\", \" them\"], [\" junk\", \" pieces\", \" mess\", \" things\", \" piles\", \" room\", \" toys\", \" items\", \" special\", \" stuff\"], [\".\", \" together\", \" into\", \" and\", \" pile\", \" in\", \",\", \" they\", \" pieces\", \" sorted\"], [\" into\", \" together\", \" in\", \" and\", \" on\", \".\", \" onto\", \" to\", \" with\", \" up\"], [\" the\", \" piles\", \" neat\", \" two\", \" place\", \" its\", \" their\", \" one\", \" pile\", \" it\"], [\" box\", \" pile\", \" room\", \" house\", \" piles\", \" special\", \" car\", \" chair\", \" junk\", \" living\"], [\".\", \" and\", \",\", \" together\", \" with\", \"!\", \" where\", \" so\", \" to\", \" again\"], [\" They\", \" Now\", \" The\", \"\\n\", \" It\", \" Then\", \" From\", \" When\", \" Every\", \" And\"], [\" was\", \" looked\", \" made\", \" felt\", \" had\", \" took\", \" stayed\", \" wasn\", \"'s\", \" seemed\"], [\" fun\", \" a\", \" much\", \" so\", \" the\", \" nice\", \" now\", \" full\", \" perfect\", \" all\"], [\" and\", \",\", \" work\", \" but\", \" to\", \" that\", \" at\", \" again\", \" because\", \".\"], [\" the\", \" one\", \" their\", \" piles\", \" a\", \" neat\", \" place\", \" pieces\", \" all\", \" two\"], [\" room\", \" most\", \" junk\", \" pieces\", \" piles\", \" pile\", \" perfect\", \" house\", \" soft\", \" same\"], [\" room\", \" junk\", \" piles\", \" pile\", \" place\", \" box\", \" one\", \" world\", \" and\", \" space\"], [\".\", \",\", \" and\", \"!\", \" so\", \" with\", \" now\", \" again\", \" -\", \" too\"], [\" and\", \" but\", \" with\", \" where\", \" so\", \" making\", \" looking\", \" just\", \" by\", \" all\"], [\" all\", \" the\", \" a\", \" lots\", \" piles\", \" every\", \" no\", \" plenty\", \" its\", \" each\"], [\" of\", \" to\", \" for\", \" more\", \" and\", \" on\", \" pieces\", \" space\", \",\", \" that\"], [\" junk\", \" things\", \" space\", \" new\", \" other\", \" fun\", \" toys\", \" room\", \" all\", \" the\"], [\" pieces\", \" and\", \" space\", \",\", \" things\", \" clothes\", \" toys\", \" boxes\", \" blankets\", \" chairs\"], [\".\", \" and\", \",\", \" for\", \" to\", \"!\", \" in\", \" on\", \" that\", \" inside\"], [\" and\", \" toys\", \" books\", \" a\", \" shoes\", \" or\", \" special\", \" the\", \" shiny\", \" even\"], [\" a\", \" the\", \" then\", \" all\", \" even\", \" it\", \" some\", \" they\", \" everything\", \" lots\"], [\" was\", \" who\", \" in\", \" had\", \" else\", \" enjoyed\", \" could\", \".\", \" lived\", \" around\"], [\" happy\", \" very\", \" so\", \" pleased\", \" proud\", \" amazed\", \" having\", \" satisfied\", \" glad\", \" excited\"], [\".\", \"!\", \" and\", \" to\", \" with\", \" in\", \" again\", \" too\", \" that\", \" once\"], [\"\\n\", \" The\", \" \", \" They\", \" Now\", \" It\", \" From\", \" And\", \" Everyone\", \" In\"], [\" was\", \" had\", \" felt\", \" made\", \" knew\", \" smiled\", \" finished\", \" thanked\", \" went\", \" could\"], [\" be\", \" never\", \" always\", \" sit\", \" sort\", \" have\", \" stay\", \" look\", \" also\", \" make\"], [\" the\", \" everything\", \" all\", \" things\", \" and\", \" them\", \" it\", \" every\", \" their\", \" anything\"], [\" every\", \" all\", \" again\", \" by\", \" into\", \" together\", \" soon\", \" and\", \" now\", \" in\"], [\" into\", \" again\", \" together\", \" in\", \" to\", \" and\", \" on\", \" soon\", \" home\", \",\"], [\" the\", \" piles\", \" their\", \" its\", \" more\", \" place\", \" different\", \" neat\", \" two\", \" all\"], [\" room\", \" junk\", \" box\", \" special\", \" pile\", \" neat\", \" same\", \" most\", \" right\", \" piles\"], [\" and\", \",\", \".\", \" of\", \" every\", \" again\", \" so\", \" soon\", \" for\", \" next\"], [\" it\", \" the\", \" they\", \" all\", \" everyone\", \" everything\", \" one\", \" bed\", \" there\", \" then\"], [\" was\", \" had\", \" became\", \" looked\", \" could\", \" spark\", \" finally\", \" would\", \" shone\", \" fell\"], [\" time\", \" nice\", \" all\", \" done\", \" full\", \" neat\", \" finished\", \" clean\", \" ready\", \" too\"], [\".\", \"!\", \" and\", \" again\", \",\", \" with\", \" to\", \" for\", \" in\", \" the\"], [\"\\n\", \" \", \" The\", \" Then\", \" They\", \" Everyone\", \" And\", \" Now\", \" It\", \" From\"], [\"Summary\", \"\\n\", \"<|endoftext|>\", \" \", \"The\", \"Story\", \"They\", \"And\", \"Words\", \"When\"], [\"The\", \"And\", \"They\", \"When\", \"From\", \"So\", \"Everyone\", \"Then\", \"Now\", \"After\"], [\" end\", \" End\", \" slow\", \" moral\", \" two\", \" spider\", \" room\", \" junk\", \" box\", \" little\"], [\" spider\", \" junk\", \" and\", \" spiders\", \" chair\", \" sorting\", \" cob\", \" machine\", \" sort\", \" robot\"], [\"igator\", \" day\", \" year\", \" the\", \" week\", \" was\", \" of\", \" afternoon\", \" sorted\", \" summer\"], [\" the\", \" them\", \" his\", \" their\", \" her\", \" its\", \" a\", \" it\", \" all\", \" each\"], [\" junk\", \" mess\", \" pieces\", \" work\", \" cleaning\", \" room\", \" things\", \" items\", \" fun\", \" sorting\"], [\" was\", \" were\", \" looked\", \" stayed\", \" had\", \" cheered\", \" went\", \" smiled\", \" knew\", \" now\"], [\" sorted\", \" been\", \" a\", \" to\", \" made\", \" become\", \" finished\", \" plenty\", \" the\", \" its\"], [\" lot\", \" great\", \" big\", \" special\", \" wonderful\", \" happy\", \" good\", \" nice\", \" new\", \" beautiful\"], [\" nice\", \" neat\", \" fun\", \" special\", \" good\", \" great\", \" cool\", \" wonderful\", \" happy\", \" big\"], [\" and\", \" pile\", \" room\", \" place\", \" space\", \" box\", \" look\", \" new\", \",\", \" style\"], [\" to\", \".\", \",\", \" and\", \" in\", \"!\", \" for\", \" on\", \" with\", \" that\"], [\" play\", \" fit\", \" be\", \" sort\", \" go\", \" keep\", \" put\", \" rest\", \" make\", \" complete\"], [\".\", \" in\", \" and\", \",\", \"!\", \" on\", \" at\", \" with\", \" for\", \" that\"], [\" It\", \" The\", \" And\", \" Now\", \"\\n\", \" Everyone\", \" From\", \" So\", \" In\", \" When\"], [\" so\", \" it\", \" when\", \" that\", \" the\", \" every\", \" from\", \" with\", \" they\", \" then\"], [\" all\", \" both\", \" lived\", \" were\", \" had\", \" did\", \" knew\", \" never\", \" would\", \" stayed\"], [\" lived\", \" had\", \" agreed\", \" enjoyed\", \" knew\", \" slept\", \" went\", \" stayed\", \" played\", \" learned\"], [\" happily\", \" together\", \" in\", \" peacefully\", \" happy\", \" there\", \" very\", \" the\", \" a\", \" unh\"], [\" ever\", \" together\", \" in\", \",\", \" and\", \".\", \" with\", \" for\", \" happily\", \" on\"], [\" after\", \" since\", \" sorted\", \" ever\", \" sorting\", \" afterwards\", \" up\", \" so\", \" in\", \" there\"], [\".\", \"!\", \" in\", \",\", \" with\", \" on\", \" -\", \" and\", \" by\", \" while\"], [\"\\n\", \" The\", \" They\", \" \", \" It\", \" And\", \" That\", \" From\", \" In\", \"Summary\"], [\"Summary\", \"<|endoftext|>\", \"\\n\", \"The\", \"THE\", \"<\", \" \", \"Story\", \"And\", \"They\"], [\"\\n\", \",\", \".\", \"\\n\\n\", \" he\", \" the\", \" it\", \".\\\"\", \",\\\"\", \" \"], [\" and\", \",\", \" in\", \"!\", \"\\n\", \" was\", \" very\", \" the\", \" go\", \" that\"], [\" felt\", \" remembered\", \" looked\", \" had\", \" kept\", \" made\", \" slept\", \" thought\", \" wanted\", \" smiled\"], [\" with\", \" in\", \" and\", \" together\", \" a\", \" the\", \" outside\", \" on\", \" his\", \" nicely\"], [\" his\", \" the\", \" them\", \" it\", \" a\", \" her\", \" something\", \" other\", \" all\", \" Lucy\"], [\" little\", \" toy\", \" new\", \" toys\", \" same\", \" ball\", \" car\", \" kids\", \" other\", \" big\"], [\" and\", \",\", \" in\", \".\", \" outside\", \" when\", \" on\", \" together\", \" every\", \" for\"], [\" the\", \" made\", \" was\", \" his\", \" thanked\", \" its\", \" never\", \" it\", \" had\", \" kept\"], [\"ney\", \"ed\", \"neys\", \"ing\", \"ering\", \"bled\", \"ized\", \"hed\", \"aved\", \"kered\"], [\" in\", \" were\", \" kept\", \",\", \".\", \" together\", \" stayed\", \" it\", \" from\", \" to\"], [\" the\", \" making\", \" driving\", \" day\", \" itself\", \" night\", \" his\", \" being\", \".\", \" himself\"], [\" sure\", \" a\", \" them\", \" loud\", \" it\", \" the\", \" him\", \" people\", \" lots\", \" everyone\"], [\" go\", \" laugh\", \" happy\", \" smile\", \" look\", \" both\", \" very\", \".\", \" feel\", \" a\"], [\".\", \" and\", \" too\", \",\", \" to\", \" again\", \" friends\", \" together\", \" every\", \" with\"], [\"\\n\", \" The\", \" They\", \" He\", \" It\", \" \", \" And\", \" She\", \" Everyone\", \" Tim\"], [\"Summary\", \"Story\", \"Words\", \"Features\", \"Random\", \"\\n\", \"The\", \"<|endoftext|>\", \" \", \"Sum\"], [\":\", \".\", \" that\", \" the\", \" one\", \" -\", \" going\", \",\", \" like\", \" in\"], [\" A\", \" Two\", \" An\", \" Lucy\", \" Jack\", \" Tom\", \" John\", \" Tim\", \" The\", \" Lily\"], [\" little\", \" man\", \" lonely\", \" red\", \" fire\", \" truck\", \" bald\", \" curious\", \" big\", \" boy\"], [\" truck\", \" chim\", \" car\", \" and\", \"-\", \" train\", \" snail\", \" engine\", \" crane\", \" turtle\"], [\" steady\", \" lonely\", \" gentle\", \" tired\", \" shy\", \" careful\", \" sad\", \" old\", \" quiet\", \" happy\"], [\" truck\", \" train\", \" car\", \" man\", \" z\", \"-\", \" chim\", \" van\", \" elevator\", \" vehicle\"], [\" girl\", \" car\", \" train\", \" chim\", \" boy\", \" bird\", \" house\", \" engine\", \" red\", \" dog\"], [\" is\", \" in\", \" play\", \" becomes\", \" of\", \" become\", \" on\", \" had\", \" wanted\", \" helps\"]], \"correctTokenRank\": [294, 0, 0, 0, 1, 0, 0, 193, 0, 0, 0, 3, 3, 7, 32, 9, 0, 9, 0, 0, 3, 4, 0, 1, 15, 0, 0, 1, 0, 0, 1, 91, 0, 0, 7, 5, 301, 0, 1, 0, 0, 0, 7, 0, 14, 3, 0, 0, 7, 0, 47, 4, 0, 0, 1, 2, 0, 0, 1, 0, 0, 3, 1, 74, 0, 0, 1, 0, 0, 0, 27, 0, 0, 0, 3, 2, 5, 0, 0, 114, 0, 0, 0, 0, 0, 361, 1, 0, 1, 5, 2, 1, 1, 0, 0, 123, 20, 0, 2, 0, 0, 1, 0, 1, 1, 0, 2, 51, 9, 2, 0, 0, 0, 13, 0, 0, 0, 39, 0, 0, 2, 0, 4, 0, 13, 40, 0, 247, 0, 1, 2, 7, 0, 27, 5, 2, 0, 46, 0, 0, 0, 5, 38, 4, 5, 19, 0, 0, 2, 13, 0, 0, 36, 0, 0, 1, 0, 2, 17, 6, 0, 5, 4, 2, 29, 1, 4, 0, 16, 0, 2, 8, 0, 0, 0, 0, 0, 0, 0, 1, 31, 16, 30, 0, 1, 36, 0, 609, 2, 22, 1, 2, 2, 0, 0, 0, 0, 0, 19, 3, 38, 12, 58, 22], \"correctTokenLogProb\": [-11.625454902648926, -0.372489869594574, -0.005904730875045061, -0.011737688444554806, -1.8141651153564453, -0.1264190971851349, -0.03639727830886841, -7.059589862823486, -0.7586244344711304, -0.4660787284374237, -0.45198941230773926, -3.531412363052368, -2.4541120529174805, -3.780423879623413, -5.294568061828613, -4.805354118347168, -0.0004503904783632606, -4.260258674621582, -0.10771898180246353, -0.4609256982803345, -2.361538887023926, -3.282353162765503, -1.2032361030578613, -1.640767216682434, -5.380034923553467, -0.11450029909610748, -0.201736181974411, -1.2467858791351318, -1.6954941749572754, -0.29978570342063904, -1.8919280767440796, -7.250479698181152, -0.5307212471961975, -1.274881362915039, -3.5086348056793213, -3.7260258197784424, -10.177480697631836, -0.5955834984779358, -1.743154764175415, -0.03866378962993622, -0.5724437236785889, -0.43097275495529175, -3.8459525108337402, -0.9496457576751709, -4.156761169433594, -3.2522835731506348, -0.49126970767974854, -0.18188579380512238, -3.650604248046875, -0.8335361480712891, -6.803802490234375, -3.896991729736328, -0.32031911611557007, -0.5803281664848328, -2.134364128112793, -3.0411720275878906, -0.782444417476654, -0.3114766478538513, -1.969999074935913, -0.782846212387085, -1.4243627786636353, -2.1955196857452393, -1.8033723831176758, -9.819659233093262, -0.570478618144989, -0.21563000977039337, -1.4745231866836548, -0.15613678097724915, -0.20562273263931274, -0.655595600605011, -5.247343063354492, -0.12847380340099335, -1.0573594570159912, -0.5258836150169373, -2.5824971199035645, -1.7808362245559692, -3.4196207523345947, -0.849854052066803, -1.3299978971481323, -7.951554298400879, -0.3024566173553467, -0.4709051847457886, -1.0554325580596924, -0.010174315422773361, -0.32709017395973206, -9.93301010131836, -1.8415019512176514, -1.0852166414260864, -0.9601659774780273, -2.9102113246917725, -3.686372995376587, -2.1035826206207275, -2.7563252449035645, -0.9488503336906433, -0.6007412672042847, -6.987605094909668, -5.529287338256836, -0.10170501470565796, -2.2341928482055664, -0.9419487714767456, -0.833315908908844, -1.6230475902557373, -0.8675547242164612, -1.563567876815796, -1.7072370052337646, -0.03742186352610588, -2.4235429763793945, -6.340259552001953, -3.7144429683685303, -3.5375802516937256, -0.15745578706264496, -1.140855073928833, -0.22303339838981628, -6.046128749847412, -0.039599210023880005, -0.07649119943380356, -0.2642212510108948, -7.548993110656738, -0.8072007894515991, -1.251315712928772, -2.1845436096191406, -0.05521513894200325, -2.8915181159973145, -0.08196064829826355, -4.249545574188232, -7.593976020812988, -0.6625797748565674, -8.387211799621582, -1.5550811290740967, -1.6193064451217651, -2.6809396743774414, -4.305453300476074, -0.00549010606482625, -5.322322845458984, -2.836850643157959, -1.6227877140045166, -0.09975278377532959, -5.8604736328125, -0.8961080312728882, -0.585811972618103, -0.22058653831481934, -4.5408101081848145, -6.400509357452393, -2.822553873062134, -3.4708781242370605, -4.8897528648376465, -0.44924065470695496, -0.8413788080215454, -2.362283229827881, -4.913575172424316, -1.1556315422058105, -0.035400524735450745, -5.744747638702393, -0.18858753144741058, -0.17246674001216888, -1.0814508199691772, -0.22755968570709229, -2.440478801727295, -5.0546159744262695, -3.854830265045166, -0.04625729098916054, -3.4870705604553223, -4.250707149505615, -1.835835337638855, -5.872346878051758, -1.7916638851165771, -3.7206132411956787, -1.13639235496521, -4.29025936126709, -0.4920291304588318, -2.4268136024475098, -3.4622368812561035, -0.47193631529808044, -0.14269927144050598, -0.00815656129270792, -0.025035038590431213, -0.0005930095794610679, -0.26140275597572327, -0.021868286654353142, -1.351833462715149, -18.83498191833496, -4.691867828369141, -5.3984551429748535, -0.9088610410690308, -1.3315141201019287, -5.460882186889648, -0.9078052639961243, -9.111862182617188, -1.4572124481201172, -5.279411315917969, -2.930103302001953, -2.6268134117126465, -2.32568359375, -0.27238547801971436, -0.05068284645676613, -0.28167083859443665, -1.0609570381348021e-05, -0.4706292152404785, -4.647707462310791, -3.4361138343811035, -5.696107387542725, -4.176355838775635, -6.437752723693848, -4.410583019256592]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f4af2996110>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = model.generate(\n",
    "    \"Once upon a time\",\n",
    "    stop_at_eos=False,  # avoids a bug on MPS\n",
    "    temperature=1,\n",
    "    verbose=True,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_steps = 30_000 # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5 # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20 # 5% of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True, # we could pre-download the token dataset if it was small.\n",
    "    \n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=False,\n",
    "    gated=True,\n",
    "    \n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,# adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999, \n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    \n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size=16,\n",
    "    \n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False, # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    \n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_tinystories_1l\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavide-ghilardi0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/juice2/scr2/ghilardi/home/mats-interp/wandb/run-20240509_095515-myndqwh2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/myndqwh2' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/myndqwh2' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/myndqwh2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30000| MSE Loss 79.977 | L1 35.866: 100%|██████████| 122880000/122880000 [57:21<00:00, 43710.50it/s]  wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c285aed7a914c908ab2599a29e69ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='128.337 MB of 128.337 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>████████████████████████████████▇▇▅▅▄▃▂▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/aux_loss</td><td>███▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▂▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>losses/mse_loss</td><td>████▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>███▇▇▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/CE_loss_score</td><td>▁▁▁▁▂▃▃▃▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>▅▃▁▆▄▃▅▆▅▄▄▁▅▃▄▃▃▄▁▃▄▆▄▄▄▃▆▄▃█▄▄▁▄▄▅█▄▄▃</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>████▇▆▆▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>▄▂▃█▃▁▃▃▄▅▃▄▂▃▄▃▄▃▃▃▃▃▄▁▂▂▆▃▄▅▃▄▃▅▇▅▃▃▃▂</td></tr><tr><td>metrics/explained_variance</td><td>▁▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████████</td></tr><tr><td>metrics/explained_variance_std</td><td>████▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l0</td><td>▆▁▁▁▁▂▂▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████████████</td></tr><tr><td>metrics/l2_norm</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇████</td></tr><tr><td>metrics/l2_norm_in</td><td>▃▃▇▂▄▂▅▅▅▅▄▆▃▃▁▃▄▅▃▂▅▂▅▄▃▄▃▅▂▅▄▃▃▄▁▄▂█▃▅</td></tr><tr><td>metrics/l2_ratio</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███████</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▅▄▄▄▃▃▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁█████████████████████████████</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▅▇▇▇████████████████████████</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▂▃▃▃▄▅▆▅▅▄▄▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/aux_loss</td><td>56.76751</td></tr><tr><td>losses/ghost_grad_loss</td><td>0</td></tr><tr><td>losses/l1_loss</td><td>7.1733</td></tr><tr><td>losses/mse_loss</td><td>79.97746</td></tr><tr><td>losses/overall_loss</td><td>172.61145</td></tr><tr><td>metrics/CE_loss_score</td><td>0.86248</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>8.29373</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>2.77671</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>1.8969</td></tr><tr><td>metrics/explained_variance</td><td>0.56077</td></tr><tr><td>metrics/explained_variance_std</td><td>0.09308</td></tr><tr><td>metrics/l0</td><td>240.43335</td></tr><tr><td>metrics/l2_norm</td><td>13.34457</td></tr><tr><td>metrics/l2_norm_in</td><td>17.58649</td></tr><tr><td>metrics/l2_ratio</td><td>0.75841</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-9.52433</td></tr><tr><td>sparsity/below_1e-5</td><td>15926</td></tr><tr><td>sparsity/below_1e-6</td><td>15926</td></tr><tr><td>sparsity/dead_features</td><td>14931</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>6809.78369</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/myndqwh2' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/myndqwh2</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240509_095515-myndqwh2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True, # we could pre-download the token dataset if it was small.\n",
    "    \n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=False,\n",
    "    gated=False,\n",
    "    \n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,# adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999, \n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    \n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size=16,\n",
    "    \n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False, # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    \n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_tinystories_1l\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/juice2/scr2/ghilardi/home/mats-interp/wandb/run-20240509_105308-baz9qhv7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2171: UserWarning: Run (myndqwh2) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "30000| MSE Loss 79.977 | L1 35.866: 100%|██████████| 122880000/122880000 [58:07<00:00, 35238.11it/s]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f140ce1152e6406b935981d403dc0284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='115.934 MB of 128.212 MB uploaded\\r'), FloatProgress(value=0.9042385622059216, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>▁▅██████████████████████████████████████</td></tr><tr><td>details/current_learning_rate</td><td>████████████████████████████████▇▇▅▅▄▃▂▁</td></tr><tr><td>details/n_training_tokens</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>losses/ghost_grad_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/l1_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>losses/mse_loss</td><td>▄▄█▇▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>losses/overall_loss</td><td>▁▅█▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>metrics/CE_loss_score</td><td>█▃▁▂▂▃▂▃▃▃▄▃▅▄▄▅▄▅▅▅▆▅▅▅▆▆▇▆▆▆▆▆▆▆▅▇▇▆▆▆</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>▅▃▁▆▄▃▅▆▅▄▄▁▅▃▄▃▃▄▁▃▄▆▄▄▄▃▆▄▃█▄▄▁▄▄▅█▄▄▃</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>▁▃▆█▅▃▅▅▄▅▃▅▃▃▄▃▄▃▂▃▂▃▃▂▂▂▃▂▃▄▂▃▂▃▅▃▁▂▂▁</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>▄▂▃█▃▁▃▃▄▅▃▄▂▃▄▃▄▃▃▃▃▃▄▁▂▂▆▃▄▅▃▄▃▅▇▅▃▃▃▂</td></tr><tr><td>metrics/explained_variance</td><td>▆▅▁▂▃▃▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇█▇▇███▇█</td></tr><tr><td>metrics/explained_variance_std</td><td>▁▆████▇▇▇▇█▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▆▆▇▆▇▆▆▇▇▆▆▆▇▆</td></tr><tr><td>metrics/l0</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>metrics/l2_norm</td><td>▇▄▅▁▄▃▄▄▄▅▄▆▄▃▃▄▄▆▄▄▅▅▆▅▅▅▄▆▄▆▅▄▄▆▄▅▄█▄▆</td></tr><tr><td>metrics/l2_norm_in</td><td>▃▃▇▂▄▂▅▅▅▅▄▆▃▃▁▃▄▅▃▂▅▂▅▄▃▄▃▅▂▅▄▃▃▄▁▄▂█▃▅</td></tr><tr><td>metrics/l2_ratio</td><td>█▄▃▁▃▃▄▄▃▄▃▅▄▃▄▄▄▅▄▄▅▅▅▅▅▅▄▅▅▅▅▅▄▅▅▅▅▇▅▆</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>█▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sparsity/below_1e-5</td><td>▁▄▄▆▇█████▇▆▆▆▇▆▅▆▅▆▆▆▅▅▅▅▅▅▅▅</td></tr><tr><td>sparsity/below_1e-6</td><td>▁▁▂▃▄▅▆██▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▅▅▆▆▅</td></tr><tr><td>sparsity/dead_features</td><td>▁▁▁▁▁▁▂▂▂▃▄▄▄▃▂▄▅▅▅▅▇▆▆▇▇█▆█▇▇▆▇█▇▆▇▇█▇█</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▂▂▂▃▃▂▃▄▄▄▄▄▅▅▅▆▆▆▆▇▆▆▆▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/ghost_grad_loss</td><td>0</td></tr><tr><td>losses/l1_loss</td><td>12.63448</td></tr><tr><td>losses/mse_loss</td><td>70.25092</td></tr><tr><td>losses/overall_loss</td><td>133.42332</td></tr><tr><td>metrics/CE_loss_score</td><td>0.86972</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>8.29373</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>2.73045</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>1.8969</td></tr><tr><td>metrics/explained_variance</td><td>0.57939</td></tr><tr><td>metrics/explained_variance_std</td><td>0.15667</td></tr><tr><td>metrics/l0</td><td>82.93921</td></tr><tr><td>metrics/l2_norm</td><td>12.74778</td></tr><tr><td>metrics/l2_norm_in</td><td>17.58649</td></tr><tr><td>metrics/l2_ratio</td><td>0.71047</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.84769</td></tr><tr><td>sparsity/below_1e-5</td><td>17</td></tr><tr><td>sparsity/below_1e-6</td><td>14</td></tr><tr><td>sparsity/dead_features</td><td>14</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>5.08258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240509_105308-baz9qhv7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard vs. Gated SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccf583f69694370a28a2438cba0fbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n",
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import LMSparseAutoencoderSessionloader\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "REPO_ID = \"ghidav/tiny-stories-1L-21M-saes\"\n",
    "path = snapshot_download(repo_id=REPO_ID)\n",
    "\n",
    "model, standard_sae, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
    "    path = os.path.join(path, 'standard'), device=device\n",
    ")\n",
    "standard_sae.eval()\n",
    "ssae = standard_sae['standard']\n",
    "\n",
    "model, gated_sae, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
    "    path = os.path.join(path, 'gated'), device=device\n",
    ")\n",
    "gated_sae.eval()\n",
    "gsae = gated_sae['gated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "def get_l0_dist(sae, key):\n",
    "    with torch.no_grad():\n",
    "        # activation store can give us tokens.\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "        # Use the SAE\n",
    "        sae_out, feature_acts, loss, mse_loss, l1_loss, *_ = sae[key](\n",
    "            cache[sae.cfg.hook_point]\n",
    "        )\n",
    "\n",
    "        # save some room\n",
    "        del cache\n",
    "\n",
    "        # ignore the bos token, get the number of features that activated in each token, averaged accross batch and position\n",
    "        l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "        print(f\"{key} average l0\", l0.mean().item())\n",
    "        return px.histogram(l0.flatten().cpu().numpy(), title=\"L0 norm distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "standard_l0_dist = get_l0_dist(standard_sae, 'standard')\n",
    "gated_l0_dist = get_l0_dist(gated_sae, 'gated')\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(standard_l0_dist.data[0], row=1, col=1)\n",
    "fig.add_trace(gated_l0_dist.data[0], row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"L0 Dist Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
