{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from sae_lens.training.config import LanguageModelSAERunnerConfig\n",
    "from sae_lens.training.lm_runner import language_model_sae_runner\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "model_name = \"tiny-stories-1L-21M\" #\"EleutherAI/pythia-2.8b\"\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    model_name\n",
    ")  # This will wrap huggingface models and has lots of nice utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'Once', ' upon', ' a', ' time', ',', ' there', ' was', ' a', ' little', ' girl', ' named', ' Lily', '.', ' She', ' lived', ' in', ' a', ' big', ',', ' happy', ' little', ' girl', '.', ' On', ' her', ' big', ' adventure', ',']\n",
      "Tokenized answer: [' Lily']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18.81</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.46</span><span style=\"font-weight: bold\">% Token: | Lily|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m18.81\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m13.46\u001b[0m\u001b[1m% Token: | Lily|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 20.48 Prob: 71.06% Token: | she|\n",
      "Top 1th token. Logit: 18.81 Prob: 13.46% Token: | Lily|\n",
      "Top 2th token. Logit: 17.35 Prob:  3.11% Token: | the|\n",
      "Top 3th token. Logit: 17.26 Prob:  2.86% Token: | her|\n",
      "Top 4th token. Logit: 16.74 Prob:  1.70% Token: | there|\n",
      "Top 5th token. Logit: 16.43 Prob:  1.25% Token: | they|\n",
      "Top 6th token. Logit: 15.80 Prob:  0.66% Token: | all|\n",
      "Top 7th token. Logit: 15.64 Prob:  0.56% Token: | things|\n",
      "Top 8th token. Logit: 15.28 Prob:  0.39% Token: | one|\n",
      "Top 9th token. Logit: 15.24 Prob:  0.38% Token: | lived|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Lily'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Lily'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "# Test the model with a prompt\n",
    "test_prompt(\n",
    "    \"Once upon a time, there was a little girl named Lily. She lived in a big, happy little girl. On her big adventure,\",\n",
    "    \" Lily\",\n",
    "    model,\n",
    "    prepend_space_to_answer=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-02eebbb5-ca4c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-02eebbb5-ca4c\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Hi\", \",\", \" how\", \" are\", \" you\", \" doing\", \" this\", \"?\", \" I\", \"'m\", \" really\", \" enjoying\", \" your\", \" posts\"], \"topKLogProbs\": [[-0.020237978547811508, -6.104498863220215, -7.070311546325684, -7.073490142822266, -7.178879737854004, -7.389684677124023, -7.525315284729004, -7.588573455810547, -7.763055801391602, -8.224309921264648], [-1.1883893013000488, -3.4683852195739746, -3.4808287620544434, -3.4896111488342285, -3.500030994415283, -3.554358959197998, -4.017881870269775, -4.030544757843018, -4.298159122467041, -4.418168544769287], [-2.9201290607452393, -3.379486322402954, -3.4266788959503174, -3.531764268875122, -3.956162691116333, -4.256065368652344, -4.443942070007324, -4.4448394775390625, -4.559991836547852, -4.583307266235352], [-0.9917522668838501, -2.928676128387451, -3.2575316429138184, -3.317981243133545, -3.4740567207336426, -3.6419081687927246, -3.8674941062927246, -3.868630886077881, -3.8917040824890137, -4.005284786224365], [-0.037123147398233414, -4.683361530303955, -4.9722676277160645, -5.854288578033447, -5.9421305656433105, -6.388034343719482, -6.3940815925598145, -6.498584270477295, -6.593432903289795, -7.8692545890808105], [-0.23486259579658508, -2.3354179859161377, -2.947497606277466, -5.052804470062256, -5.078576564788818, -5.102746486663818, -5.116313457489014, -5.737276554107666, -5.768456935882568, -5.893773555755615], [-0.44884783029556274, -2.076716423034668, -3.433588981628418, -3.645073890686035, -3.7033796310424805, -4.046278953552246, -4.097006797790527, -4.209780693054199, -4.518967628479004, -4.961886405944824], [-0.4609467387199402, -2.7377679347991943, -3.158902883529663, -3.686795949935913, -4.416429042816162, -4.448527812957764, -4.571945667266846, -4.669140338897705, -4.695371150970459, -4.748204708099365], [-0.9866101741790771, -1.8349759578704834, -2.460031270980835, -2.511583089828491, -3.1156270503997803, -3.419478178024292, -3.5203635692596436, -3.8049819469451904, -4.003089904785156, -4.258264541625977], [-1.3091926574707031, -1.633901596069336, -1.78680419921875, -2.631612777709961, -3.4602813720703125, -3.615842819213867, -4.020046234130859, -4.093286514282227, -4.177457809448242, -4.309240341186523], [-1.9952350854873657, -2.55653715133667, -2.645555019378662, -2.8948235511779785, -3.11043119430542, -3.3945651054382324, -3.7311148643493652, -3.8203349113464355, -3.967912197113037, -4.026367664337158], [-1.0431095361709595, -1.959466576576233, -3.0507731437683105, -3.4215006828308105, -3.48012113571167, -3.4898486137390137, -3.6020045280456543, -4.332496166229248, -4.492417812347412, -4.517611026763916], [-1.5123934745788574, -2.020272731781006, -2.22328519821167, -2.2493205070495605, -3.376523494720459, -3.92171049118042, -3.9798388481140137, -4.199243068695068, -4.265368938446045, -4.6615891456604], [-3.188736915588379, -3.192061424255371, -3.4252281188964844, -3.494192123413086, -3.7325897216796875, -3.7353057861328125, -3.735713005065918, -3.833963394165039, -4.233694076538086, -4.265708923339844]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\",\", \" Tim\", \" bird\", \"!\", \" little\", \" Lily\", \" Tom\", \"!\\\"\", \" Max\", \" tree\"], [\" cat\", \" a\", \" bird\", \" little\", \" I\", \"\\n\", \" dog\", \" but\", \" frog\", \" sw\"], [\" are\", \" I\", \" was\", \" do\", \" fast\", \" big\", \" did\", \" to\", \" he\", \" old\"], [\" you\", \" we\", \" they\", \" the\", \" Lily\", \" your\", \" I\", \" Tim\", \" friends\", \" those\"], [\"?\\\"\", \" today\", \"?\", \" and\", \".\", \",\", \" doing\", \" going\", \" up\", \"?\\\".\"], [\"?\\\"\", \" this\", \" today\", \"?\", \" here\", \" a\", \" it\", \" these\", \".\", \" in\"], [\"?\\\"\", \"?\", \" great\", \" so\", \" job\", \" puzzle\", \" task\", \" very\", \".\", \" amazing\"], [\"\\ufffd\", \" You\", \" I\", \" It\", \" We\", \" Can\", \"\\n\", \" This\", \" Do\", \" Are\"], [\"'m\", \" am\", \" want\", \" like\", \" know\", \" have\", \" love\", \" can\", \" just\", \" hope\"], [\" a\", \" so\", \" very\", \" trying\", \" going\", \" an\", \" looking\", \" just\", \" making\", \" playing\"], [\" good\", \" hungry\", \" enjoying\", \" a\", \" tired\", \" proud\", \" happy\", \" excited\", \" busy\", \" glad\"], [\" the\", \" it\", \" this\", \" my\", \" a\", \" your\", \" playing\", \" some\", \" these\", \" myself\"], [\" meal\", \" food\", \" day\", \" ice\", \" sandwich\", \" delicious\", \" new\", \" dance\", \" cake\", \" time\"]], \"correctTokenRank\": [1718, 0, 675, 0, 0, 6, 1, 1, 2, 0, 23, 2, 5, 10036], \"correctTokenLogProb\": [-13.814948081970215, -1.1883893013000488, -8.445575714111328, -0.9917522668838501, -0.037123147398233414, -5.116313457489014, -2.076716423034668, -2.7377679347991943, -2.460031270980835, -1.3091926574707031, -4.860561847686768, -3.0507731437683105, -3.92171049118042, -17.039505004882812]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f11ea993010>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
    "\n",
    "# Let's make a longer prompt and see the log probabilities of the tokens\n",
    "example_prompt = \"\"\"Hi, how are you doing this? I'm really enjoying your posts\"\"\"\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")\n",
    "# hover on the output to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a515e3e044f4285aaac8db5fea65f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-f1e66994-56f2\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-f1e66994-56f2\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<|endoftext|>\", \"Once\", \" upon\", \" a\", \" time\", \",\", \" there\", \" was\", \" a\", \" boy\", \" named\", \" Jack\", \".\", \" He\", \" had\", \" a\", \" toy\", \" sail\", \".\", \" The\", \" sail\", \"boat\", \" was\", \" struggling\", \" and\", \" it\", \" felt\", \" broken\", \".\", \" He\", \" went\", \" to\", \" the\", \" beach\", \" and\", \" waved\", \" to\", \" the\", \" sack\", \",\", \" but\", \" it\", \" stayed\", \" Jack\", \" and\", \" kept\", \" getting\", \" in\", \" the\", \" way\", \".\", \"\\n\", \"\\n\", \"Suddenly\", \",\", \" he\", \" saw\", \" another\", \" open\", \" bottle\", \".\", \" He\", \" was\", \" very\", \" excited\", \" and\", \" he\", \" quickly\", \" grabbed\", \" one\", \" out\", \" and\", \" tried\", \" to\", \" sail\", \" away\", \".\", \" But\", \" it\", \" was\", \" stuck\", \"!\", \" He\", \" tried\", \" to\", \" pull\", \" it\", \" out\", \" but\", \" it\", \" wouldn\", \"'t\", \" bud\", \"ge\", \".\", \" He\", \" started\", \" to\", \" complain\", \",\", \" \\\"\", \"Let\", \" Jenny\", \" try\", \" one\", \" more\", \" minute\", \",\", \" and\", \" then\", \" we\", \" will\", \" split\", \" it\", \" open\", \",\\\"\", \" he\", \" said\", \".\", \"\\n\", \"\\n\", \"J\", \"enny\", \" tried\", \" to\", \" open\", \" the\", \" sack\", \" anyway\", \",\", \" but\", \" it\", \" wouldn\", \"'t\", \" bud\", \"ge\", \".\", \" They\", \" argued\", \" for\", \" a\", \" minute\", \",\", \" until\", \" one\", \" of\", \" them\", \" finally\", \" gave\", \" up\", \".\", \" It\", \" split\", \" open\", \" and\", \" set\", \" them\", \" free\", \"!\", \" They\", \" were\", \" so\", \" excited\", \".\", \" \", \"\\n\", \"\\n\", \"The\", \" chase\", \" of\", \" Jenny\", \" and\", \" Jack\", \" snatched\", \" a\", \" sack\", \" from\", \" her\", \" and\", \" they\", \" took\", \" it\", \" out\", \" of\", \" the\", \" sack\", \" of\", \" crack\", \"ers\", \".\", \" \", \"\\n\", \"\\n\", \"The\", \" two\", \" friends\", \" split\", \" open\", \" the\", \" sack\", \" and\", \" found\", \" colourful\", \" pieces\", \" of\"], \"topKLogProbs\": [[-0.020237978547811508, -6.104497909545898, -7.070315361022949, -7.073488235473633, -7.1788787841796875, -7.389683723449707, -7.525317192077637, -7.5885772705078125, -7.763050079345703, -8.224308967590332], [-0.372489869594574, -1.827528953552246, -4.3061370849609375, -4.838803291320801, -4.989402770996094, -5.1117401123046875, -5.187068939208984, -5.250604629516602, -5.662858963012695, -5.694143295288086], [-0.005904730875045061, -5.495633602142334, -7.522153377532959, -8.207719802856445, -8.449649810791016, -8.90707778930664, -9.541242599487305, -9.691887855529785, -10.111766815185547, -10.492300033569336], [-0.011737688444554806, -6.031045913696289, -7.209378242492676, -7.243843078613281, -7.747928619384766, -7.977005958557129, -8.321712493896484, -8.35726547241211, -8.502359390258789, -8.701475143432617], [-0.1878184974193573, -1.8141651153564453, -5.624242782592773, -6.579645156860352, -7.822257995605469, -8.386683464050293, -8.49909496307373, -8.57803726196289, -8.823796272277832, -8.960565567016602], [-0.10250605642795563, -3.402726650238037, -3.946469783782959, -5.159356594085693, -5.411166667938232, -6.1134867668151855, -6.131921291351318, -6.200311183929443, -6.424906253814697, -7.0071539878845215], [-0.1382717341184616, -2.544334888458252, -3.050598621368408, -7.775615215301514, -8.049697875976562, -8.075815200805664, -8.107090950012207, -8.183040618896484, -8.868163108825684, -8.878026962280273], [-0.0321299247443676, -3.6293933391571045, -7.695366382598877, -7.812208652496338, -7.8907952308654785, -8.088072776794434, -8.26425552368164, -9.077349662780762, -9.536680221557617, -9.683252334594727], [-1.843049168586731, -2.4128103256225586, -2.9644947052001953, -3.615971565246582, -4.061753273010254, -4.090791702270508, -4.206696510314941, -4.35806941986084, -4.626364707946777, -4.680699348449707], [-0.6622740030288696, -1.520332932472229, -1.9663130044937134, -2.4271397590637207, -3.896627902984619, -5.384399890899658, -5.681784152984619, -6.174414157867432, -6.669332981109619, -7.449211597442627], [-1.5416234731674194, -2.2549586296081543, -2.4379515647888184, -2.5763354301452637, -2.779222011566162, -3.0478720664978027, -3.200364589691162, -3.5621161460876465, -3.730983257293701, -3.760758876800537], [-0.1681029349565506, -2.0431830883026123, -4.236788272857666, -5.541414737701416, -5.966976642608643, -6.533712863922119, -7.855257511138916, -8.123698234558105, -8.299535751342773, -9.012740135192871], [-0.46368974447250366, -1.2546272277832031, -3.7381649017333984, -4.689929962158203, -5.011028289794922, -5.097517013549805, -5.7707719802856445, -5.812961578369141, -5.946718215942383, -6.13825798034668], [-0.6653797030448914, -1.8203518390655518, -2.3646175861358643, -2.4618923664093018, -2.658404588699341, -3.3033268451690674, -4.775996208190918, -5.267500877380371, -6.041424751281738, -6.715685844421387], [-0.2179473340511322, -2.994804620742798, -3.2292425632476807, -3.9375250339508057, -4.368462085723877, -4.481926441192627, -4.720535755157471, -5.548621654510498, -5.655529499053955, -5.717911243438721], [-2.0361571311950684, -2.1998724937438965, -2.6203436851501465, -3.575500011444092, -3.8212389945983887, -3.981177806854248, -4.225039005279541, -4.337863445281982, -4.367166042327881, -4.390383243560791], [-0.9655255079269409, -2.6970911026000977, -3.02573299407959, -3.0813379287719727, -3.2428369522094727, -3.386845588684082, -3.820185661315918, -4.020718574523926, -4.234800338745117, -4.399458885192871], [-0.839320719242096, -1.54664945602417, -1.7438406944274902, -2.7049059867858887, -3.3671507835388184, -3.5564799308776855, -4.392899990081787, -4.456563472747803, -5.730519771575928, -5.828582286834717], [-0.4898378849029541, -2.06386399269104, -2.808626413345337, -2.9872725009918213, -3.0976850986480713, -3.4115488529205322, -3.758558511734009, -5.026762008666992, -5.785970687866211, -5.874408721923828], [-0.22709661722183228, -2.5695056915283203, -3.1585445404052734, -4.454557418823242, -5.195947647094727, -5.444559097290039, -5.612953186035156, -5.631766319274902, -5.868577003479004, -6.000304222106934], [-0.8264817595481873, -0.8340997099876404, -4.214560508728027, -4.450737953186035, -4.8565778732299805, -5.15187931060791, -5.256888389587402, -5.357300758361816, -5.383469581604004, -5.3874006271362305], [-0.18225006759166718, -2.7994089126586914, -4.204119682312012, -4.3823137283325195, -4.586703300476074, -4.831671714782715, -5.044461250305176, -5.263007164001465, -5.554844856262207, -5.753842353820801], [-2.089587926864624, -2.3178651332855225, -2.820932149887085, -2.9035680294036865, -3.224210500717163, -3.535539388656616, -3.5517518520355225, -3.645589590072632, -3.871724843978882, -3.896075963973999], [-0.8178844451904297, -1.956502914428711, -2.099180221557617, -2.220285415649414, -2.9371109008789062, -3.2884769439697266, -3.668977737426758, -4.199588775634766, -4.5590667724609375, -5.454519271850586], [-1.3284074068069458, -2.0479183197021484, -2.8491439819335938, -2.9536209106445312, -3.0508604049682617, -3.471409797668457, -3.61984920501709, -3.7098236083984375, -3.8727846145629883, -4.09852409362793], [-0.8763755559921265, -2.135075092315674, -2.707033634185791, -2.9409260749816895, -3.5637059211730957, -4.049004077911377, -4.108707904815674, -4.176697254180908, -4.241793155670166, -4.274099826812744], [-1.827170729637146, -2.431914806365967, -2.706050395965576, -3.1664633750915527, -3.1808390617370605, -3.5131258964538574, -3.5276331901550293, -3.6353487968444824, -3.738643169403076, -3.795222759246826], [-0.21257247030735016, -2.225983142852783, -3.7011170387268066, -4.340147495269775, -4.871443271636963, -5.201334476470947, -5.722958087921143, -5.945898532867432, -5.982740879058838, -6.209822177886963], [-0.6662067174911499, -1.6757053136825562, -2.498260974884033, -2.7449631690979004, -3.784729480743408, -4.119297504425049, -4.742424488067627, -4.805496692657471, -4.970554828643799, -5.095692157745361], [-1.212861180305481, -1.9690829515457153, -2.732405662536621, -2.922471046447754, -2.9423742294311523, -3.0088281631469727, -3.0182714462280273, -3.589505195617676, -3.795842170715332, -3.838780403137207], [-0.2939232289791107, -3.0834128856658936, -3.570751905441284, -3.8073699474334717, -3.873873472213745, -4.389029502868652, -4.485894203186035, -4.498791694641113, -4.850415229797363, -4.933533668518066], [-0.6799303293228149, -1.5412508249282837, -3.382082462310791, -3.6673874855041504, -3.692476749420166, -3.7274670600891113, -3.8508172035217285, -4.142706394195557, -4.199429035186768, -4.244940280914307], [-1.9136321544647217, -2.0637214183807373, -2.353745222091675, -2.625014066696167, -2.8666465282440186, -3.297600507736206, -3.50940203666687, -3.6429336071014404, -3.6449124813079834, -3.7304112911224365], [-0.919985294342041, -1.143761157989502, -2.1409268379211426, -2.935842990875244, -3.404837131500244, -3.7961525917053223, -5.1575703620910645, -5.4122395515441895, -5.6125054359436035, -5.671518802642822], [-1.9119302034378052, -2.104053497314453, -2.3409061431884766, -3.033580780029297, -3.0861892700195312, -3.122417449951172, -3.4833145141601562, -3.5709495544433594, -3.714672088623047, -3.771564483642578], [-0.670299768447876, -1.7657606601715088, -1.9701063632965088, -2.551950693130493, -3.9769327640533447, -4.03748893737793, -4.24690055847168, -4.798084259033203, -4.882970809936523, -5.207944869995117], [-0.39927276968955994, -1.9701536893844604, -3.3414971828460693, -3.362994909286499, -3.3708035945892334, -3.8596818447113037, -4.458864212036133, -4.891468048095703, -5.367607116699219, -5.432220458984375], [-1.4213217496871948, -2.11260986328125, -2.59039306640625, -3.0645065307617188, -3.313028335571289, -3.3471908569335938, -3.376424789428711, -3.7882232666015625, -3.8177480697631836, -4.000765800476074], [-0.730599582195282, -2.211138963699341, -2.7364742755889893, -3.110461473464966, -3.1191933155059814, -3.1887447834014893, -3.4162418842315674, -3.503932237625122, -3.5125839710235596, -4.177994728088379], [-0.8046091198921204, -1.4820821285247803, -2.45670485496521, -3.5124948024749756, -3.7364156246185303, -3.887897253036499, -4.018045425415039, -4.668304443359375, -4.714031219482422, -4.773244857788086], [-1.5585801601409912, -1.7450978755950928, -1.8903443813323975, -2.119107961654663, -2.1578118801116943, -3.2648770809173584, -4.224090576171875, -4.229047775268555, -4.266300201416016, -4.314126968383789], [-1.1167328357696533, -1.484208345413208, -2.3518078327178955, -2.9175941944122314, -3.159571886062622, -3.202002763748169, -3.564162492752075, -3.5872414112091064, -4.480557441711426, -4.5734758377075195], [-1.0765970945358276, -3.029378890991211, -3.0397071838378906, -3.1380538940429688, -3.221647262573242, -3.2894229888916016, -3.2988338470458984, -3.3619651794433594, -3.8171539306640625, -3.882966995239258], [-0.996981143951416, -1.7428669929504395, -2.5591187477111816, -2.7178425788879395, -4.043371677398682, -4.186770915985107, -4.349116802215576, -4.406483173370361, -4.433713436126709, -4.656446933746338], [-1.5188981294631958, -2.3955650329589844, -2.4488067626953125, -2.7866744995117188, -3.1265602111816406, -3.2726001739501953, -3.405019760131836, -3.480010986328125, -3.52313232421875, -3.7058143615722656], [-1.3530505895614624, -2.052786350250244, -2.6765904426574707, -2.747044086456299, -3.2512974739074707, -3.296905994415283, -3.357861042022705, -3.537855625152588, -3.757507801055908, -3.7622647285461426], [-1.8147063255310059, -1.8750395774841309, -2.580867290496826, -2.9508261680603027, -3.3575491905212402, -3.4500765800476074, -3.577239513397217, -3.596475124359131, -3.598784923553467, -3.6880850791931152], [-0.9960278868675232, -1.6460447311401367, -1.9207830429077148, -2.369593620300293, -2.678704261779785, -3.6350088119506836, -4.632113456726074, -5.356265068054199, -5.399008750915527, -5.439268112182617], [-1.0580132007598877, -1.4884846210479736, -2.357173204421997, -2.623582124710083, -2.714932680130005, -3.4156219959259033, -4.085976600646973, -4.325737953186035, -4.5504350662231445, -4.615120887756348], [-0.0612158365547657, -4.2068610191345215, -4.799193859100342, -4.889443874359131, -5.7226176261901855, -5.864211559295654, -5.868855953216553, -6.045947551727295, -6.71094274520874, -6.793647289276123], [-0.5061531066894531, -1.9426002502441406, -2.1063461303710938, -4.164838790893555, -4.276317596435547, -4.386362075805664, -4.591642379760742, -4.67601203918457, -4.781030654907227, -4.833463668823242], [-0.014467342756688595, -6.062286376953125, -6.231910705566406, -6.412630081176758, -6.725667953491211, -6.8337249755859375, -6.934110641479492, -7.46762752532959, -7.589747428894043, -7.591108322143555], [-1.904248833656311, -2.19002103805542, -2.2005515098571777, -2.322495937347412, -2.3467459678649902, -2.732461452484131, -2.7753024101257324, -2.934394359588623, -2.937671184539795, -3.5613722801208496], [-0.06192167475819588, -3.9154295921325684, -4.233582973480225, -4.699307918548584, -5.051864147186279, -5.909951686859131, -6.22963285446167, -6.74146032333374, -7.103450298309326, -7.1765456199646], [-1.2472119331359863, -1.3236603736877441, -1.7007927894592285, -2.028341770172119, -3.75144624710083, -3.927673816680908, -4.03576135635376, -4.063112735748291, -4.371431827545166, -4.598463535308838], [-0.5834070444107056, -1.3692022562026978, -3.2708115577697754, -3.402468204498291, -3.626671314239502, -4.061800479888916, -4.077978610992432, -5.000975131988525, -5.079695224761963, -5.099489688873291], [-0.2947913408279419, -2.046463966369629, -3.133418083190918, -4.0620832443237305, -4.452353477478027, -4.457026481628418, -4.514571189880371, -4.616677284240723, -5.106877326965332, -5.734997749328613], [-1.4295345544815063, -1.4970661401748657, -1.8034454584121704, -2.661048412322998, -2.8110175132751465, -3.963164806365967, -4.129628658294678, -4.329204082489014, -4.768420696258545, -4.776181697845459], [-1.4789938926696777, -2.0047659873962402, -2.4140048027038574, -3.1740736961364746, -3.2893271446228027, -3.297534465789795, -3.4650588035583496, -3.6247029304504395, -3.798161029815674, -3.918801784515381], [-1.0232428312301636, -1.482456088066101, -2.6451892852783203, -2.862882614135742, -2.889781951904297, -2.9914932250976562, -3.731473922729492, -3.7968006134033203, -4.328025817871094, -4.472715377807617], [-0.6135923266410828, -1.522451639175415, -2.791818857192993, -3.357818841934204, -3.4609663486480713, -3.6876604557037354, -3.853161096572876, -4.9457244873046875, -5.219679832458496, -5.459338188171387], [-2.1453137397766113, -2.7276463508605957, -2.785727024078369, -2.7940621376037598, -3.113224506378174, -3.253389835357666, -3.267988681793213, -3.343559741973877, -3.4631104469299316, -3.5059704780578613], [-1.302513837814331, -1.8376262187957764, -2.284712553024292, -2.8017470836639404, -3.250868558883667, -4.147801399230957, -4.170901298522949, -4.1898393630981445, -4.275778770446777, -4.295535087585449], [-1.0018718242645264, -1.3357512950897217, -2.6783034801483154, -3.1840484142303467, -3.978426694869995, -4.150328636169434, -4.171109199523926, -4.336010932922363, -4.457406044006348, -4.547823905944824], [-0.5399669408798218, -1.6360896825790405, -2.445194721221924, -2.6591286659240723, -3.596924304962158, -4.21799898147583, -5.41782808303833, -5.559086322784424, -5.779465198516846, -6.021015644073486], [-1.1068181991577148, -2.3304529190063477, -2.461520195007324, -2.9749860763549805, -3.1261892318725586, -3.384701728820801, -3.675858497619629, -3.6862401962280273, -3.749972343444824, -3.8173742294311523], [-1.5847547054290771, -2.4699113368988037, -2.6409223079681396, -2.729337453842163, -2.9796102046966553, -3.194211721420288, -3.5516583919525146, -3.5739686489105225, -3.5753591060638428, -3.58939528465271], [-0.8361993432044983, -1.7614178657531738, -2.3421883583068848, -3.358084201812744, -3.8828701972961426, -3.9182114601135254, -4.008200168609619, -4.265955448150635, -4.490959644317627, -4.504665851593018], [-0.24005769193172455, -1.7198359966278076, -4.60281229019165, -5.174391269683838, -5.188108921051025, -5.607000827789307, -5.812929630279541, -6.514997959136963, -7.10155725479126, -7.451719760894775], [-0.5099654197692871, -1.3742671012878418, -3.443175792694092, -3.7200121879577637, -3.882140636444092, -4.238940715789795, -4.877288341522217, -4.997985363006592, -5.65565824508667, -5.815396785736084], [-0.42343035340309143, -1.5081051588058472, -3.529046058654785, -3.769637107849121, -3.9326791763305664, -4.150816917419434, -5.037631034851074, -5.121474266052246, -5.229098320007324, -5.929913520812988], [-1.4279223680496216, -1.9843417406082153, -2.3224706649780273, -2.398503303527832, -2.860325813293457, -3.2940378189086914, -3.4199628829956055, -3.5087594985961914, -3.768742561340332, -4.057562828063965], [-0.09658709168434143, -2.9570741653442383, -4.736666679382324, -5.196022987365723, -5.681618690490723, -5.8561906814575195, -6.080903053283691, -6.389805793762207, -6.983054161071777, -7.019665718078613], [-1.072587013244629, -2.7488832473754883, -2.808260917663574, -2.8622007369995117, -2.9477148056030273, -3.5439748764038086, -3.570784568786621, -3.669583320617676, -3.867722511291504, -4.011031150817871], [-1.1216830015182495, -1.281326174736023, -1.785495638847351, -2.327892303466797, -4.248630523681641, -4.43235969543457, -4.681436538696289, -4.706357955932617, -4.927900314331055, -5.039302825927734], [-0.233905628323555, -2.982228994369507, -2.9970853328704834, -3.414541006088257, -3.8272664546966553, -4.913078308105469, -5.140584945678711, -5.195308685302734, -5.685447692871094, -5.715764999389648], [-0.8066551685333252, -1.4353020191192627, -2.831599473953247, -3.2651894092559814, -3.291142702102661, -3.5208141803741455, -4.213387489318848, -4.248379707336426, -4.422884941101074, -4.449173927307129], [-0.9593029022216797, -1.2686195373535156, -2.495189666748047, -2.8455810546875, -3.5396461486816406, -3.794483184814453, -4.054950714111328, -4.173088073730469, -4.195817947387695, -4.2971038818359375], [-0.21141986548900604, -2.416105031967163, -3.7306840419769287, -4.4864654541015625, -4.569608688354492, -5.342884063720703, -5.7318267822265625, -5.844709396362305, -5.894021987915039, -5.908821105957031], [-0.2447229027748108, -2.4943528175354004, -3.084747791290283, -4.432804584503174, -4.5489888191223145, -4.618654727935791, -4.974804401397705, -5.033270359039307, -5.219961643218994, -5.487276554107666], [-1.2537198066711426, -1.2809205055236816, -1.6484322547912598, -2.7811379432678223, -3.5540852546691895, -3.714184284210205, -3.865187168121338, -4.235392093658447, -4.311367511749268, -4.635563373565674], [-0.8683459758758545, -1.1902873516082764, -2.6292712688446045, -2.782789945602417, -4.417168617248535, -4.521344184875488, -4.559975624084473, -4.5749711990356445, -4.616274833679199, -4.851849555969238], [-1.5421781539916992, -1.997227668762207, -2.62479305267334, -2.647149085998535, -3.012578010559082, -3.381951332092285, -3.394089698791504, -3.426323890686035, -3.4773435592651367, -3.7692041397094727], [-0.40588369965553284, -1.4352091550827026, -3.743715286254883, -4.313543319702148, -5.013204574584961, -5.018381118774414, -5.096929550170898, -5.757850646972656, -5.833354949951172, -5.869558334350586], [-1.3710194826126099, -2.1433868408203125, -2.192564010620117, -2.5515708923339844, -3.146352767944336, -3.2514572143554688, -3.4056854248046875, -3.6502819061279297, -3.8407344818115234, -3.8684539794921875], [-0.29757070541381836, -2.1859030723571777, -3.1838126182556152, -3.8988356590270996, -4.280446529388428, -4.395883083343506, -4.432824611663818, -5.181962490081787, -5.411473751068115, -5.651973247528076], [-0.47833946347236633, -2.35455060005188, -2.562953233718872, -3.2468388080596924, -3.3755905628204346, -3.5226337909698486, -4.157342433929443, -4.2889227867126465, -4.379310131072998, -4.926537990570068], [-0.5107041597366333, -1.3295480012893677, -3.017599105834961, -3.2133140563964844, -4.754127502441406, -4.813116073608398, -5.14178466796875, -5.525547027587891, -5.833545684814453, -5.852558135986328], [-0.16531595587730408, -2.5929815769195557, -3.1620123386383057, -4.42937707901001, -5.040266513824463, -5.347914218902588, -6.423166751861572, -6.58848237991333, -7.207685947418213, -7.257744312286377], [-0.3240576684474945, -1.5372248888015747, -4.129284858703613, -4.644532203674316, -4.844681739807129, -5.573124885559082, -5.745684623718262, -5.990700721740723, -6.057997703552246, -6.085310935974121], [-0.012859278358519077, -4.409940719604492, -8.813573837280273, -9.494848251342773, -9.554830551147461, -9.634061813354492, -10.373449325561523, -10.418521881103516, -10.489723205566406, -11.239303588867188], [-0.3687290549278259, -2.1402344703674316, -2.5128331184387207, -3.2510037422180176, -3.9332470893859863, -4.889101505279541, -5.000097751617432, -5.067917346954346, -5.129795551300049, -5.440365314483643], [-9.60780744208023e-05, -9.73155689239502, -10.971917152404785, -12.611088752746582, -12.915907859802246, -13.231308937072754, -13.628212928771973, -13.745150566101074, -14.06110668182373, -14.0883150100708], [-0.010634183883666992, -4.7816667556762695, -7.408839225769043, -7.885741233825684, -8.03861141204834, -8.734143257141113, -9.29314136505127, -9.31295108795166, -9.458672523498535, -9.701333045959473], [-0.7598627805709839, -1.4955366849899292, -2.5016326904296875, -2.518817901611328, -2.924379348754883, -3.876209259033203, -4.727176666259766, -4.804773330688477, -5.175285339355469, -5.256377220153809], [-1.102856993675232, -1.4547170400619507, -3.1019206047058105, -3.3447985649108887, -3.6097731590270996, -3.721818447113037, -3.9636893272399902, -3.9972357749938965, -4.058589458465576, -4.099315166473389], [-0.021869802847504616, -5.173913955688477, -5.36760139465332, -7.1189422607421875, -7.124170303344727, -7.256368637084961, -7.304788589477539, -7.488788604736328, -7.61834716796875, -7.969440460205078], [-0.6190434098243713, -1.9076614379882812, -2.159505844116211, -2.7331466674804688, -3.7744083404541016, -3.9357051849365234, -4.284168243408203, -4.5507659912109375, -5.20155143737793, -5.401338577270508], [-1.2895005941390991, -1.5746606588363647, -1.5772393941879272, -1.7770131826400757, -3.4205336570739746, -4.225427150726318, -4.31308126449585, -4.350095272064209, -4.481303691864014, -4.9336676597595215], [-0.5218283534049988, -1.975926160812378, -2.731396436691284, -3.3400142192840576, -4.048738956451416, -4.179962635040283, -4.204334735870361, -4.621534824371338, -4.796633243560791, -4.84580659866333], [-1.8282638788223267, -1.997113823890686, -2.0222487449645996, -2.3221182823181152, -2.355252742767334, -2.5118021965026855, -3.463622570037842, -3.563506603240967, -3.573432445526123, -3.7865843772888184], [-0.547157883644104, -1.2186113595962524, -2.5512356758117676, -4.3873066902160645, -4.909338474273682, -5.608200550079346, -5.708350658416748, -5.932844638824463, -7.109951496124268, -7.294020175933838], [-1.6510953903198242, -1.6545705795288086, -1.8433809280395508, -2.7305898666381836, -2.8519468307495117, -3.079817771911621, -3.360579490661621, -3.364720344543457, -3.6090879440307617, -3.8129377365112305], [-1.5187532901763916, -1.7664721012115479, -2.389171838760376, -2.6355459690093994, -2.839845895767212, -2.9354288578033447, -3.0094873905181885, -3.4188120365142822, -3.876678705215454, -4.325830459594727], [-0.13953861594200134, -2.5038211345672607, -5.3886919021606445, -5.42995548248291, -5.453761100769043, -6.184239387512207, -6.459198951721191, -6.516912460327148, -6.519112586975098, -6.523409843444824], [-0.39512091875076294, -3.728365182876587, -3.7439844608306885, -4.198654651641846, -4.296566486358643, -4.355346202850342, -4.609028339385986, -4.755903720855713, -4.760141849517822, -4.785913944244385], [-1.5672738552093506, -1.729581594467163, -1.8645341396331787, -2.2836148738861084, -2.354875326156616, -2.430959463119507, -3.2563626766204834, -3.578735113143921, -3.828172445297241, -3.850942373275757], [-1.5149279832839966, -1.7617465257644653, -2.515467643737793, -2.8030595779418945, -2.820733070373535, -3.224541664123535, -3.266293525695801, -3.298975944519043, -3.340926170349121, -3.3466339111328125], [-1.1652450561523438, -1.3769397735595703, -1.6301136016845703, -3.2723388671875, -3.5169830322265625, -3.5300445556640625, -4.061124801635742, -4.430643081665039, -4.574159622192383, -5.055676460266113], [-1.1282286643981934, -1.7936186790466309, -2.4344935417175293, -2.445573329925537, -2.828691005706787, -3.227342128753662, -3.8770995140075684, -4.131961345672607, -4.185384273529053, -4.416187763214111], [-0.8695288896560669, -0.8727637529373169, -2.805985450744629, -4.220545768737793, -4.6305341720581055, -4.996524810791016, -5.028576850891113, -5.193471908569336, -5.6604461669921875, -5.788212776184082], [-1.7211987972259521, -2.0501744747161865, -2.6514298915863037, -2.8864858150482178, -3.113351583480835, -3.4162919521331787, -3.598172903060913, -3.6651322841644287, -3.6970765590667725, -3.762956380844116], [-0.869734525680542, -0.9891326427459717, -2.3914763927459717, -3.889979124069214, -4.208828926086426, -4.818230628967285, -4.902396202087402, -5.128596305847168, -5.469714164733887, -5.519997596740723], [-0.8247092366218567, -1.7806341648101807, -2.09944748878479, -2.652172327041626, -4.040350437164307, -4.12182092666626, -4.211308002471924, -4.312744617462158, -4.477579593658447, -4.598402500152588], [-1.2867964506149292, -1.3958262205123901, -2.0324668884277344, -2.211515426635742, -3.068513870239258, -3.1984195709228516, -3.684070587158203, -3.729330062866211, -4.323293685913086, -4.93096923828125], [-0.24715906381607056, -2.0317506790161133, -3.55275821685791, -3.8471384048461914, -4.6493120193481445, -4.871212959289551, -5.925293922424316, -6.133854866027832, -6.51637077331543, -6.529170036315918], [-0.09245855361223221, -3.36387038230896, -4.757352828979492, -4.837568283081055, -5.026084899902344, -6.199445724487305, -6.380393981933594, -6.408184051513672, -6.411251068115234, -6.437265396118164], [-0.14069277048110962, -3.4085779190063477, -3.617600440979004, -4.149069786071777, -4.393988609313965, -4.956671714782715, -5.608424186706543, -5.7292890548706055, -5.782927513122559, -6.019627571105957], [-0.2908884584903717, -2.0209949016571045, -3.8815486431121826, -3.888880491256714, -3.9310081005096436, -4.68688440322876, -5.051657199859619, -5.052481174468994, -5.094223499298096, -5.57395601272583], [-0.01255407091230154, -5.257455825805664, -6.036632537841797, -6.808074951171875, -6.808515548706055, -7.95611572265625, -8.059707641601562, -8.448258399963379, -8.6166410446167, -8.8341064453125], [-1.4397013187408447, -1.5455858707427979, -1.5780088901519775, -2.7035601139068604, -3.160240411758423, -3.2820913791656494, -3.3243372440338135, -3.7047579288482666, -4.5156402587890625, -4.581512451171875], [-0.001374729792587459, -6.857274532318115, -10.168747901916504, -10.949658393859863, -11.183244705200195, -11.260212898254395, -11.631317138671875, -11.693964004516602, -11.79383373260498, -11.801090240478516], [-1.2811031341552734, -2.321126937866211, -2.5466060638427734, -2.7370738983154297, -2.965818405151367, -3.571523666381836, -3.614480972290039, -3.6571693420410156, -3.683816909790039, -4.055891036987305], [-1.451838493347168, -1.744795799255371, -2.3921709060668945, -2.4096899032592773, -3.0251474380493164, -3.277998924255371, -3.872626304626465, -4.167543411254883, -4.306244850158691, -4.306436538696289], [-1.6868748664855957, -2.3272461891174316, -2.889164447784424, -2.9251580238342285, -3.147594928741455, -3.1972222328186035, -3.2606968879699707, -3.459646701812744, -3.493443012237549, -3.6715283393859863], [-0.071550153195858, -2.993274450302124, -5.298131942749023, -6.102949142456055, -6.195882797241211, -6.488777160644531, -6.659488677978516, -7.060905456542969, -7.470310211181641, -7.663470268249512], [-1.076019287109375, -1.2599620819091797, -3.022296905517578, -3.2420921325683594, -3.307069778442383, -3.451751708984375, -3.467409133911133, -4.317262649536133, -5.030769348144531, -5.040355682373047], [-0.7239741086959839, -1.4667376279830933, -2.328878402709961, -2.860231399536133, -3.194803237915039, -3.6439895629882812, -4.15644645690918, -4.764528274536133, -5.580595016479492, -5.72882080078125], [-0.48842698335647583, -1.8365447521209717, -1.9622867107391357, -2.5269668102264404, -6.483094215393066, -6.919005393981934, -7.167588233947754, -7.305394172668457, -7.899319648742676, -8.528334617614746], [-0.09752276539802551, -2.613941192626953, -5.395977020263672, -6.3938751220703125, -6.626605987548828, -6.8345794677734375, -7.027858734130859, -7.271759033203125, -7.612791061401367, -7.798076629638672], [-0.10213370621204376, -3.5252294540405273, -3.931746482849121, -3.945864677429199, -4.682223320007324, -6.3017683029174805, -6.459166526794434, -6.8397321701049805, -6.8891096115112305, -7.056696891784668], [-0.45929741859436035, -1.6529886722564697, -2.8211863040924072, -4.210357666015625, -4.259700775146484, -4.424022674560547, -4.53724479675293, -4.711006164550781, -4.848745346069336, -4.932943344116211], [-0.001865553087554872, -6.365652084350586, -11.039163589477539, -11.109472274780273, -11.506908416748047, -11.56356143951416, -11.609329223632812, -11.680702209472656, -11.812640190124512, -12.091650009155273], [-0.24320362508296967, -2.2985339164733887, -3.3650755882263184, -4.135392665863037, -4.234071254730225, -4.7483954429626465, -5.399989604949951, -5.413035869598389, -5.6675944328308105, -5.761315822601318], [-7.819823804311454e-05, -10.193204879760742, -11.117504119873047, -11.306529998779297, -12.770126342773438, -13.22806167602539, -13.381296157836914, -13.628061294555664, -14.352340698242188, -14.942314147949219], [-0.0336938351392746, -3.593590259552002, -6.369436740875244, -6.980112552642822, -7.247215747833252, -7.643051624298096, -7.687574863433838, -7.92997407913208, -9.408463478088379, -9.652670860290527], [-1.2858657836914062, -1.8376655578613281, -2.2591781616210938, -2.3671951293945312, -2.648214340209961, -3.119892120361328, -3.2874488830566406, -3.43994140625, -3.480104446411133, -3.819559097290039], [-1.320392370223999, -1.3945767879486084, -2.52182936668396, -3.2218244075775146, -3.3218533992767334, -3.8158490657806396, -3.999591588973999, -4.158420562744141, -4.166265487670898, -4.187807083129883], [-0.47219616174697876, -1.5031180381774902, -3.245408535003662, -3.4654994010925293, -3.7035651206970215, -3.844316005706787, -5.166179180145264, -5.2136969566345215, -5.373738765716553, -5.987046718597412], [-0.07215513288974762, -4.059593200683594, -4.910808563232422, -4.915241241455078, -5.03968620300293, -5.363368988037109, -5.604940414428711, -5.925464630126953, -6.000856399536133, -6.056613922119141], [-0.8716135025024414, -1.597762107849121, -1.7360906600952148, -2.462986946105957, -2.5972490310668945, -3.9263696670532227, -4.463290214538574, -5.728411674499512, -6.325757026672363, -6.880862236022949], [-0.5735659599304199, -1.8686442375183105, -2.036708354949951, -2.1277823448181152, -4.601853847503662, -5.758431911468506, -5.8723273277282715, -6.2618231773376465, -6.526973247528076, -7.057113170623779], [-0.9814082980155945, -1.2127525806427002, -1.760117769241333, -2.482367753982544, -5.189379692077637, -5.224339485168457, -5.492962837219238, -5.630470275878906, -5.699490547180176, -5.848073959350586], [-0.6767104268074036, -2.0229074954986572, -2.691419839859009, -2.9499990940093994, -2.9928762912750244, -3.086784601211548, -3.2552053928375244, -3.396951913833618, -4.346052646636963, -4.630486011505127], [-0.722653865814209, -1.6702666282653809, -2.3648734092712402, -2.5166220664978027, -4.357625484466553, -4.387486934661865, -4.669877529144287, -4.7551398277282715, -5.218761920928955, -5.488419055938721], [-0.4017976224422455, -1.5533345937728882, -2.7871830463409424, -4.036744594573975, -5.2349371910095215, -5.249379634857178, -5.73646879196167, -5.921050548553467, -6.146729946136475, -6.545193195343018], [-0.9812257289886475, -2.1682889461517334, -2.444335699081421, -3.0635812282562256, -3.328246831893921, -3.393636465072632, -3.5543363094329834, -3.6153295040130615, -3.746049642562866, -4.153643608093262], [-1.3164817094802856, -2.103461265563965, -2.2025957107543945, -2.341214179992676, -2.559786796569824, -3.177016258239746, -3.458611488342285, -4.158791542053223, -4.264020919799805, -4.37553596496582], [-0.8448961973190308, -0.9003943204879761, -2.9546642303466797, -3.6776809692382812, -4.08271598815918, -4.207544326782227, -4.631925582885742, -4.772012710571289, -4.909523010253906, -5.871919631958008], [-0.4761863350868225, -1.130826473236084, -4.363101482391357, -5.01715612411499, -5.511815547943115, -5.675059795379639, -5.978745937347412, -6.115591526031494, -6.35375452041626, -6.410867214202881], [-2.0132555961608887, -2.101682186126709, -2.1205248832702637, -2.1228556632995605, -2.275498867034912, -2.3320765495300293, -3.29982328414917, -3.696805477142334, -3.7828898429870605, -4.021053791046143], [-0.177988201379776, -3.5368940830230713, -4.277318954467773, -4.610620498657227, -4.79461669921875, -4.821453094482422, -4.9769134521484375, -4.9797821044921875, -5.106529235839844, -5.167245864868164], [-0.39351677894592285, -2.384371042251587, -2.439554452896118, -3.5820791721343994, -4.343513488769531, -4.554231643676758, -4.973869323730469, -5.053445816040039, -5.054330825805664, -5.215875625610352], [-0.9448423385620117, -1.8324308395385742, -2.039156913757324, -2.4153966903686523, -3.024897575378418, -3.1562910079956055, -3.7740564346313477, -3.9997053146362305, -4.499075889587402, -4.851263999938965], [-1.1495716571807861, -1.9609692096710205, -2.3283474445343018, -2.5894997119903564, -3.5499727725982666, -3.9354145526885986, -4.253582954406738, -4.307723045349121, -4.390646934509277, -4.547479629516602], [-0.5599991083145142, -2.678130626678467, -2.7103915214538574, -2.9720282554626465, -3.0946669578552246, -3.268540859222412, -3.435206890106201, -3.767800807952881, -3.844897747039795, -4.249557018280029], [-1.2244900465011597, -2.021122932434082, -2.329888343811035, -2.416775703430176, -2.662356376647949, -3.1682825088500977, -3.5857725143432617, -3.7554407119750977, -3.8422746658325195, -3.8423070907592773], [-0.350106805562973, -1.703595757484436, -2.6836562156677246, -5.023738384246826, -5.283471584320068, -5.2962565422058105, -5.724603176116943, -6.119893550872803, -6.260804653167725, -6.322268962860107], [-0.4887368083000183, -1.5536363124847412, -2.9825685024261475, -3.4152867794036865, -3.782499074935913, -4.276967525482178, -5.156482219696045, -5.431779384613037, -5.446231365203857, -5.492448329925537], [-0.4624500870704651, -2.2654953002929688, -3.4202747344970703, -3.6457443237304688, -4.000150680541992, -4.040121078491211, -4.074583053588867, -4.13359260559082, -4.518106460571289, -4.520477294921875], [-0.17612281441688538, -2.499380350112915, -3.4049017429351807, -4.317615509033203, -5.566408157348633, -5.613533020019531, -5.684181213378906, -6.074195861816406, -6.462789535522461, -6.518117904663086], [-0.557892918586731, -1.277457356452942, -3.052311897277832, -3.7087793350219727, -4.100462913513184, -4.579411506652832, -4.621884346008301, -5.089936256408691, -5.184828758239746, -5.547442436218262], [-1.029655933380127, -1.09501314163208, -2.261864185333252, -2.624271869659424, -2.895369052886963, -3.61790132522583, -4.23746919631958, -4.980705738067627, -5.064907550811768, -5.32023286819458], [-0.36712905764579773, -2.481966733932495, -2.6065948009490967, -3.321465253829956, -3.62048602104187, -4.170923709869385, -4.179579257965088, -4.932386875152588, -5.3044304847717285, -5.4063286781311035], [-0.0015544723719358444, -7.613630294799805, -7.881364822387695, -8.243631362915039, -9.9330472946167, -9.948543548583984, -10.500215530395508, -10.678388595581055, -10.751972198486328, -10.765456199645996], [-0.008370081894099712, -6.0451741218566895, -6.18577241897583, -6.982412815093994, -7.139383792877197, -8.134549140930176, -8.159344673156738, -8.50190258026123, -8.663641929626465, -8.736149787902832], [-1.0432336330413818, -1.8263661861419678, -2.1156957149505615, -3.047067403793335, -3.308339834213257, -3.348275899887085, -3.4472196102142334, -3.4566380977630615, -3.7778737545013428, -3.791858434677124], [-1.7196604013442993, -1.8512922525405884, -2.657717227935791, -2.868063449859619, -3.18095064163208, -3.256824016571045, -3.3826069831848145, -3.606606960296631, -3.8970046043395996, -4.15523099899292], [-1.7693288326263428, -1.7819154262542725, -3.3347280025482178, -3.372514486312866, -3.676434278488159, -3.737291097640991, -4.007862091064453, -4.01027774810791, -4.241626739501953, -4.344644546508789], [-0.2157338708639145, -3.0789902210235596, -3.3788645267486572, -3.6015961170196533, -4.616561412811279, -5.313955783843994, -5.9718451499938965, -5.995490550994873, -6.514543056488037, -6.566507816314697], [-0.4280637502670288, -2.296477794647217, -2.4626364707946777, -4.107550144195557, -4.3692708015441895, -4.554446697235107, -4.819934368133545, -4.839047908782959, -4.874934673309326, -4.945106029510498], [-0.6078917980194092, -2.336338758468628, -2.6146552562713623, -3.030010938644409, -3.294659376144409, -3.5501067638397217, -4.410981178283691, -4.4417009353637695, -4.578665733337402, -5.020362854003906], [-2.101005792617798, -2.2420084476470947, -2.5924150943756104, -2.9576094150543213, -3.307314157485962, -3.5970327854156494, -3.641979455947876, -3.7467234134674072, -3.8467447757720947, -3.8482134342193604], [-0.2742314338684082, -3.0022835731506348, -3.4670376777648926, -3.5841755867004395, -3.701826572418213, -3.9221978187561035, -4.054760456085205, -4.200649738311768, -4.472208499908447, -4.841511249542236], [-1.6968836784362793, -2.1087775230407715, -2.6820216178894043, -2.9742941856384277, -3.4959464073181152, -3.689746379852295, -4.191409587860107, -4.281203746795654, -4.473987102508545, -4.5825724601745605], [-1.3889646530151367, -1.5374040603637695, -2.0741662979125977, -2.411370277404785, -2.43520450592041, -3.693913459777832, -4.079195976257324, -4.120011329650879, -4.134087562561035, -4.141880989074707], [-0.6386191248893738, -1.8878657817840576, -2.5629241466522217, -2.8150298595428467, -3.2080485820770264, -3.6440589427948, -3.976628065109253, -4.137911319732666, -4.253498554229736, -4.745829105377197], [-0.9439324140548706, -1.067759394645691, -2.5506181716918945, -3.547316551208496, -3.789402961730957, -4.532855987548828, -5.038325309753418, -5.293664932250977, -5.379020690917969, -5.556051254272461], [-1.3809058666229248, -3.1378486156463623, -3.1723506450653076, -3.309138059616089, -3.329134702682495, -3.387493848800659, -3.4524409770965576, -3.472567319869995, -3.551487684249878, -3.6468780040740967], [-1.7096613645553589, -1.8542555570602417, -2.224048614501953, -3.1737632751464844, -3.34393310546875, -3.5665550231933594, -3.6465511322021484, -3.7869834899902344, -4.120035171508789, -4.21894645690918], [-0.5557006597518921, -1.9715102910995483, -2.5443215370178223, -3.1489338874816895, -3.386566638946533, -3.495972156524658, -4.038139820098877, -4.248053073883057, -4.728241443634033, -4.81570291519165], [-1.211690068244934, -1.9493094682693481, -2.035597801208496, -2.1459264755249023, -2.686469078063965, -3.0523080825805664, -3.4404783248901367, -3.4435014724731445, -4.251574516296387, -4.402024269104004], [-0.7972376942634583, -1.017091989517212, -3.2294352054595947, -4.0943074226379395, -4.327707767486572, -4.474125385284424, -4.563999652862549, -4.741447925567627, -4.819214344024658, -4.864084720611572], [-0.10139290243387222, -3.300079584121704, -3.328747034072876, -4.231258392333984, -5.562854766845703, -6.236425399780273, -7.287128448486328, -7.967182159423828, -8.545370101928711, -8.55656623840332], [-1.3483690023422241, -1.518170714378357, -2.4569315910339355, -3.0879931449890137, -3.7988085746765137, -3.903869152069092, -4.216450214385986, -4.369424343109131, -4.55366849899292, -4.589274883270264], [-0.06262421607971191, -4.3025054931640625, -4.669498443603516, -4.989679336547852, -5.54271125793457, -5.706295013427734, -5.956817626953125, -6.307018280029297, -6.423316955566406, -6.485013961791992], [-2.5495076179504395, -2.5675063133239746, -3.042685031890869, -3.1042580604553223, -3.39054536819458, -3.400477886199951, -3.4144062995910645, -3.6298699378967285, -3.7439751625061035, -3.7600274085998535], [-0.09137691557407379, -3.475541830062866, -4.2667155265808105, -4.662120342254639, -5.20846700668335, -5.508571147918701, -5.635375499725342, -6.091742992401123, -6.11230993270874, -6.341228008270264], [-0.18201260268688202, -2.368541717529297, -3.696704864501953, -4.225114822387695, -5.073600769042969, -5.284589767456055, -5.555824279785156, -6.381378173828125, -6.584751129150391, -6.672506332397461], [-0.9016001224517822, -2.268352746963501, -2.584024667739868, -2.931650400161743, -3.263654947280884, -3.4984095096588135, -3.5274813175201416, -3.578829050064087, -4.017011642456055, -4.061138153076172], [-0.11714259535074234, -2.94112491607666, -4.900289535522461, -5.1920881271362305, -5.254494667053223, -5.381329536437988, -6.071743011474609, -6.230602264404297, -6.26826286315918, -6.27938175201416], [-0.06557973474264145, -3.669421434402466, -4.82211446762085, -4.869842052459717, -5.106460094451904, -5.193267345428467, -6.17078161239624, -6.514668941497803, -6.544055461883545, -7.402038097381592], [-1.030350923538208, -1.483058214187622, -2.183255434036255, -2.5520145893096924, -2.7042152881622314, -4.012787818908691, -4.065133094787598, -4.093894004821777, -4.546229362487793, -4.547656059265137], [-1.3742985725402832, -2.0942063331604004, -2.475864887237549, -2.8991684913635254, -3.029329776763916, -3.5953497886657715, -3.652097225189209, -3.7876534461975098, -3.7885489463806152, -3.8671622276306152], [-1.0311336517333984, -2.1572933197021484, -2.2236881256103516, -3.1790599822998047, -3.566823959350586, -3.8217105865478516, -3.844965934753418, -4.089427947998047, -4.24880313873291, -4.544251441955566], [-0.685200572013855, -2.6686887741088867, -3.211125373840332, -3.4209165573120117, -3.510441780090332, -3.6480093002319336, -3.794857978820801, -3.8130578994750977, -4.207077980041504, -4.297345161437988], [-0.7575279474258423, -1.1479774713516235, -3.368588924407959, -3.5933737754821777, -3.7284369468688965, -4.0172553062438965, -4.290660381317139, -4.507211208343506, -4.542802333831787, -4.743058681488037], [-0.21740996837615967, -2.908949851989746, -3.3841352462768555, -4.084765434265137, -4.254019737243652, -4.5183000564575195, -4.715529441833496, -5.328167915344238, -5.715561866760254, -5.749777793884277], [-0.2695348560810089, -3.709380865097046, -4.102128028869629, -4.130378723144531, -4.639004707336426, -5.025005340576172, -5.193634033203125, -5.525087356567383, -5.643150329589844, -5.649812698364258], [-0.4080590009689331, -2.0571985244750977, -3.4775819778442383, -3.5463647842407227, -3.7925596237182617, -4.42836856842041, -4.554379463195801, -4.809592247009277, -4.862614631652832, -4.986878395080566], [-1.8691797256469727, -2.3221845626831055, -2.466702461242676, -2.8556737899780273, -3.0711851119995117, -3.2183170318603516, -3.614659309387207, -3.767179489135742, -3.881969451904297, -4.141114234924316], [-1.3312058448791504, -1.4146027565002441, -2.6731514930725098, -2.8823914527893066, -3.167351245880127, -3.2072300910949707, -3.2995247840881348, -3.3541665077209473, -3.6721692085266113, -3.6906704902648926], [-1.9998599290847778, -2.537775993347168, -2.5626449584960938, -3.015496253967285, -3.1410627365112305, -3.3380937576293945, -3.4569501876831055, -3.5569753646850586, -3.6368770599365234, -3.7716569900512695], [-0.8629760146141052, -1.1353645324707031, -2.311382293701172, -3.1272945404052734, -3.67535400390625, -4.118551254272461, -4.215915679931641, -4.476306915283203, -5.11979866027832, -5.3126220703125]], \"topKTokens\": [[\"\\n\", \",\", \"Words\", \"Summary\", \"\\n\\n\", \"<|endoftext|>\", \" \", \"Features\", \"Random\", \" the\"], [\" upon\", \" there\", \",\", \" the\", \" she\", \" on\", \" he\", \" day\", \" in\", \" night\"], [\" a\", \" an\", \" the\", \" one\", \" time\", \" some\", \" upon\", \" it\", \" two\", \" something\"], [\" time\", \" day\", \" night\", \" morning\", \" week\", \" Sunday\", \" long\", \" Wednesday\", \" dark\", \" little\"], [\",\", \" there\", \" in\", \" a\", \" was\", \" upon\", \".\", \" on\", \" the\", \" lived\"], [\" there\", \" a\", \" in\", \" two\", \" the\", \" she\", \" it\", \" Jack\", \" he\", \" Sam\"], [\" was\", \" were\", \" lived\", \" are\", \" is\", \"'s\", \",\", \" a\", \" wasn\", \" had\"], [\" a\", \" an\", \" two\", \" one\", \" something\", \" some\", \" the\", \" three\", \" his\", \" Jack\"], [\" little\", \" girl\", \" boy\", \" big\", \" brave\", \" small\", \" man\", \" young\", \" kind\", \" happy\"], [\" named\", \" called\", \" who\", \".\", \" and\", \",\", \" with\", \" in\", \" that\", \" walking\"], [\" Jack\", \" Tim\", \" Tom\", \" Joe\", \" John\", \" Sam\", \" Jake\", \" Jimmy\", \" Mark\", \" Bob\"], [\".\", \" who\", \" and\", \",\", \"y\", \" called\", \" named\", \" with\", \"i\", \"lyn\"], [\" He\", \" Jack\", \" One\", \" Joe\", \" Jake\", \" Every\", \" Tom\", \" Jim\", \" John\", \" His\"], [\" was\", \" loved\", \" had\", \" wanted\", \" liked\", \" lived\", \" went\", \" really\", \" always\", \" didn\"], [\" a\", \" long\", \" an\", \" lots\", \" big\", \" many\", \" two\", \" very\", \" been\", \" to\"], [\" big\", \" special\", \" very\", \" toy\", \" long\", \" lot\", \" bright\", \" blue\", \" red\", \" great\"], [\" car\", \" gun\", \" truck\", \" that\", \" boat\", \" pistol\", \" sword\", \" box\", \" rocket\", \" train\"], [\"boat\", \" that\", \".\", \" and\", \" in\", \",\", \" with\", \" on\", \" which\", \" he\"], [\" He\", \" Jack\", \" It\", \" One\", \" Every\", \" His\", \" The\", \"\\n\", \" Joe\", \" Whenever\"], [\" sail\", \" boat\", \" toy\", \" boy\", \" wind\", \" sky\", \" ship\", \" sailor\", \" sea\", \" lake\"], [\" was\", \"boat\", \" had\", \" boat\", \" made\", \" could\", \" kept\", \" would\", \" helped\", \" went\"], [\" was\", \" had\", \" could\", \" sailed\", \"'s\", \" went\", \" wanted\", \" moved\", \" loved\", \" would\"], [\" very\", \" so\", \" a\", \" big\", \" special\", \" his\", \" blue\", \" white\", \" red\", \" in\"], [\" to\", \",\", \" because\", \" and\", \" in\", \".\", \" with\", \" against\", \" but\", \" at\"], [\" he\", \" it\", \" needed\", \" the\", \" Jack\", \" looked\", \" wanted\", \" looking\", \" had\", \" was\"], [\" was\", \" looked\", \" made\", \" kept\", \" had\", \" started\", \" felt\", \" moved\", \" went\", \" sailed\"], [\" like\", \" very\", \" so\", \" heavy\", \" helpless\", \" really\", \" lonely\", \" tight\", \" uncomfortable\", \" hard\"], [\".\", \" in\", \",\", \" when\", \" and\", \" because\", \" on\", \" by\", \" inside\", \" so\"], [\" Jack\", \"\\n\", \" He\", \" \", \" So\", \" The\", \" But\", \" One\", \" Joe\", \" It\"], [\" wanted\", \" was\", \" decided\", \" tried\", \" asked\", \" looked\", \" had\", \" went\", \" thought\", \" knew\"], [\" to\", \" out\", \" home\", \" over\", \" back\", \" sailing\", \" up\", \" on\", \" around\", \" looking\"], [\" the\", \" his\", \" a\", \" get\", \" see\", \" help\", \" find\", \" ask\", \" look\", \" Jack\"], [\" lake\", \" store\", \" beach\", \" shore\", \" pond\", \" dock\", \" river\", \" park\", \" edge\", \" sea\"], [\" to\", \" and\", \" with\", \",\", \" every\", \".\", \"!\", \" all\", \" but\", \" where\"], [\" saw\", \" found\", \" asked\", \" looked\", \" started\", \" tried\", \" got\", \" put\", \" he\", \" used\"], [\" to\", \" at\", \" goodbye\", \" his\", \" hello\", \".\", \" as\", \" the\", \" it\", \" in\"], [\" the\", \" his\", \" it\", \" Jack\", \" everyone\", \" a\", \" all\", \" people\", \" other\", \" him\"], [\" people\", \" sail\", \" waves\", \" sailors\", \" boat\", \" se\", \" children\", \" birds\", \" other\", \" wind\"], [\".\", \" of\", \",\", \" to\", \" as\", \" around\", \" with\", \" in\", \" and\", \" at\"], [\" but\", \" hoping\", \" and\", \" which\", \" trying\", \" saying\", \" asking\", \" \\\"\", \" wishing\", \" making\"], [\" it\", \" nothing\", \" the\", \" he\", \" no\", \" nobody\", \" still\", \" then\", \" his\", \" something\"], [\" was\", \" didn\", \" wouldn\", \" did\", \" stayed\", \" kept\", \" just\", \" still\", \" had\", \" would\"], [\" in\", \" broken\", \" afloat\", \" away\", \" shut\", \" far\", \" on\", \" closed\", \" put\", \" with\"], [\".\", \"'s\", \" and\", \" all\", \" in\", \" from\", \" kept\", \" until\", \" had\", \"\\ufffd\"], [\" kept\", \" his\", \" sailed\", \" the\", \" fixed\", \" helped\", \" played\", \" he\", \" watched\", \" made\"], [\" sailing\", \" playing\", \" looking\", \" trying\", \" going\", \" it\", \" his\", \" him\", \" the\", \" on\"], [\" in\", \" more\", \" wet\", \" tired\", \" bigger\", \" stuck\", \" angry\", \" better\", \" hurt\", \" away\"], [\" the\", \" his\", \" a\", \".\", \" trouble\", \" it\", \" one\", \" its\", \" danger\", \" mind\"], [\" boat\", \" way\", \" sack\", \" sail\", \" water\", \" sand\", \" kay\", \" surf\", \" car\", \" bucket\"], [\".\", \" he\", \" of\", \" with\", \" back\", \" it\", \" when\", \" too\", \" again\", \",\"], [\"\\n\", \" He\", \" \", \" Finally\", \" Suddenly\", \" Then\", \" After\", \" The\", \" Jack\", \" Soon\"], [\"\\n\", \" \", \"<|endoftext|>\", \"Jack\", \"He\", \"Suddenly\", \"Summary\", \"Finally\", \"Soon\", \"The\"], [\"Suddenly\", \"He\", \"Jack\", \"Finally\", \"One\", \"Soon\", \"When\", \"Then\", \"The\", \"After\"], [\",\", \" he\", \" a\", \" Jack\", \" the\", \" his\", \" an\", \" there\", \" something\", \" one\"], [\" a\", \" Jack\", \" he\", \" the\", \" an\", \" something\", \" his\", \" there\", \" it\", \" they\"], [\" heard\", \" saw\", \" noticed\", \" felt\", \" had\", \" remembered\", \" spotted\", \" tri\", \" realized\", \" got\"], [\" a\", \" something\", \" an\", \" another\", \" his\", \" some\", \" the\", \" someone\", \" two\", \" it\"], [\" boat\", \" boy\", \" sack\", \" little\", \" sail\", \" kid\", \" man\", \" child\", \" toy\", \" animal\"], [\" sack\", \" door\", \" boat\", \" box\", \" field\", \" sail\", \" beach\", \" eye\", \" and\", \" bucket\"], [\" of\", \".\", \" and\", \" in\", \" on\", \" with\", \" that\", \" filled\", \"!\", \" at\"], [\" He\", \" It\", \" Jack\", \" This\", \" The\", \" Inside\", \" A\", \" His\", \" Out\", \" In\"], [\" was\", \" quickly\", \" ran\", \" thought\", \" had\", \" opened\", \" wanted\", \" tried\", \" picked\", \" knew\"], [\" so\", \" curious\", \" very\", \" about\", \" excited\", \" a\", \" walking\", \" surprised\", \" trying\", \" scared\"], [\" excited\", \" curious\", \" happy\", \" surprised\", \" angry\", \" sad\", \" alert\", \" confused\", \" scared\", \" thirsty\"], [\" and\", \".\", \",\", \"!\", \" to\", \" because\", \" but\", \" as\", \" -\", \" so\"], [\" he\", \" quickly\", \" ran\", \" wanted\", \" opened\", \" asked\", \" said\", \" started\", \" picked\", \" grabbed\"], [\" ran\", \" quickly\", \" opened\", \" wanted\", \" grabbed\", \" tried\", \" picked\", \" knew\", \" started\", \" sailed\"], [\" opened\", \" grabbed\", \" ran\", \" picked\", \" turned\", \" put\", \" sailed\", \" took\", \" jumped\", \" reached\"], [\" it\", \" the\", \" a\", \" his\", \" one\", \" hold\", \" some\", \" onto\", \" Jack\", \" all\"], [\" of\", \".\", \" and\", \" side\", \" end\", \",\", \" too\", \" from\", \" out\", \"!\"], [\" of\", \".\", \" and\", \" to\", \"!\", \",\", \" the\", \" with\", \" from\", \" his\"], [\" started\", \" opened\", \" tried\", \" ran\", \" held\", \" began\", \" put\", \" took\", \" threw\", \" sailed\"], [\" to\", \" it\", \" again\", \".\", \" his\", \" the\", \" pushing\", \" one\", \" over\", \" a\"], [\" open\", \" take\", \" pull\", \" sail\", \" turn\", \" put\", \" stop\", \" grab\", \" break\", \" pinch\"], [\" away\", \" it\", \" the\", \".\", \" his\", \" back\", \" to\", \" across\", \",\", \" with\"], [\".\", \" with\", \" from\", \"!\", \",\", \" too\", \" again\", \" on\", \" to\", \" but\"], [\" But\", \" He\", \"\\n\", \" The\", \" Jack\", \" It\", \" After\", \" His\", \" As\", \" Unfortunately\"], [\" the\", \" it\", \" he\", \",\", \" Jack\", \" as\", \" when\", \" his\", \" then\", \" before\"], [\" was\", \" wouldn\", \" didn\", \" kept\", \" wasn\", \" held\", \" got\", \" started\", \" stayed\", \" did\"], [\" too\", \" stuck\", \" no\", \" a\", \" not\", \" very\", \" so\", \" broken\", \" locked\", \" difficult\"], [\" in\", \"!\", \".\", \" and\", \" tight\", \",\", \" to\", \" on\", \" shut\", \" inside\"], [\" Jack\", \" He\", \" The\", \"\\n\", \" His\", \" So\", \" Then\", \" It\", \" \", \" Just\"], [\" was\", \" tried\", \" started\", \" pulled\", \" couldn\", \" had\", \" sailed\", \" kept\", \" tug\", \" didn\"], [\" and\", \" to\", \" again\", \" pushing\", \" his\", \" harder\", \" for\", \",\", \" hard\", \" but\"], [\" pull\", \" open\", \" get\", \" sail\", \" move\", \" use\", \" push\", \" grab\", \" w\", \" turn\"], [\" it\", \" the\", \" and\", \" himself\", \",\", \" harder\", \" his\", \" off\", \" out\", \" away\"], [\" out\", \",\", \" off\", \" free\", \" open\", \" but\", \" back\", \" away\", \" apart\", \" and\"], [\",\", \" but\", \" with\", \" of\", \" and\", \" himself\", \".\", \" too\", \" again\", \" by\"], [\" it\", \" he\", \" the\", \" nothing\", \" no\", \" couldn\", \" that\", \" his\", \" there\", \" something\"], [\" wouldn\", \" was\", \" just\", \" didn\", \" would\", \" only\", \" hurt\", \" wasn\", \" still\", \" couldn\"], [\"'t\", \"\\ufffd\", \"t\", \" not\", \"\\u00b4\", \".\", \"en\", \" no\", \" go\", \" be\"], [\" bud\", \" move\", \" come\", \" open\", \" work\", \" go\", \" break\", \".\", \" stay\", \" fit\"], [\"ge\", \".\", \"ging\", \" bud\", \"t\", \"g\", \"ged\", \"ty\", \" open\", \"ch\"], [\".\", \"!\", \",\", \" -\", \" and\", \";\", \" no\", \" until\", \" either\", \" the\"], [\"\\n\", \" He\", \" \", \" Jack\", \" Then\", \" So\", \" Just\", \" The\", \" Fr\", \" Suddenly\"], [\" was\", \" started\", \" felt\", \" tried\", \" asked\", \" began\", \" kept\", \" became\", \" thought\", \" called\"], [\" to\", \" crying\", \" feeling\", \" screaming\", \" shouting\", \" getting\", \" shaking\", \" struggling\", \" pushing\", \" with\"], [\" cry\", \" get\", \" panic\", \" feel\", \" worry\", \" scream\", \" yell\", \" shout\", \" tear\", \" struggle\"], [\" and\", \" to\", \",\", \".\", \" that\", \" but\", \" again\", \" about\", \" because\", \" loudly\"], [\" \\\"\", \" but\", \" feeling\", \" and\", \" until\", \" \\ufffd\", \" hoping\", \" so\", \" saying\", \"\\n\"], [\"Help\", \"It\", \"Mom\", \"I\", \"This\", \"Oh\", \"What\", \"My\", \"M\", \"No\"], [\" me\", \"'s\", \" go\", \" us\", \" it\", \" the\", \" this\", \"\\ufffd\", \" that\", \" you\"], [\" try\", \" go\", \" help\", \" take\", \",\", \" get\", \" have\", \"!\", \" use\", \" come\"], [\" to\", \" and\", \" one\", \" again\", \" something\", \" the\", \" this\", \" it\", \" another\", \" together\"], [\" more\", \" last\", \"!\\\"\", \" of\", \" final\", \" thing\", \",\\\"\", \" another\", \".\\\"\", \"!\"], [\" time\", \" sail\", \" turn\", \" way\", \" thing\", \" push\", \" game\", \" minute\", \" trick\", \" chance\"], [\".\\\"\", \".\", \"\\\".\", \",\", \"!\\\"\", \" and\", \"!\", \",\\\"\", \"\\\"\", \" to\"], [\" I\", \" maybe\", \" but\", \" it\", \" and\", \" this\", \" we\", \" let\", \" you\", \" please\"], [\" then\", \" this\", \" I\", \" you\", \" it\", \" maybe\", \" the\", \" we\", \" Jack\", \" soon\"], [\" I\", \" we\", \" the\", \" you\", \" it\", \" maybe\", \" Jack\", \" this\", \" another\", \" try\"], [\"'ll\", \" can\", \" will\", \" have\", \"\\ufffd\", \" both\", \" all\", \" won\", \"'re\", \" need\"], [\" get\", \" have\", \" find\", \" open\", \" go\", \" make\", \" try\", \" come\", \" pull\", \" sail\"], [\" it\", \" the\", \" open\", \" up\", \" this\", \"!\\\"\", \" in\", \" into\", \" out\", \".\\\"\"], [\" open\", \"!\\\"\", \" in\", \".\\\"\", \",\\\"\", \"\\\".\", \" into\", \" and\", \".\", \" together\"], [\".\\\"\", \"!\\\"\", \"\\\".\", \" again\", \" and\", \".\", \",\\\"\", \" for\", \" with\", \"!\"], [\" he\", \" she\", \" said\", \" Jack\", \" Jenny\", \" they\", \" his\", \" it\", \"\\n\", \" He\"], [\" said\", \" suggested\", \" explained\", \" thought\", \" replied\", \" told\", \" pleaded\", \" had\", \" finally\", \" warned\"], [\".\", \" with\", \",\", \" to\", \" as\", \" in\", \" excited\", \" firmly\", \" sadly\", \" and\"], [\"\\n\", \" \", \" Jenny\", \" He\", \" So\", \" They\", \" Jack\", \" And\", \" But\", \" \\\"\"], [\"\\n\", \" \", \"Jack\", \"J\", \"So\", \"They\", \"He\", \"The\", \"But\", \" Jenny\"], [\"Jack\", \"J\", \"So\", \"They\", \"He\", \"But\", \"The\", \"Finally\", \"Just\", \"After\"], [\"enny\", \"ill\", \"aney\", \"elly\", \"illian\", \"enna\", \"asper\", \"ally\", \"oby\", \"cy\"], [\" was\", \" and\", \" smiled\", \" tried\", \" thought\", \" did\", \" didn\", \" looked\", \"'s\", \" felt\"], [\" and\", \" to\", \" again\", \" one\", \" pushing\", \",\", \" it\", \" very\", \" a\", \" pulling\"], [\" open\", \" pull\", \" move\", \" push\", \" think\", \" help\", \" tug\", \" stretch\", \" do\", \" get\"], [\" the\", \" it\", \" her\", \" a\", \" one\", \" his\", \" and\", \" another\", \" again\", \",\"], [\" sail\", \" sack\", \" can\", \" lock\", \" bottle\", \" zip\", \" box\", \" cup\", \" lid\", \" second\"], [\",\", \" but\", \" with\", \" and\", \" too\", \" again\", \".\", \" of\", \" together\", \" all\"], [\",\", \" and\", \".\", \" but\", \" this\", \" -\", \";\", \"!\", \" with\", \" so\"], [\" but\", \" and\", \" it\", \" he\", \" so\", \" with\", \" she\", \" the\", \" opened\", \" pushing\"], [\" it\", \" he\", \" the\", \" nothing\", \" she\", \" they\", \" as\", \" when\", \" there\", \" still\"], [\" was\", \" wouldn\", \" still\", \" didn\", \" would\", \" just\", \" did\", \" wasn\", \" stayed\", \" split\"], [\"'t\", \"\\ufffd\", \"\\u00b4\", \" not\", \".\", \" no\", \"en\", \" shut\", \"t\", \" be\"], [\" bud\", \" move\", \" open\", \" come\", \" work\", \".\", \" fit\", \" break\", \" go\", \" split\"], [\"ge\", \".\", \"ging\", \" bud\", \" open\", \"ged\", \"ty\", \"ched\", \"t\", \" until\"], [\".\", \"!\", \" either\", \" -\", \" and\", \" until\", \",\", \";\", \" no\", \" the\"], [\" She\", \" They\", \" He\", \" Then\", \" Finally\", \" Suddenly\", \" \\\"\", \" Just\", \" Eventually\", \" The\"], [\" both\", \" were\", \" started\", \" had\", \" kept\", \" tried\", \" pulled\", \" all\", \" decided\", \" began\"], [\" for\", \" and\", \" back\", \" about\", \" until\", \",\", \" a\", \" with\", \" so\", \" over\"], [\" a\", \" hours\", \" many\", \" what\", \" so\", \" more\", \" too\", \" an\", \" days\", \" awhile\"], [\" while\", \" minute\", \" few\", \" long\", \" bit\", \" little\", \" moment\", \" whole\", \" very\", \" couple\"], [\",\", \" until\", \" and\", \".\", \" but\", \" before\", \" so\", \"!\", \" to\", \" -\"], [\" until\", \" but\", \" and\", \" then\", \" trying\", \" eventually\", \" so\", \" the\", \" with\", \" Finally\"], [\" finally\", \" suddenly\", \" Jenny\", \" eventually\", \" one\", \" a\", \" the\", \" they\", \" then\", \" their\"], [\" of\", \" minute\", \" finally\", \" day\", \" eventually\", \" little\", \" brave\", \" came\", \" that\", \" special\"], [\" them\", \" the\", \" Jenny\", \" their\", \" Jack\", \" her\", \" his\", \" you\", \" us\", \" Harry\"], [\" finally\", \" suggested\", \" had\", \" split\", \" came\", \" opened\", \" gave\", \" said\", \" decided\", \" spoke\"], [\" opened\", \" split\", \" gave\", \" decided\", \" agreed\", \" managed\", \" came\", \" let\", \" said\", \" heard\"], [\" in\", \" up\", \" it\", \" way\", \" the\", \" them\", \" one\", \" out\", \" a\", \" him\"], [\".\", \" and\", \",\", \" on\", \"!\", \" hope\", \" the\", \" in\", \" trying\", \" all\"], [\" It\", \" Jenny\", \"\\n\", \" They\", \" \\\"\", \" He\", \" Inside\", \" But\", \" The\", \" \"], [\" was\", \" worked\", \" split\", \" had\", \" opened\", \" looked\", \" seemed\", \" turned\", \" wasn\", \" took\"], [\" open\", \" in\", \" the\", \" into\", \" and\", \" right\", \",\", \"!\", \" with\", \" off\"], [\" and\", \",\", \"!\", \" the\", \".\", \" again\", \" with\", \" by\", \" just\", \" a\"], [\" inside\", \" they\", \" out\", \" the\", \" Jenny\", \" a\", \" in\", \" all\", \" there\", \" revealed\"], [\" the\", \" out\", \" it\", \" off\", \" to\", \" a\", \",\", \" up\", \" them\", \" sail\"], [\" both\", \" free\", \" to\", \" all\", \" on\", \" aside\", \" down\", \" out\", \" inside\", \" in\"], [\".\", \"!\", \",\", \" in\", \" from\", \" to\", \" -\", \" again\", \" and\", \" at\"], [\"\\n\", \" They\", \" \", \" Jenny\", \" Inside\", \" The\", \" It\", \" Now\", \" Everyone\", \" \\\"\"], [\" were\", \" both\", \" all\", \" cheered\", \" ran\", \" hugged\", \" had\", \" happily\", \" opened\", \" smiled\"], [\" so\", \" both\", \" all\", \" very\", \" able\", \" happy\", \" amazed\", \" thrilled\", \" delighted\", \" the\"], [\" happy\", \" excited\", \" proud\", \" relieved\", \" surprised\", \" glad\", \" grateful\", \" thrilled\", \" delighted\", \" pleased\"], [\" and\", \" to\", \" that\", \",\", \"!\", \".\", \" they\", \" as\", \" for\", \" about\"], [\"\\n\", \" \", \" They\", \" Jenny\", \" Inside\", \" But\", \" The\", \" Now\", \" From\", \" With\"], [\"\\n\", \" \", \"\\n\\n\", \" They\", \" The\", \" Jenny\", \" Now\", \"The\", \" It\", \" From\"], [\"\\n\", \"The\", \"They\", \" \", \"J\", \"\\\"\", \"Jack\", \"Inside\", \"But\", \"Once\"], [\"The\", \"They\", \"J\", \"Inside\", \"Jack\", \"But\", \"When\", \"\\\"\", \"From\", \"And\"], [\" next\", \" two\", \" end\", \" sack\", \" End\", \" children\", \" moral\", \" kids\", \" boy\", \" boys\"], [\" after\", \" was\", \" all\", \" and\", \" were\", \" the\", \" tag\", \" them\", \" filled\", \" back\"], [\" the\", \" them\", \" all\", \" their\", \" Jenny\", \" a\", \" what\", \" it\", \" fish\", \" things\"], [\" and\", \",\", \"'s\", \" as\", \" all\", \" around\", \" for\", \" until\", \" was\", \" to\"], [\" Jack\", \" Harry\", \" the\", \" Tommy\", \" her\", \" Jacob\", \" eventually\", \" Jenny\", \" she\", \" they\"], [\" ran\", \" and\", \" were\", \",\", \" cheered\", \" laughed\", \" had\", \" hugged\", \" soon\", \" just\"], [\" the\", \" one\", \" out\", \" it\", \" a\", \" up\", \" all\", \" their\", \" away\", \" both\"], [\" few\", \" big\", \" piece\", \" sack\", \" toy\", \" minute\", \" bite\", \" treat\", \" shiny\", \" nap\"], [\" of\", \" from\", \".\", \",\", \" and\", \" that\", \" away\", \" with\", \" full\", \" at\"], [\" the\", \" it\", \" her\", \" their\", \" them\", \" his\", \" each\", \" him\", \" a\", \" one\"], [\" hands\", \".\", \" hand\", \" and\", \",\", \" arm\", \" neck\", \" mom\", \" again\", \" pocket\"], [\" ran\", \" said\", \" split\", \" opened\", \" it\", \" put\", \" they\", \" she\", \" threw\", \" started\"], [\" both\", \" ran\", \" were\", \" split\", \" started\", \" never\", \" all\", \" took\", \" hugged\", \" opened\"], [\" it\", \" the\", \" a\", \" them\", \" turns\", \" all\", \" her\", \" out\", \" their\", \" him\"], [\" to\", \" home\", \" outside\", \" away\", \" back\", \" far\", \".\", \" with\", \" out\", \" from\"], [\".\", \" of\", \" to\", \",\", \"!\", \" into\", \" with\", \" for\", \" -\", \" from\"], [\" the\", \" her\", \" their\", \" his\", \" Jenny\", \" Jack\", \" them\", \" its\", \" Billy\", \" it\"], [\" sack\", \" harbor\", \" beach\", \" split\", \" car\", \" nearby\", \" boat\", \" park\", \" water\", \" lake\"], [\".\", \",\", \"!\", \" and\", \" with\", \" to\", \" from\", \" as\", \" -\", \" at\"], [\" honey\", \" crack\", \" the\", \" split\", \" cookies\", \" hay\", \" shrimp\", \" broken\", \" potatoes\", \" toys\"], [\"ers\", \"les\", \".\", \"er\", \"ling\", \"s\", \"-\", \"ings\", \" in\", \"ly\"], [\".\", \" and\", \",\", \"!\", \" with\", \" that\", \" from\", \" in\", \" they\", \" until\"], [\" They\", \" Jack\", \" Inside\", \" It\", \" Jenny\", \" The\", \" When\", \" Then\", \" He\", \" Now\"], [\"\\n\", \" They\", \"\\n\\n\", \" It\", \" Jack\", \" Jenny\", \" The\", \"They\", \" She\", \" When\"], [\"\\n\", \"Jack\", \"\\\"\", \"J\", \"They\", \"The\", \"It\", \"And\", \" \", \"He\"], [\"Jack\", \"J\", \"The\", \"They\", \"\\\"\", \"It\", \"When\", \"And\", \"But\", \"Finally\"], [\" two\", \" end\", \" End\", \" sack\", \" children\", \" moral\", \" kids\", \" bad\", \" friends\", \" next\"], [\" friends\", \" of\", \" were\", \" children\", \" boys\", \" halves\", \" little\", \" pieces\", \" kids\", \" siblings\"], [\" were\", \" hugged\", \" laughed\", \" never\", \" had\", \" ran\", \" looked\", \" cheered\", \" enjoyed\", \" learned\"], [\" the\", \" open\", \" into\", \" up\", \" it\", \" and\", \" away\", \" their\", \" off\", \" in\"], [\" the\", \" and\", \" it\", \",\", \" all\", \" again\", \" their\", \" a\", \".\", \" up\"], [\" sack\", \" chest\", \" crack\", \" split\", \" can\", \" last\", \" contents\", \" shell\", \" rest\", \" broken\"], [\" and\", \",\", \".\", \" open\", \" in\", \" with\", \" together\", \" until\", \" of\", \" again\"], [\" inside\", \" all\", \" the\", \" they\", \" were\", \" found\", \" set\", \" find\", \" it\", \" one\"], [\" a\", \" lots\", \" two\", \" many\", \" the\", \" that\", \" all\", \" some\", \" it\", \" out\"], [\" toys\", \" pieces\", \" stones\", \",\", \" and\", \" shells\", \" gems\", \" balloons\", \" jewels\", \" balls\"], [\" inside\", \" of\", \".\", \" to\", \",\", \" and\", \" that\", \" in\", \"!\", \" for\"]], \"correctTokenRank\": [294, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 3, 41, 2, 6, 0, 1, 0, 338, 3, 1, 6, 16, 0, 2, 7, 0, 0, 2, 1, 61, 0, 0, 174, 2, 0, 0, 4, 41, 2, 0, 14, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 3, 41, 51, 1, 0, 0, 2, 0, 0, 0, 1, 1, 4, 8, 2, 2, 0, 3, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 14, 2, 0, 14, 127, 0, 2, 0, 7, 3, 4, 0, 1, 2, 43, 0, 0, 6, 0, 0, 0, 0, 0, 1, 0, 3, 1, 0, 0, 1, 14, 0, 0, 0, 1, 0, 0, 0, 0, 1, 11, 0, 0, 1, 0, 0, 4, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 30, 8, 1, 1, 1, 0, 0, 1, 5, 1, 0, 0, 0, 516, 13, 4, 0, 0, 149, 4, 3, 1, 2, 3, 6, 7, 0, 8, 1, 0, 0, 14, 1, 0, 0, 11, 0, 0, 2, 0, 0, 72, 1, 0, 0, 0, 5, 71, 1, 1], \"correctTokenLogProb\": [-11.625454902648926, -0.372489869594574, -0.005904730875045061, -0.011737688444554806, -0.1878184974193573, -0.10250605642795563, -0.1382717341184616, -0.0321299247443676, -2.9644947052001953, -0.6622740030288696, -1.5416234731674194, -0.1681029349565506, -0.46368974447250366, -2.3646175861358643, -0.2179473340511322, -3.575500011444092, -6.000157356262207, -1.7438406944274902, -3.758558511734009, -0.22709661722183228, -0.8340997099876404, -0.18225006759166718, -9.012614250183105, -2.220285415649414, -2.0479183197021484, -4.108707904815674, -4.43994665145874, -0.21257247030735016, -2.498260974884033, -3.589505195617676, -0.2939232289791107, -0.6799303293228149, -2.353745222091675, -1.143761157989502, -6.430000305175781, -0.670299768447876, -0.39927276968955994, -8.55900764465332, -2.7364742755889893, -0.8046091198921204, -1.5585801601409912, -3.159571886062622, -5.98371696472168, -2.5591187477111816, -1.5188981294631958, -4.570854663848877, -1.8147063255310059, -0.9960278868675232, -1.4884846210479736, -0.0612158365547657, -0.5061531066894531, -0.014467342756688595, -1.904248833656311, -0.06192167475819588, -1.7007927894592285, -1.3692022562026978, -4.0620832443237305, -6.9657511711120605, -6.589221477508545, -1.482456088066101, -0.6135923266410828, -2.1453137397766113, -2.284712553024292, -1.0018718242645264, -0.5399669408798218, -1.1068181991577148, -2.4699113368988037, -1.7614178657531738, -5.188108921051025, -5.65565824508667, -3.529046058654785, -2.3224706649780273, -0.09658709168434143, -2.8622007369995117, -1.1216830015182495, -0.233905628323555, -0.8066551685333252, -1.2686195373535156, -0.21141986548900604, -2.4943528175354004, -1.2809205055236816, -1.1902873516082764, -1.997227668762207, -1.4352091550827026, -1.3710194826126099, -0.29757070541381836, -0.47833946347236633, -1.3295480012893677, -0.16531595587730408, -0.3240576684474945, -0.012859278358519077, -0.3687290549278259, -9.60780744208023e-05, -0.010634183883666992, -1.4955366849899292, -1.4547170400619507, -0.021869802847504616, -6.184778213500977, -1.5772393941879272, -0.5218283534049988, -4.868173122406006, -10.581866264343262, -1.6510953903198242, -2.389171838760376, -0.13953861594200134, -4.755903720855713, -2.2836148738861084, -2.820733070373535, -1.1652450561523438, -1.7936186790466309, -2.805985450744629, -6.399561882019043, -0.869734525680542, -0.8247092366218567, -3.684070587158203, -0.24715906381607056, -0.09245855361223221, -0.14069277048110962, -0.2908884584903717, -0.01255407091230154, -1.5455858707427979, -0.001374729792587459, -2.7370738983154297, -1.744795799255371, -1.6868748664855957, -0.071550153195858, -1.2599620819091797, -6.6492156982421875, -0.48842698335647583, -0.09752276539802551, -0.10213370621204376, -1.6529886722564697, -0.001865553087554872, -0.24320362508296967, -7.819823804311454e-05, -0.0336938351392746, -1.8376655578613281, -4.39990234375, -0.47219616174697876, -0.07215513288974762, -1.597762107849121, -0.5735659599304199, -0.9814082980155945, -2.9928762912750244, -0.722653865814209, -0.4017976224422455, -0.9812257289886475, -2.2025957107543945, -0.9003943204879761, -0.4761863350868225, -2.0132555961608887, -4.277318954467773, -0.39351677894592285, -0.9448423385620117, -5.9239959716796875, -3.844897747039795, -2.021122932434082, -1.703595757484436, -1.5536363124847412, -0.4624500870704651, -0.17612281441688538, -1.277457356452942, -3.61790132522583, -2.481966733932495, -0.0015544723719358444, -0.008370081894099712, -1.0432336330413818, -9.289742469787598, -4.784180641174316, -4.616561412811279, -0.4280637502670288, -0.6078917980194092, -8.108386993408203, -3.701826572418213, -2.9742941856384277, -1.5374040603637695, -2.5629241466522217, -3.547316551208496, -3.4524409770965576, -3.7869834899902344, -0.5557006597518921, -4.251574516296387, -1.017091989517212, -0.10139290243387222, -1.3483690023422241, -7.061807632446289, -2.5675063133239746, -0.09137691557407379, -0.18201260268688202, -4.111955642700195, -0.11714259535074234, -0.06557973474264145, -2.183255434036255, -1.3742985725402832, -1.0311336517333984, -7.133974075317383, -1.1479774713516235, -0.21740996837615967, -0.2695348560810089, -0.4080590009689331, -3.2183170318603516, -8.130208969116211, -2.537775993347168, -1.1353645324707031]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f11eac36690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = model.generate(\n",
    "    \"Once upon a time\",\n",
    "    stop_at_eos=False,  # avoids a bug on MPS\n",
    "    temperature=1,\n",
    "    verbose=True,\n",
    "    max_new_tokens=200,\n",
    ")\n",
    "logits, cache = model.run_with_cache(example_prompt)\n",
    "cv.logits.token_log_probs(\n",
    "    model.to_tokens(example_prompt),\n",
    "    model(example_prompt)[0].log_softmax(dim=-1),\n",
    "    model.to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_steps = 30_000 # probably we should do more\n",
    "batch_size = 4096\n",
    "total_training_tokens = total_training_steps * batch_size\n",
    "\n",
    "lr_warm_up_steps = 0\n",
    "lr_decay_steps = total_training_steps // 5 # 20% of training\n",
    "l1_warm_up_steps = total_training_steps // 20 # 5% of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 32768-L1-0.01-LR-0.0001-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=model_name,  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True, # we could pre-download the token dataset if it was small.\n",
    "    \n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=32,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=False,\n",
    "    gated=True,\n",
    "    \n",
    "    # Training Parameters\n",
    "    lr=1e-4,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.0,# adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999, \n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=3e-5,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    \n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size_prompts=16,\n",
    "    \n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False, # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    \n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_tinystories_1l\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Run name: 32768-L1-0.01-LR-0.0001-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 32768-L1-0.01-LR-0.0001-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavide-ghilardi0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/juice2/scr2/ghilardi/home/mats-interp/wandb/run-20240512_061532-xh8zgwd5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/xh8zgwd5' target=\"_blank\">32768-L1-0.01-LR-0.0001-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/xh8zgwd5' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/xh8zgwd5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19400| MSE Loss 22.017 | L1 0.401:  65%|   | 79867904/122880000 [45:10<22:55, 31273.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interrupted, saving progress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19400| MSE Loss 22.017 | L1 0.401:  65%|   | 79867904/122880000 [45:20<22:55, 31273.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done saving\n"
     ]
    },
    {
     "ename": "InterruptedException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterruptedException\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# look at the next cell to see some instruction for what to do while this is running.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sparse_autoencoder_dictionary \u001b[38;5;241m=\u001b[39m \u001b[43mlanguage_model_sae_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/sae_lens/training/lm_runner.py:103\u001b[0m, in \u001b[0;36mlanguage_model_sae_runner\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    100\u001b[0m         sparse_autoencoder\u001b[38;5;241m.\u001b[39mautoencoders[k] \u001b[38;5;241m=\u001b[39m sae  \u001b[38;5;66;03m# type: ignore # pyright: ignore [reportPossiblyUnboundVariable]\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# train SAE\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m sparse_autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sae_group_on_language_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore [reportPossiblyUnboundVariable] # type: ignore\u001b[39;49;00m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_autoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore [reportPossiblyUnboundVariable]\u001b[39;49;00m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivations_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore [reportPossiblyUnboundVariable]\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_contexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_contexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_run_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_run_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_batch_size_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_checkpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_checkpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_sampling_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_to_wandb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_log_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwandb_log_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_every_n_wandb_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_every_n_wandb_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_eval_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_eval_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_batch_size_prompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_batch_size_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msae_group\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mlog_to_wandb:\n\u001b[1;32m    121\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/sae_lens/training/train_sae_on_language_model.py:315\u001b[0m, in \u001b[0;36mtrain_sae_group_on_language_model\u001b[0;34m(model, sae_group, activation_store, train_contexts, training_run_state, batch_size, n_checkpoints, feature_sampling_window, use_wandb, wandb_log_frequency, eval_every_n_wandb_logs, autocast, n_eval_batches, eval_batch_size_prompts)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    312\u001b[0m         training_run_state\u001b[38;5;241m.\u001b[39mn_training_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m     ) \u001b[38;5;241m%\u001b[39m wandb_log_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    314\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m--> 315\u001b[0m             \u001b[43m_build_train_step_log_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                \u001b[49m\u001b[43msparse_autoencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstep_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[43mwandb_suffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtraining_run_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_training_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    322\u001b[0m             step\u001b[38;5;241m=\u001b[39mtraining_run_state\u001b[38;5;241m.\u001b[39mn_training_steps,\n\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;66;03m# record loss frequently, but not all the time.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (training_run_state\u001b[38;5;241m.\u001b[39mn_training_steps \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    327\u001b[0m         wandb_log_frequency \u001b[38;5;241m*\u001b[39m eval_every_n_wandb_logs\n\u001b[1;32m    328\u001b[0m     ) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/sae_lens/training/train_sae_on_language_model.py:694\u001b[0m, in \u001b[0;36m_build_train_step_log_dict\u001b[0;34m(sparse_autoencoder, output, ctx, wandb_suffix, n_training_tokens)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ghost_grad_loss, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    691\u001b[0m     ghost_grad_loss \u001b[38;5;241m=\u001b[39m ghost_grad_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# losses\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses/mse_loss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmse_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses/l1_loss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: l1_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;241m/\u001b[39m sparse_autoencoder\u001b[38;5;241m.\u001b[39ml1_coefficient,  \u001b[38;5;66;03m# normalize by l1 coefficient\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses/aux_loss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: aux_loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses/ghost_grad_loss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: ghost_grad_loss,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses/overall_loss\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;66;03m# variance explained\u001b[39;00m\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/explained_variance\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: explained_variance\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/explained_variance_std\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: explained_variance\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics/l0\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: l0\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# sparsity\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparsity/mean_passes_since_fired\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: ctx\u001b[38;5;241m.\u001b[39mn_forward_passes_since_fired\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparsity/dead_features\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: ghost_grad_neuron_mask\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails/current_learning_rate\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: current_learning_rate,\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails/current_l1_coefficient\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwandb_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: sparse_autoencoder\u001b[38;5;241m.\u001b[39ml1_coefficient,\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails/n_training_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_training_tokens,\n\u001b[1;32m    710\u001b[0m }\n",
      "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/sae_lens/training/train_sae_on_language_model.py:274\u001b[0m, in \u001b[0;36mtrain_sae_group_on_language_model.<locals>.interrupt_callback\u001b[0;34m(sig_num, stack_frame)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minterrupt_callback\u001b[39m(sig_num: Any, stack_frame: Any):\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InterruptedException()\n",
      "\u001b[0;31mInterruptedException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# look at the next cell to see some instruction for what to do while this is running.\n",
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    }
   ],
   "source": [
    "cfg = LanguageModelSAERunnerConfig(\n",
    "    # Data Generating Function (Model + Training Distibuion)\n",
    "    model_name=\"tiny-stories-1L-21M\",  # our model (more options here: https://neelnanda-io.github.io/TransformerLens/generated/model_properties_table.html)\n",
    "    hook_point=\"blocks.0.hook_mlp_out\",  # A valid hook point (see more details here: https://neelnanda-io.github.io/TransformerLens/generated/demos/Main_Demo.html#Hook-Points)\n",
    "    hook_point_layer=0,  # Only one layer in the model.\n",
    "    d_in=1024,  # the width of the mlp output.\n",
    "    dataset_path=\"apollo-research/roneneldan-TinyStories-tokenizer-gpt2\",  # this is a tokenized language dataset on Huggingface for the Tiny Stories corpus.\n",
    "    is_dataset_tokenized=True,\n",
    "    streaming=True, # we could pre-download the token dataset if it was small.\n",
    "    \n",
    "    # SAE Parameters\n",
    "    mse_loss_normalization=None,  # We won't normalize the mse loss,\n",
    "    expansion_factor=16,  # the width of the SAE. Larger will result in better stats but slower training.\n",
    "    b_dec_init_method=\"zeros\",  # The geometric median can be used to initialize the decoder weights.\n",
    "    apply_b_dec_to_input=False,  # We won't apply the decoder weights to the input.\n",
    "    normalize_sae_decoder=False,\n",
    "    scale_sparsity_penalty_by_decoder_norm=True,\n",
    "    decoder_heuristic_init=True,\n",
    "    init_encoder_as_decoder_transpose=True,\n",
    "    normalize_activations=False,\n",
    "    gated=False,\n",
    "    \n",
    "    # Training Parameters\n",
    "    lr=5e-5,  # lower the better, we'll go fairly high to speed up the tutorial.\n",
    "    adam_beta1=0.9,# adam params (default, but once upon a time we experimented with these.)\n",
    "    adam_beta2=0.999, \n",
    "    lr_scheduler_name=\"constant\",  # constant learning rate with warmup. Could be better schedules out there.\n",
    "    lr_warm_up_steps=lr_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lr_decay_steps=lr_decay_steps,  # this will help us avoid overfitting.\n",
    "    l1_coefficient=1e-3,  # will control how sparse the feature activations are\n",
    "    l1_warm_up_steps=l1_warm_up_steps,  # this can help avoid too many dead features initially.\n",
    "    lp_norm=1.0,  # the L1 penalty (and not a Lp for p < 1)\n",
    "    train_batch_size_tokens=batch_size,\n",
    "    context_size=256,  # will control the lenght of the prompts we feed to the model. Larger is better but slower. so for the tutorial we'll use a short one.\n",
    "    \n",
    "    # Activation Store Parameters\n",
    "    n_batches_in_buffer=64,  # controls how many activations we store / shuffle.\n",
    "    training_tokens=total_training_tokens,  # 100 million tokens is quite a few, but we want to see good stats. Get a coffee, come back.\n",
    "    store_batch_size=16,\n",
    "    \n",
    "    # Resampling protocol\n",
    "    use_ghost_grads=False, # we don't use ghost grads anymore.\n",
    "    feature_sampling_window=1000,  # this controls our reporting of feature sparsity stats\n",
    "    dead_feature_window=1000,  # would effect resampling or ghost grads if we were using it.\n",
    "    dead_feature_threshold=1e-4,  # would effect resampling or ghost grads if we were using it.\n",
    "    \n",
    "    # WANDB\n",
    "    log_to_wandb=True,  # always use wandb unless you are just testing code.\n",
    "    wandb_project=\"sae_tinystories_1l\",\n",
    "    wandb_log_frequency=30,\n",
    "    eval_every_n_wandb_logs=20,\n",
    "    # Misc\n",
    "    device=device,\n",
    "    seed=42,\n",
    "    n_checkpoints=0,\n",
    "    checkpoint_path=\"checkpoints\",\n",
    "    dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Run name: 16384-L1-5-LR-5e-05-Tokens-1.229e+08\n",
      "n_tokens_per_buffer (millions): 0.262144\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 30000\n",
      "Total wandb updates: 1000\n",
      "n_tokens_per_feature_sampling_window (millions): 1048.576\n",
      "n_tokens_per_dead_feature_window (millions): 1048.576\n",
      "We will reset the sparsity calculation 30 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/juice2/scr2/ghilardi/home/mats-interp/wandb/run-20240509_105308-baz9qhv7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</a></strong> to <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:2171: UserWarning: Run (myndqwh2) is finished. The call to `_console_raw_callback` will be ignored. Please make sure that you are using an active run.\n",
      "  lambda data: self._console_raw_callback(\"stderr\", data),\n",
      "30000| MSE Loss 79.977 | L1 35.866: 100%|| 122880000/122880000 [58:07<00:00, 35238.11it/s]\n",
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f140ce1152e6406b935981d403dc0284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='115.934 MB of 128.212 MB uploaded\\r'), FloatProgress(value=0.9042385622059216, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td></td></tr><tr><td>details/current_learning_rate</td><td></td></tr><tr><td>details/n_training_tokens</td><td></td></tr><tr><td>losses/ghost_grad_loss</td><td></td></tr><tr><td>losses/l1_loss</td><td></td></tr><tr><td>losses/mse_loss</td><td></td></tr><tr><td>losses/overall_loss</td><td></td></tr><tr><td>metrics/CE_loss_score</td><td></td></tr><tr><td>metrics/ce_loss_with_ablation</td><td></td></tr><tr><td>metrics/ce_loss_with_sae</td><td></td></tr><tr><td>metrics/ce_loss_without_sae</td><td></td></tr><tr><td>metrics/explained_variance</td><td></td></tr><tr><td>metrics/explained_variance_std</td><td></td></tr><tr><td>metrics/l0</td><td></td></tr><tr><td>metrics/l2_norm</td><td></td></tr><tr><td>metrics/l2_norm_in</td><td></td></tr><tr><td>metrics/l2_ratio</td><td></td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td></td></tr><tr><td>sparsity/below_1e-5</td><td></td></tr><tr><td>sparsity/below_1e-6</td><td></td></tr><tr><td>sparsity/dead_features</td><td></td></tr><tr><td>sparsity/mean_passes_since_fired</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>details/current_l1_coefficient</td><td>5</td></tr><tr><td>details/current_learning_rate</td><td>0.0</td></tr><tr><td>details/n_training_tokens</td><td>122880000</td></tr><tr><td>losses/ghost_grad_loss</td><td>0</td></tr><tr><td>losses/l1_loss</td><td>12.63448</td></tr><tr><td>losses/mse_loss</td><td>70.25092</td></tr><tr><td>losses/overall_loss</td><td>133.42332</td></tr><tr><td>metrics/CE_loss_score</td><td>0.86972</td></tr><tr><td>metrics/ce_loss_with_ablation</td><td>8.29373</td></tr><tr><td>metrics/ce_loss_with_sae</td><td>2.73045</td></tr><tr><td>metrics/ce_loss_without_sae</td><td>1.8969</td></tr><tr><td>metrics/explained_variance</td><td>0.57939</td></tr><tr><td>metrics/explained_variance_std</td><td>0.15667</td></tr><tr><td>metrics/l0</td><td>82.93921</td></tr><tr><td>metrics/l2_norm</td><td>12.74778</td></tr><tr><td>metrics/l2_norm_in</td><td>17.58649</td></tr><tr><td>metrics/l2_ratio</td><td>0.71047</td></tr><tr><td>metrics/mean_log10_feature_sparsity</td><td>-2.84769</td></tr><tr><td>sparsity/below_1e-5</td><td>17</td></tr><tr><td>sparsity/below_1e-6</td><td>14</td></tr><tr><td>sparsity/dead_features</td><td>14</td></tr><tr><td>sparsity/mean_passes_since_fired</td><td>5.08258</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">16384-L1-5-LR-5e-05-Tokens-1.229e+08</strong> at: <a href='https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae_tinystories_1l/runs/baz9qhv7</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240509_105308-baz9qhv7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparse_autoencoder_dictionary = language_model_sae_runner(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard vs. Gated SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccf583f69694370a28a2438cba0fbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n",
      "Loaded pretrained model tiny-stories-1L-21M into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Scale sparsity penalty by decoder norm not implemented for Gated SAE. Setting it to standard...\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import LMSparseAutoencoderSessionloader\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "REPO_ID = \"ghidav/tiny-stories-1L-21M-saes\"\n",
    "path = snapshot_download(repo_id=REPO_ID)\n",
    "\n",
    "model, standard_sae, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
    "    path = os.path.join(path, 'standard'), device=device\n",
    ")\n",
    "standard_sae.eval()\n",
    "ssae = standard_sae['standard']\n",
    "\n",
    "model, gated_sae, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
    "    path = os.path.join(path, 'gated'), device=device\n",
    ")\n",
    "gated_sae.eval()\n",
    "gsae = gated_sae['gated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "\n",
    "def get_l0_dist(sae, key):\n",
    "    with torch.no_grad():\n",
    "        # activation store can give us tokens.\n",
    "        batch_tokens = activation_store.get_batch_tokens()\n",
    "        _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
    "\n",
    "        # Use the SAE\n",
    "        sae_out, feature_acts, loss, mse_loss, l1_loss, *_ = sae[key](\n",
    "            cache[sae.cfg.hook_point]\n",
    "        )\n",
    "\n",
    "        # save some room\n",
    "        del cache\n",
    "\n",
    "        # ignore the bos token, get the number of features that activated in each token, averaged accross batch and position\n",
    "        l0 = (feature_acts[:, 1:] > 0).float().sum(-1).detach()\n",
    "        print(f\"{key} average l0\", l0.mean().item())\n",
    "        return px.histogram(l0.flatten().cpu().numpy(), title=\"L0 norm distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "standard_l0_dist = get_l0_dist(standard_sae, 'standard')\n",
    "gated_l0_dist = get_l0_dist(gated_sae, 'gated')\n",
    "\n",
    "fig = make_subplots(rows=2, cols=1)\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(standard_l0_dist.data[0], row=1, col=1)\n",
    "fig.add_trace(gated_l0_dist.data[0], row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=800, width=800, title_text=\"L0 Dist Subplots\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects\n",
    "\n",
    "1. Transcoders\n",
    "2. No Toy Models --> Useful research (work on LLMs)\n",
    "\n",
    "### Use interp to get something that matters\n",
    "* Steering vectors for safety (fine-tune an SAE on a safety dataset...)\n",
    "* Better interface to interact with chat models (other than prompting... for example `to generate json`, `to be concise`, ...)\n",
    "* Early exiting with SAEs on known tasks.\n",
    "* Interesting circuit analysis projects on 7B models (more complex than IOI) ~ pretty ambitious (require SAEs) (example: refusal circuit)\n",
    "    * Compare to other techniques (FT, steering vectors)\n",
    "\n",
    "**SAEs projects**\n",
    "* SAEs to improve SVs\n",
    "* Arthur project\n",
    "* SHIFT for early exiting.\n",
    "* Address ELK with SAEs.\n",
    "* Red teaming (jailbreaks)\n",
    "* SAEs transfer to fine-tuned models (if not, how will the difference be? Sparse?)\n",
    "* SAEs on safety-tuned models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
