{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AyKO0rbNb6P"
      },
      "source": [
        "# 001 - Early Exiting\n",
        "\n",
        "We want to use SAEs features to help perform early exiting. The idea is to merge the knowledge on the task (e.g. python programming) with interpretable features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeZ5LhEnOLkz"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBiTidq6OcKf",
        "outputId": "4e0ee6e5-508d-40f6-cf14-85d2d8ff25da"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab # type: ignore\n",
        "    from google.colab import output\n",
        "    COLAB = True\n",
        "    %pip install circuitsvis sae-lens transformer-lens einsum\n",
        "except:\n",
        "    COLAB = False\n",
        "    from IPython import get_ipython # type: ignore\n",
        "    ipython = get_ipython(); assert ipython is not None\n",
        "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
        "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
        "\n",
        "# Standard imports\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "# Imports for displaying vis in Colab / notebook\n",
        "import webbrowser\n",
        "import http.server\n",
        "import socketserver\n",
        "import threading\n",
        "PORT = 8000\n",
        "\n",
        "torch.set_grad_enabled(False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-eLlKUSOiNQ",
        "outputId": "6e5e94ae-9ee6-42ca-ec5d-4fa4f79ed5b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "# For the most part I'll try to import functions and classes near where they are used\n",
        "# to make it clear where they come from.\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6C1671UtOju8"
      },
      "outputs": [],
      "source": [
        "def display_vis_inline(filename: str, height: int = 850):\n",
        "    '''\n",
        "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
        "    vis has a unique port without having to define a port within the function.\n",
        "    '''\n",
        "    if not(COLAB):\n",
        "        webbrowser.open(filename);\n",
        "\n",
        "    else:\n",
        "        global PORT\n",
        "\n",
        "        def serve(directory):\n",
        "            os.chdir(directory)\n",
        "\n",
        "            # Create a handler for serving files\n",
        "            handler = http.server.SimpleHTTPRequestHandler\n",
        "\n",
        "            # Create a socket server with the handler\n",
        "            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n",
        "                print(f\"Serving files from {directory} on port {PORT}\")\n",
        "                httpd.serve_forever()\n",
        "\n",
        "        thread = threading.Thread(target=serve, args=(\"/content\",))\n",
        "        thread.start()\n",
        "\n",
        "        output.serve_kernel_port_as_iframe(PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True)\n",
        "\n",
        "        PORT += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR7YFCgnNb6Q"
      },
      "source": [
        "### Loading SAEs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "407afe40d7d143cd8165167aafb229a9",
            "91ffb8b7c9894feca396d6b8d6ff0e9b",
            "7f3dd6294b7c46a78134730727781956",
            "0812a958752b4de4a71dd7dba1ebc792",
            "b0784141d3454c3b9b82af693d8ba899",
            "3a7136ac75864871977dd034ff3dac61",
            "cd75ae16b65847558222e442683edc6d",
            "563bc1d0c6b04fa1a3eaba937c194da6",
            "c4ae09a102c44ddda3f8558b1c741e31",
            "b9c39fb16d834994af100894810f6c5b",
            "40aafe6738cb4e079123559b5a4932eb"
          ]
        },
        "id": "KNTW6tIvNb6R",
        "outputId": "fe93c373-1085-4613-8030-5f030636509e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f39407aa5d34fc7b28a8e8456f3fcca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "REPO_ID = \"jbloom/GPT2-Small-SAEs-Reformatted\"\n",
        "path = snapshot_download(repo_id=REPO_ID)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMWtnWeGNb6S",
        "outputId": "fede9ff0-eb1f-4b3d-a5a5-e3e2f8e9889e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "Moving model to device:  cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/datasets/load.py:1454: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sae_lens import LMSparseAutoencoderSessionloader\n",
        "from huggingface_hub import snapshot_download\n",
        "import os\n",
        "\n",
        "layer = 8\n",
        "SUBFOLDER = f\"blocks.{layer}.hook_resid_pre\"\n",
        "\n",
        "model, sae_group, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
        "    path = os.path.join(path, SUBFOLDER), device=device\n",
        ")\n",
        "sae_group.eval()\n",
        "sae = sae_group[f'blocks.{layer}.hook_resid_pre']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoHNFJcc2H1_"
      },
      "source": [
        "### Testing GPT2 on Python and HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformer_lens import utils\n",
        "\n",
        "# Load and prepare the dataset\n",
        "dataset = load_dataset('NeelNanda/c4-code-20k')['train']\n",
        "tokens = utils.tokenize_and_concatenate(dataset, model.tokenizer, max_length=512)['tokens']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwpUO8Rl2Kzv"
      },
      "source": [
        "### Reconstruction test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btdQWD-jsvkt"
      },
      "source": [
        "We first test how the SAE handles reconstruction of python code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "U4i8NJZZsuxO"
      },
      "outputs": [],
      "source": [
        "from transformer_lens import utils\n",
        "from functools import partial\n",
        "\n",
        "# next we want to do a reconstruction test.\n",
        "def reconstr_hook(activation, hook, sae_out):\n",
        "    return sae_out\n",
        "\n",
        "def zero_abl_hook(activation, hook):\n",
        "    return torch.zeros_like(activation)\n",
        "\n",
        "def reconstruction_test(batch_tokens, component, layer, sae_out):\n",
        "\n",
        "    original = model(batch_tokens, return_type=\"loss\").item()\n",
        "    reconstruction = model.run_with_hooks(\n",
        "        batch_tokens,\n",
        "        fwd_hooks=[\n",
        "            (\n",
        "                utils.get_act_name(component, layer),\n",
        "                partial(reconstr_hook, sae_out=sae_out),\n",
        "            )\n",
        "        ],\n",
        "        return_type=\"loss\",\n",
        "    ).item()\n",
        "    zero = model.run_with_hooks(\n",
        "        batch_tokens,\n",
        "        return_type=\"loss\",\n",
        "        fwd_hooks=[(utils.get_act_name(component, layer), zero_abl_hook)],\n",
        "    ).item()\n",
        "\n",
        "    print(\"Original:\", original)\n",
        "    print(\"Reconstruction:\", reconstruction)\n",
        "    print(\"Zero Ablation:\", zero)\n",
        "    print(\"Ratio:\", (reconstruction - zero) / (original - zero))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: 2.0879335403442383\n",
            "Reconstruction: 2.8737123012542725\n",
            "Zero Ablation: 11.773224830627441\n",
            "Ratio: 0.9188688561490794\n"
          ]
        }
      ],
      "source": [
        "batch_tokens = tokens[:16]\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
        "    sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sae(\n",
        "        cache[sae_group.cfg.hook_point]\n",
        "    )\n",
        "\n",
        "reconstruction_test(batch_tokens, 'resid_pre', 8, sae_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "X57IuwJas-0q",
        "outputId": "7fb5a38a-1211-4187-8a1a-a2f94a7b7b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', 'import', ' pand', 'as', ' as', ' p', 'd', '\\n', 'import', ' n', 'umpy', ' as']\n",
            "Tokenized answer: [' np']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29.40</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.00</span><span style=\"font-weight: bold\">% Token: | np|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m29.40\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m99.00\u001b[0m\u001b[1m% Token: | np|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 29.40 Prob: 99.00% Token: | np|\n",
            "Top 1th token. Logit: 24.71 Prob:  0.91% Token: | p|\n",
            "Top 2th token. Logit: 21.96 Prob:  0.06% Token: | n|\n",
            "Top 3th token. Logit: 19.13 Prob:  0.00% Token: | u|\n",
            "Top 4th token. Logit: 18.94 Prob:  0.00% Token: | m|\n",
            "Top 5th token. Logit: 18.85 Prob:  0.00% Token: | pl|\n",
            "Top 6th token. Logit: 18.81 Prob:  0.00% Token: | pi|\n",
            "Top 7th token. Logit: 18.60 Prob:  0.00% Token: | r|\n",
            "Top 8th token. Logit: 17.95 Prob:  0.00% Token: | pc|\n",
            "Top 9th token. Logit: 17.69 Prob:  0.00% Token: | mm|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' np'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' np'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens import utils\n",
        "\n",
        "example_prompt = \"import pandas as pd\\nimport numpy as\"\n",
        "example_answer = \" np\"\n",
        "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "drViYYgFu6b6",
        "outputId": "2b91dd8d-a7ce-4c0d-ead6-edf9209140d5"
      },
      "outputs": [],
      "source": [
        "for l in range(12):\n",
        "    SUBFOLDER = f\"blocks.{l}.hook_resid_pre\"\n",
        "    print(f\"\\n\\nLAYER {l}\")\n",
        "\n",
        "    model, sae_group, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
        "        path = os.path.join(path, SUBFOLDER), device=device\n",
        "    )\n",
        "    sae_group.eval()\n",
        "    sae = sae_group[f'blocks.{l}.hook_resid_pre']\n",
        "\n",
        "    hook_point = sae_group.cfg.hook_point\n",
        "\n",
        "    logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
        "    sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sae(\n",
        "        cache[sae_group.cfg.hook_point]\n",
        "    )\n",
        "\n",
        "    with model.hooks(\n",
        "        fwd_hooks=[\n",
        "            (\n",
        "                hook_point,\n",
        "                partial(reconstr_hook, sae_out=sae_out),\n",
        "            )\n",
        "        ]\n",
        "    ): utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UDFGF6UNb6S"
      },
      "source": [
        "**Results**\n",
        "\n",
        "start: 99.0%\n",
        "* L0: 98.8% *\n",
        "* L1: 97.1% *\n",
        "* L2: 52.8% *\n",
        "* L3: 47.3% *\n",
        "* L4: 77.0% *\n",
        "* L5: 24.5%\n",
        "* L6: 9.0%\n",
        "* L7: 13.2%\n",
        "* L8: 2.3%\n",
        "* L9: 2.9%\n",
        "* L10: 0.5%\n",
        "* L11: 3.5%\n",
        "\n",
        "The first objective is to find the features related to Python. We can use lienar probing for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reconstruction_test(code_tokens[:1], 'resid', 8, sae_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "e7mse_Ovz_7j",
        "outputId": "ac3c82a8-6ce7-4c98-b0af-083316c1cfe3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-c83f05c3-2255\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-c83f05c3-2255\",\n",
              "      TokenLogProbs,\n",
              "      {\"prompt\": [\"<|endoftext|>\", \"import\", \" pand\", \"as\", \" as\", \" p\", \"d\", \"\\n\", \"import\", \" n\", \"umpy\", \" as\"], \"topKLogProbs\": [[-2.7758209705352783, -3.278094530105591, -3.725001573562622, -3.9423258304595947, -3.999708414077759, -4.458621025085449, -4.482809066772461, -4.697759628295898, -4.74949836730957, -4.858037948608398], [-2.3758420944213867, -3.0682172775268555, -3.091958999633789, -3.1538610458374023, -3.5384597778320312, -3.729860305786133, -3.8627233505249023, -3.9566822052001953, -4.159672737121582, -4.383298873901367], [-0.010759908705949783, -4.686729907989502, -8.32953929901123, -9.024802207946777, -9.636832237243652, -9.813433647155762, -9.996865272521973, -10.127219200134277, -10.250100135803223, -10.35304069519043], [-0.8113057017326355, -1.147552251815796, -2.6517693996429443, -3.23706316947937, -3.5722110271453857, -3.716057538986206, -4.873380184173584, -4.979671001434326, -6.0254740715026855, -6.086181163787842], [-0.10044531524181366, -3.545332431793213, -4.3201069831848145, -5.197891712188721, -5.269131183624268, -5.3704705238342285, -5.639593601226807, -5.767439365386963, -5.8428215980529785, -5.898108005523682], [-0.04631408676505089, -5.139186859130859, -5.973142623901367, -6.065471649169922, -6.095745086669922, -6.314687728881836, -6.346588134765625, -6.36390495300293, -6.408540725708008, -6.679595947265625], [-1.1779799461364746, -2.0012145042419434, -2.084258556365967, -3.022212505340576, -3.17842435836792, -3.1975321769714355, -3.341722011566162, -3.4802184104919434, -4.5470194816589355, -4.937218189239502], [-0.00020990552729927003, -10.467233657836914, -10.91457748413086, -11.199020385742188, -11.266693115234375, -11.554792404174805, -11.83346939086914, -11.894943237304688, -12.094354629516602, -12.215805053710938], [-1.4310047626495361, -2.122973680496216, -3.144514322280884, -3.355501413345337, -3.593350648880005, -3.6369822025299072, -3.6651298999786377, -4.068330764770508, -4.521180152893066, -4.619366645812988], [-0.024193763732910156, -5.962929725646973, -6.01003360748291, -6.403472900390625, -6.589095115661621, -6.912925720214844, -7.704553604125977, -7.8096208572387695, -7.935334205627441, -7.999081611633301], [-0.01034693792462349, -5.86694860458374, -5.940093517303467, -6.945483684539795, -7.528838634490967, -7.5837836265563965, -7.892735958099365, -8.639202117919922, -8.862295150756836, -8.97730827331543]], \"topKTokens\": [[\"\\n\", \"The\", \"\\\"\", \"A\", \"I\", \"In\", \".\", \"It\", \"S\", \"This\"], [\" java\", \" \\\"\", \" {\", \" std\", \" sys\", \" os\", \" n\", \" j\", \" c\", \" *\"], [\"as\", \"oc\", \"ig\", \"emic\", \"i\", \"lib\", \"em\", \"asi\", \"ora\", \"af\"], [\".\", \" as\", \" import\", \" from\", \"\\n\", \" .\", \",\", \";\", \".*\", \" ,\"], [\" p\", \" t\", \" pl\", \" r\", \" q\", \" w\", \" sv\", \" u\", \" np\", \" s\"], [\"d\", \"raw\", \"yp\", \"b\", \"sql\", \"ng\", \"t\", \"anda\", \"yth\", \"print\"], [\" import\", \"\\n\", \" from\", \";\", \",\", \" as\", \" ;\", \" ,\", \".\", \"2\"], [\"\\n\", \".\", \" (\", \",\", \"\\n\\n\", \":\", \" and\", \"-\", \"<|endoftext|>\", \"\\\"\"], [\" pand\", \" p\", \" random\", \" n\", \" sys\", \" json\", \" time\", \" os\", \" text\", \" std\"], [\"umpy\", \"c\", \"map\", \"d\", \"t\", \"db\", \"ginx\", \"th\", \"y\", \"p\"], [\" as\", \"\\n\", \".\", \" import\", \"as\", \" from\", \"_\", \" .\", \" main\", \",\"]], \"correctTokenRank\": [3696, 21, 0, 1, 0, 0, 1, 736, 3, 0, 0], \"correctTokenLogProb\": [-10.417813301086426, -4.883296012878418, -0.010759908705949783, -1.147552251815796, -0.10044531524181366, -0.04631408676505089, -2.0012145042419434, -19.116857528686523, -3.355501413345337, -0.024193763732910156, -0.01034693792462349]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7b6a8fcb6200>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import circuitsvis as cv  # optional dep, install with pip install circuitsvis\n",
        "\n",
        "# Let's make a longer prompt and see the log probabilities of the tokens\n",
        "logits, cache = model.run_with_cache(example_prompt)\n",
        "cv.logits.token_log_probs(\n",
        "    model.to_tokens(example_prompt),\n",
        "    model(example_prompt)[0].log_softmax(dim=-1),\n",
        "    model.to_string,\n",
        ")\n",
        "# hover on the output to see the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "6976ccfee67d492399e41a575523a9c3",
            "a17bde7e01ed4fc7ac08010cbe5184ba",
            "a32bf713d37b40488a97110387de2d29",
            "4544c1d6343c42c5ad2b3761e0efd929",
            "cd7f1897215c48b88e2fa0d83f575d2e",
            "f2b4582ab7b64ece9851c9083b922f0d",
            "fe0acbf6ea334a27b510be7f69f5dd21",
            "d686a3e6c6a34ef89089a81533f96b34",
            "b5c342c18d004aa88bcac63af3f52024",
            "b8b71c6b371a4d7183b6e4953af28488",
            "1b21dedae2734ab7adc5bb3d3e7f6536"
          ]
        },
        "id": "MMZTPCfZ08RO",
        "outputId": "d76ef1dc-e3b5-41fa-90a2-dc1fa7e91c4b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6976ccfee67d492399e41a575523a9c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-c1d03c8a-8eaf\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-c1d03c8a-8eaf\",\n",
              "      TokenLogProbs,\n",
              "      {\"prompt\": [\"<|endoftext|>\", \"import\", \" pand\", \"as\", \" as\", \" p\", \"d\", \"\\n\", \"\\n\", \"import\", \" pand\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\", \".\", \"p\", \"and\", \"as\"], \"topKLogProbs\": [[-2.7758164405822754, -3.2780957221984863, -3.7250027656555176, -3.9423298835754395, -3.9997124671936035, -4.458624362945557, -4.482798099517822, -4.697764873504639, -4.749501705169678, -4.8580403327941895], [-2.3758385181427, -3.068216562271118, -3.091959238052368, -3.1538641452789307, -3.5384533405303955, -3.7298614978790283, -3.862719774246216, -3.9566843509674072, -4.159669876098633, -4.383299827575684], [-0.010759908705949783, -4.686731815338135, -8.3295259475708, -9.024802207946777, -9.636832237243652, -9.813424110412598, -9.996864318847656, -10.127212524414062, -10.25009822845459, -10.353031158447266], [-0.8113053441047668, -1.1475498676300049, -2.651775598526001, -3.237067461013794, -3.5722086429595947, -3.7160608768463135, -4.87337064743042, -4.979672908782959, -6.025482654571533, -6.086181163787842], [-0.10044574737548828, -3.5453310012817383, -4.320099830627441, -5.197890281677246, -5.269137382507324, -5.370469093322754, -5.639592170715332, -5.767416954040527, -5.8428239822387695, -5.898097038269043], [-0.04631351679563522, -5.139204978942871, -5.973151206970215, -6.065484046936035, -6.095746040344238, -6.314694404602051, -6.346583366394043, -6.363905906677246, -6.408568382263184, -6.679604530334473], [-1.1779844760894775, -2.0012094974517822, -2.084261178970337, -3.022209405899048, -3.178417444229126, -3.1975290775299072, -3.3417246341705322, -3.4802210330963135, -4.547013282775879, -4.937216758728027], [-0.00020990552729927003, -10.467241287231445, -10.91457748413086, -11.199028015136719, -11.26669692993164, -11.55479621887207, -11.833471298217773, -11.89494514465332, -12.094356536865234, -12.215801239013672], [-0.3154279887676239, -1.8048880100250244, -4.995521545410156, -5.054084777832031, -5.084529876708984, -5.6043853759765625, -5.8497819900512695, -5.915871620178223, -6.191018104553223, -6.306467056274414], [-1.712167739868164, -1.8135404586791992, -3.4017953872680664, -3.507126808166504, -3.5741348266601562, -3.6887197494506836, -3.783381462097168, -3.9898061752319336, -4.502359390258789, -4.62847900390625], [-0.0007949291029945016, -8.38618278503418, -9.737712860107422, -10.52857780456543, -10.734195709228516, -10.762187004089355, -10.863370895385742, -10.890727043151855, -11.059216499328613, -11.06995964050293], [-0.28996697068214417, -1.752142310142517, -4.072625637054443, -5.174093723297119, -5.427292346954346, -5.566249370574951, -5.989420413970947, -6.000919818878174, -6.2678914070129395, -6.3184685707092285], [-2.510058641433716, -3.5196516513824463, -3.692521333694458, -3.741795778274536, -3.801645517349243, -4.077491760253906, -4.128735542297363, -4.216495513916016, -4.458408355712891, -4.580563545227051], [-1.0873913764953613, -1.6986050605773926, -2.259523868560791, -2.9638428688049316, -2.9843945503234863, -3.2608914375305176, -3.9290432929992676, -4.007381916046143, -4.126743793487549, -4.342831134796143], [-0.002290009055286646, -8.647297859191895, -8.78466510772705, -8.786803245544434, -9.00344181060791, -9.169877052307129, -9.222695350646973, -9.486115455627441, -9.580061912536621, -9.60826587677002], [-0.15997016429901123, -2.5792055130004883, -3.6929025650024414, -4.225651741027832, -5.190908432006836, -5.455413818359375, -5.697607040405273, -6.238163948059082, -6.971465110778809, -7.092559814453125], [-2.53598690032959, -2.7902002334594727, -3.714832305908203, -4.1527099609375, -4.21153450012207, -4.319829940795898, -4.408154487609863, -4.696488380432129, -4.741306304931641, -4.826129913330078], [-0.21851861476898193, -4.035447597503662, -4.318356990814209, -4.608267307281494, -4.690043926239014, -4.766747951507568, -4.909116268157959, -5.136928081512451, -5.3544793128967285, -5.681429386138916], [-0.0013705631718039513, -8.28081226348877, -8.969544410705566, -9.474469184875488, -9.639763832092285, -9.939923286437988, -9.983292579650879, -10.001748085021973, -10.236310005187988, -10.290974617004395], [-0.1018194705247879, -3.8597846031188965, -4.229136943817139, -4.274758815765381, -4.458580493927002, -5.275182247161865, -5.424008846282959, -6.084373950958252, -7.070072650909424, -7.169148921966553], [-1.1119306087493896, -3.4476687908172607, -4.356842994689941, -4.478464126586914, -4.6257476806640625, -4.651226997375488, -4.798203468322754, -4.830798149108887, -4.850458145141602, -4.911602020263672], [-0.04314332455396652, -5.950521469116211, -6.09432315826416, -6.3129777908325195, -6.452288627624512, -6.66690731048584, -6.715679168701172, -6.828858375549316, -6.972813606262207, -7.017853736877441], [-0.0013993718894198537, -8.10895824432373, -8.788386344909668, -9.334357261657715, -9.846575736999512, -10.014843940734863, -10.029206275939941, -10.073241233825684, -10.150704383850098, -10.275946617126465], [-0.07747387886047363, -4.219731330871582, -4.6066694259643555, -4.7758684158325195, -4.922308921813965, -4.982632637023926, -5.65596866607666, -5.902035713195801, -7.080960273742676, -7.3211565017700195], [-0.7612418532371521, -3.591416358947754, -4.594532012939453, -4.602210998535156, -4.741824150085449, -4.764769554138184, -4.863846778869629, -5.042320251464844, -5.149860382080078, -5.338939666748047], [-0.016312340274453163, -6.38423490524292, -7.002233982086182, -7.026632785797119, -7.191262722015381, -7.220766544342041, -7.539820194244385, -7.723551273345947, -8.049583435058594, -8.119288444519043], [-0.001046348363161087, -8.459647178649902, -9.251755714416504, -9.29854679107666, -9.788895606994629, -10.033379554748535, -10.399405479431152, -10.497078895568848, -10.534344673156738, -10.675021171569824], [-0.06516388803720474, -4.136288166046143, -4.563827037811279, -5.254236698150635, -5.265397548675537, -5.274272441864014, -5.922997951507568, -6.009068965911865, -6.836872577667236, -7.451451778411865], [-0.6135091781616211, -3.927936553955078, -4.3953046798706055, -4.736804962158203, -4.800531387329102, -4.892116546630859, -5.117399215698242, -5.157709121704102, -5.170513153076172, -5.251587867736816], [-0.009396021254360676, -6.653310298919678, -7.491257190704346, -7.562102794647217, -7.669596195220947, -7.753570079803467, -7.879333019256592, -8.173062324523926, -8.299509048461914, -8.537391662597656], [-0.0008192281820811331, -8.839360237121582, -9.370474815368652, -9.679915428161621, -9.827832221984863, -10.208827018737793, -10.678282737731934, -10.684828758239746, -10.691584587097168, -10.746676445007324], [-0.06954054534435272, -4.119482517242432, -4.343434810638428, -4.991823673248291, -5.327908039093018, -5.799562931060791, -5.9733452796936035, -6.248815059661865, -6.275913715362549, -6.9283623695373535], [-0.5372496247291565, -4.273231506347656, -4.346989631652832, -4.800022125244141, -4.910107612609863, -4.966789245605469, -4.967474937438965, -5.159051895141602, -5.197806358337402, -5.38250732421875], [-0.005643506534397602, -6.902757167816162, -7.834709644317627, -8.050631523132324, -8.15540885925293, -8.224038124084473, -8.436478614807129, -8.553072929382324, -8.635706901550293, -8.951342582702637], [-0.000676998752169311, -9.200004577636719, -9.534952163696289, -9.907419204711914, -9.912900924682617, -10.312520980834961, -10.816595077514648, -10.85630989074707, -10.908973693847656, -10.909172058105469], [-0.07933967560529709, -3.711254835128784, -4.598090648651123, -4.845405101776123, -5.277493000030518, -5.9446635246276855, -6.054624080657959, -6.178719997406006, -6.437889575958252, -6.5969719886779785], [-0.4671004116535187, -4.217243671417236, -4.732283115386963, -4.845397472381592, -4.942175388336182, -4.994364261627197, -5.036344051361084, -5.23864221572876, -5.3047308921813965, -5.414228916168213], [-0.003510267473757267, -7.214547157287598, -8.237847328186035, -8.465922355651855, -8.541532516479492, -8.700453758239746, -9.032917976379395, -9.065508842468262, -9.171650886535645, -9.30381965637207], [-0.0005847889697179198, -9.498475074768066, -9.716130256652832, -9.900343894958496, -10.04582691192627, -10.421963691711426, -10.89939022064209, -10.9011812210083, -11.11176586151123, -11.128273963928223]], \"topKTokens\": [[\"\\n\", \"The\", \"\\\"\", \"A\", \"I\", \"In\", \".\", \"It\", \"S\", \"This\"], [\" java\", \" \\\"\", \" {\", \" std\", \" sys\", \" os\", \" n\", \" j\", \" c\", \" *\"], [\"as\", \"oc\", \"ig\", \"emic\", \"i\", \"lib\", \"em\", \"asi\", \"ora\", \"af\"], [\".\", \" as\", \" import\", \" from\", \"\\n\", \" .\", \",\", \";\", \".*\", \" ,\"], [\" p\", \" t\", \" pl\", \" r\", \" q\", \" w\", \" sv\", \" u\", \" np\", \" s\"], [\"d\", \"raw\", \"yp\", \"b\", \"sql\", \"ng\", \"t\", \"anda\", \"yth\", \"print\"], [\" import\", \"\\n\", \" from\", \";\", \",\", \" as\", \" ;\", \" ,\", \".\", \"2\"], [\"\\n\", \".\", \" (\", \",\", \"\\n\\n\", \":\", \" and\", \"-\", \"<|endoftext|>\", \"\\\"\"], [\"import\", \"from\", \"def\", \"#\", \"package\", \"p\", \"export\", \"class\", \"\\\"\\\"\\\"\", \"P\"], [\" pand\", \" p\", \" n\", \" random\", \" json\", \" time\", \" sys\", \" os\", \" std\", \" c\"], [\"as\", \"asi\", \"a\", \"al\", \"asa\", \"us\", \" as\", \"asher\", \"asm\", \"oc\"], [\".\", \" as\", \" .\", \" p\", \" from\", \" import\", \"\\n\", \" data\", \"._\", \"_\"], [\"p\", \"core\", \"h\", \"utils\", \"py\", \"db\", \"lib\", \"as\", \"text\", \"cont\"], [\"and\", \"d\", \"do\", \"yd\", \"ars\", \"ip\", \"open\", \"da\", \"print\", \"db\"], [\"as\", \"at\", \"ora\", \"orum\", \"oras\", \"ata\", \"asi\", \"acity\", \"ag\", \"af\"], [\".\", \" as\", \"\\n\", \" import\", \"._\", \" .\", \".*\", \"_\", \" p\", \" from\"], [\"p\", \"P\", \"Par\", \"File\", \"Pand\", \"Data\", \"path\", \"common\", \"core\", \"db\"], [\"and\", \"print\", \"ip\", \"d\", \"db\", \"do\", \"ars\", \"da\", \"anded\", \"rel\"], [\"as\", \"a\", \"ars\", \"asi\", \"asm\", \"ae\", \"ag\", \"ases\", \"asa\", \"asp\"], [\".\", \" as\", \"\\n\", \" import\", \"._\", \".*\", \"_\", \" .\", \"2\", \" module\"], [\"p\", \"P\", \"import\", \"core\", \"common\", \"cont\", \"path\", \"h\", \"py\", \"lib\"], [\"and\", \"anda\", \"anded\", \"andan\", \"ango\", \"print\", \"ip\", \"d\", \".\", \" pand\"], [\"as\", \"a\", \"ars\", \"ast\", \"asp\", \"aps\", \"has\", \"asm\", \"ar\", \"asi\"], [\".\", \"._\", \"\\n\", \"_\", \" import\", \" as\", \".*\", \" .\", \"2\", \" from\"], [\"p\", \"P\", \"import\", \"py\", \"cont\", \"h\", \"core\", \"lib\", \"common\", \"path\"], [\"and\", \"anda\", \"andan\", \"anded\", \"ango\", \"ander\", \"ant\", \" pand\", \"ande\", \"andi\"], [\"as\", \"a\", \"ast\", \"ars\", \"has\", \"asp\", \"ar\", \"asm\", \"os\", \"is\"], [\".\", \"._\", \"\\n\", \" import\", \"_\", \" as\", \" .\", \".*\", \" from\", \";\"], [\"p\", \"P\", \"py\", \"h\", \"import\", \"cont\", \"lib\", \"core\", \"python\", \"c\"], [\"and\", \"anda\", \"ander\", \"andan\", \"ango\", \"anded\", \"ant\", \" pand\", \"andi\", \"ande\"], [\"as\", \"a\", \"ast\", \"ars\", \"has\", \"asp\", \"ar\", \"os\", \"is\", \"asm\"], [\".\", \"\\n\", \"._\", \" as\", \" import\", \"_\", \" .\", \".*\", \" from\", \";\"], [\"p\", \"py\", \"P\", \"h\", \"import\", \"python\", \"cont\", \"lib\", \"c\", \"core\"], [\"and\", \"anda\", \"ander\", \"andan\", \"ango\", \"ant\", \"anded\", \" pand\", \"andi\", \"ande\"], [\"as\", \"a\", \"ast\", \"has\", \"ars\", \"asp\", \"is\", \"ass\", \"os\", \"ar\"], [\".\", \"\\n\", \"._\", \" as\", \" import\", \" from\", \" .\", \"_\", \".*\", \";\"], [\"p\", \"py\", \"P\", \"python\", \"h\", \"import\", \"cont\", \"c\", \"lib\", \"r\"], [\"and\", \"anda\", \"ander\", \"ant\", \"andan\", \"ango\", \"andi\", \" pand\", \"anded\", \"ande\"], [\"as\", \"a\", \"ast\", \"has\", \"ars\", \"asp\", \"is\", \"ass\", \"ar\", \"os\"]], \"correctTokenRank\": [3696, 21, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \"correctTokenLogProb\": [-10.417818069458008, -4.883293151855469, -0.010759908705949783, -1.1475498676300049, -0.10044574737548828, -0.04631351679563522, -2.0012094974517822, -0.00020990552729927003, -0.3154279887676239, -1.712167739868164, -0.0007949291029945016, -0.28996697068214417, -2.510058641433716, -1.0873913764953613, -0.002290009055286646, -0.15997016429901123, -2.53598690032959, -0.21851861476898193, -0.0013705631718039513, -0.1018194705247879, -1.1119306087493896, -0.04314332455396652, -0.0013993718894198537, -0.07747387886047363, -0.7612418532371521, -0.016312340274453163, -0.001046348363161087, -0.06516388803720474, -0.6135091781616211, -0.009396021254360676, -0.0008192281820811331, -0.06954054534435272, -0.5372496247291565, -0.005643506534397602, -0.000676998752169311, -0.07933967560529709, -0.4671004116535187, -0.003510267473757267, -0.0005847889697179198]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7b6b94efed10>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generation = model.generate(\n",
        "    \"import pandas as pd\\n\",\n",
        "    stop_at_eos=True,\n",
        "    temperature=0,\n",
        "    verbose=True,\n",
        "    max_new_tokens=32,\n",
        ")\n",
        "logits, cache = model.run_with_cache(generation)\n",
        "cv.logits.token_log_probs(\n",
        "    model.to_tokens(generation),\n",
        "    model(generation)[0].log_softmax(dim=-1),\n",
        "    model.to_string,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58euzX-P0A-8"
      },
      "source": [
        "### Probing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfM7zDxETuxQ",
        "outputId": "fc341ee3-6cc9-4906-a46c-5cb70ee89bf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:31<00:00,  1.24s/it]\n"
          ]
        }
      ],
      "source": [
        "code_features = []\n",
        "wiki_features = []\n",
        "batch_size = 4\n",
        "\n",
        "for b in tqdm(range(0, 100, batch_size)):\n",
        "    # Code\n",
        "    with torch.no_grad():\n",
        "        _, cache = model.run_with_cache(code_tokens[b:b+batch_size])\n",
        "\n",
        "        sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sae(\n",
        "            cache[sae.cfg.hook_point]\n",
        "        )\n",
        "\n",
        "    code_features.append(feature_acts.cpu())\n",
        "    del cache\n",
        "\n",
        "    # Wiki\n",
        "    with torch.no_grad():\n",
        "        _, cache = model.run_with_cache(wiki_tokens[b:b+batch_size])\n",
        "\n",
        "        sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sae(\n",
        "            cache[sae.cfg.hook_point]\n",
        "        )\n",
        "\n",
        "    wiki_features.append(feature_acts.cpu())\n",
        "    del cache\n",
        "\n",
        "code_features = torch.cat(code_features, dim=0)\n",
        "wiki_features = torch.cat(wiki_features, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTSDYeSFcKHS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "idx = torch.tensor(np.random.choice(range(1024), 128, replace=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGZLZS8YRaIN"
      },
      "outputs": [],
      "source": [
        "n_features = code_features.shape[-1]\n",
        "\n",
        "X = torch.cat([\n",
        "    code_features[:, idx], wiki_features[:, idx]\n",
        "], dim=0).reshape(-1, n_features)\n",
        "\n",
        "y = torch.cat([\n",
        "    torch.ones(X.shape[0] // 2), torch.zeros(X.shape[0] // 2)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbLnt3z2ZmkV",
        "outputId": "cb77bd6a-9c1a-46da-8c77-3c938e55191c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24576/24576 [06:27<00:00, 63.38it/s]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)\n",
        "\n",
        "f1_scores = {}\n",
        "\n",
        "# Iterate over each variable\n",
        "for i in tqdm(range(X.shape[1])):\n",
        "    # Reset model parameters\n",
        "    lr = LogisticRegression(penalty=None)\n",
        "\n",
        "    lr.fit(X_train[:, i, None], y_train)\n",
        "\n",
        "    # Evaluate the lr on the validation set\n",
        "    y_pred = lr.predict(X_val[:, i, None])\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "\n",
        "    # Store the F1 score for the current variable\n",
        "    f1_scores[i] = f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWZbRGT0dL7Y",
        "outputId": "1deb4113-471a-43df-afea-2df0c63158c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The top variable is 21130 with an F1 score of 0.7168\n"
          ]
        }
      ],
      "source": [
        "# Sort the variables based on F1 score in descending order\n",
        "sorted_vars = sorted(f1_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Get the top variable index and its F1 score\n",
        "top_var_idx, top_var_f1 = sorted_vars[0]\n",
        "\n",
        "print(f\"The top variable is {top_var_idx} with an F1 score of {top_var_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "duSw8dG3kOqh",
        "outputId": "7c273b09-7885-46a5-a83e-e4bd9b7b596c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%228-res-jb%22%2C%20%22index%22%3A%20%2221130%22%7D%5D'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
        "\n",
        "get_neuronpedia_quick_list([21130], layer=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gq1T1smyqlQ"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8sWvyplO-j7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, lambda_=1e-5):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lambda_ = lambda_\n",
        "\n",
        "        # Initialize weights and biases as nn.Parameters\n",
        "        self.W_enc = nn.Parameter(torch.randn(input_size, hidden_size) * 0.01)\n",
        "        self.b_enc = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.W_dec = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
        "        self.b_dec = nn.Parameter(torch.zeros(input_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = F.linear(x, self.W_enc.T, self.b_enc)\n",
        "        encoded = F.relu(encoded)\n",
        "        decoded = F.linear(encoded, self.W_dec.T, self.b_dec)\n",
        "        return encoded, decoded\n",
        "\n",
        "    def loss_function(self, x):\n",
        "        encoded, decoded = self.forward(x)\n",
        "        l2_loss = F.mse_loss(decoded, x, reduction='sum')\n",
        "        l1_loss = self.lambda_ * torch.sum(torch.abs(encoded))\n",
        "        total_loss = l2_loss + l1_loss\n",
        "        return total_loss, l2_loss, l1_loss\n",
        "\n",
        "    def from_hooked(self, sae):\n",
        "        assert sae.W_enc.shape == self.W_enc.shape\n",
        "        assert sae.b_enc.shape == self.b_enc.shape\n",
        "        assert sae.W_dec.shape == self.W_dec.shape\n",
        "        assert sae.b_dec.shape == self.b_dec.shape\n",
        "        \n",
        "        self.W_enc.data = sae.W_enc.data.clone()\n",
        "        self.b_enc.data = sae.b_enc.data.clone()\n",
        "        self.W_dec.data = sae.W_dec.data.clone()\n",
        "        self.b_dec.data = sae.b_dec.data.clone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "magoCvrF-9Ps"
      },
      "outputs": [],
      "source": [
        "torch_sae = SparseAutoencoder(\n",
        "    input_size=sae.d_in,\n",
        "    hidden_size=sae.d_sae,\n",
        "    lambda_=sae.cfg.l1_coefficient\n",
        ")\n",
        "\n",
        "torch_sae.from_hooked(sae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IzHuwJHmBwtM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModel\n",
        "from peft import LoraConfig, PeftModel\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "# Set up the LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"encoder\", \"decoder\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "# Create the LoRA model\n",
        "lora_model = PeftModel(torch_sae, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "01SO3c1LzU61",
        "outputId": "9b62d2e8-c450-4bcc-819b-4ba097a8ca6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavide-ghilardi0\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/juice2/scr2/ghilardi/home/mats-interp/experiments/wandb/run-20240513_050047-3hz4g0sr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/davide-ghilardi0/sae-fine-tuning/runs/3hz4g0sr' target=\"_blank\">floral-totem-4</a></strong> to <a href='https://wandb.ai/davide-ghilardi0/sae-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/davide-ghilardi0/sae-fine-tuning' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae-fine-tuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/davide-ghilardi0/sae-fine-tuning/runs/3hz4g0sr' target=\"_blank\">https://wandb.ai/davide-ghilardi0/sae-fine-tuning/runs/3hz4g0sr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 80770/80770 [37:20<00:00, 36.04it/s]\n"
          ]
        }
      ],
      "source": [
        "# Initialize wandb\n",
        "wandb.init(project=\"sae-fine-tuning\")\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "# Set up the training loop\n",
        "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=3e-4)\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in tqdm(tokens):\n",
        "        inputs = batch['tokens']\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _, cache = model.run_with_cache(inputs)\n",
        "\n",
        "        act = cache['blocks.8.hook_resid_pre'].reshape(-1, sae.d_in) # bs * pos, d_in\n",
        "        del cache\n",
        "        \n",
        "        loss, l2_loss, l1_loss = lora_model.loss_function(act)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Log losses to wandb\n",
        "        wandb.log({\"loss\": loss.item(), \"mse_loss\": l2_loss.item(), \"l1_loss\": l1_loss.item()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YiCyElKqAhve"
      },
      "outputs": [],
      "source": [
        "lora_sae = SparseAutoencoder(sae.d_in, sae.d_sae)\n",
        "lora_sae.from_hooked(sae)\n",
        "state_dict = torch.load('../models/lora_model.pth')\n",
        "\n",
        "# Adjust LoRA weights\n",
        "lora_encoder = torch.matmul(\n",
        "    state_dict[\"base_model.model.encoder.lora_B.default.weight\"],\n",
        "    state_dict[\"base_model.model.encoder.lora_A.default.weight\"]\n",
        ")\n",
        "\n",
        "lora_decoder = torch.matmul(\n",
        "    state_dict[\"base_model.model.decoder.lora_B.default.weight\"],\n",
        "    state_dict[\"base_model.model.decoder.lora_A.default.weight\"]\n",
        ")\n",
        "\n",
        "lora_sae.W_enc += lora_encoder.T\n",
        "lora_sae.W_dec += lora_decoder.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original: 2.0879335403442383\n",
            "Reconstruction: 2.3907034397125244\n",
            "Zero Ablation: 11.773224830627441\n",
            "Ratio: 0.968739205637311\n"
          ]
        }
      ],
      "source": [
        "batch_tokens = tokens[:16]\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
        "    encoded, decoded = lora_sae(\n",
        "        cache[sae_group.cfg.hook_point]\n",
        "    )\n",
        "\n",
        "reconstruction_test(batch_tokens, 'resid_pre', 8, decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', '\\n', '<', '!', 'DO', 'CT', 'Y', 'PE', ' html', '>', '\\n', '<', 'html', ' lang', '=\"', 'en', '\">', '\\n', '<', 'head', '>', '\\n', ' ', ' ', ' ', ' <', 'meta', ' chars', 'et', '=\"', 'UTF', '-', '8', '\">', '\\n', ' ', ' ', ' ', ' <', 'meta', ' name', '=\"', 'view', 'port', '\"', ' content', '=\"', 'width', '=', 'device', '-', 'width', ',', ' initial', '-', 'scale', '=', '1', '.', '0', '\">', '\\n', ' ', ' ', ' ', ' <', 'title', '>', 'My', ' Web', 'page', '</', 'title', '>', '\\n', ' ', ' ', ' ', ' <', 'style', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' .', 'container', ' {', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' max', '-', 'width', ':', ' 800', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' margin', ':', ' 20', 'px', ' auto', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' padding', ':', ' 0', ' 20', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' }', '\\n', ' ', ' ', ' ', ' </', 'style', '>', '\\n', '</', 'head', '>', '\\n', '<', 'body', '>', '\\n', ' ', ' ', ' ', ' <', 'header', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '1', '>', 'Welcome', ' to', ' My', ' Web', 'page', '</', 'h', '1', '>', '\\n', ' ', ' ', ' ', ' </', 'header', '>', '\\n', ' ', ' ', ' ', ' <', 'div', ' class', '=\"', 'container', '\">', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'About', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'This', ' is', ' a', ' sample', ' webpage', '.</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'Contact', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'You', ' can', ' reach', ' us', ' at', ' example', '@', 'email', '.', 'com', '</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' </']\n",
            "Tokenized answer: [' num']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14090</span><span style=\"font-weight: bold\">    Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.44</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | num|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m14090\u001b[0m\u001b[1m    Logit:  \u001b[0m\u001b[1;36m1.44\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | num|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 19.97 Prob: 54.19% Token: |body|\n",
            "Top 1th token. Logit: 19.50 Prob: 34.18% Token: |div|\n",
            "Top 2th token. Logit: 17.37 Prob:  4.06% Token: |section|\n",
            "Top 3th token. Logit: 15.92 Prob:  0.95% Token: |html|\n",
            "Top 4th token. Logit: 15.74 Prob:  0.79% Token: |foot|\n",
            "Top 5th token. Logit: 15.70 Prob:  0.76% Token: |p|\n",
            "Top 6th token. Logit: 15.67 Prob:  0.74% Token: |header|\n",
            "Top 7th token. Logit: 15.30 Prob:  0.51% Token: |block|\n",
            "Top 8th token. Logit: 14.18 Prob:  0.17% Token: |head|\n",
            "Top 9th token. Logit: 14.07 Prob:  0.15% Token: | body|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' num'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14090</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' num'\u001b[0m, \u001b[1;36m14090\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens import utils\n",
        "\n",
        "example_prompt = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>My Webpage</title>\n",
        "    <style>\n",
        "        .container {\n",
        "            max-width: 800px;\n",
        "            margin: 20px auto;\n",
        "            padding: 0 20px;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <header>\n",
        "        <h1>Welcome to My Webpage</h1>\n",
        "    </header>\n",
        "    <div class=\"container\">\n",
        "        <section>\n",
        "            <h2>About Us</h2>\n",
        "            <p>This is a sample webpage.</p>\n",
        "        </section>\n",
        "        <section>\n",
        "            <h2>Contact Us</h2>\n",
        "            <p>You can reach us at example@email.com</p>\n",
        "        </section>\n",
        "    </\"\"\"\n",
        "example_answer = \"num\"\n",
        "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', '\\n', '<', '!', 'DO', 'CT', 'Y', 'PE', ' html', '>', '\\n', '<', 'html', ' lang', '=\"', 'en', '\">', '\\n', '<', 'head', '>', '\\n', ' ', ' ', ' ', ' <', 'meta', ' chars', 'et', '=\"', 'UTF', '-', '8', '\">', '\\n', ' ', ' ', ' ', ' <', 'meta', ' name', '=\"', 'view', 'port', '\"', ' content', '=\"', 'width', '=', 'device', '-', 'width', ',', ' initial', '-', 'scale', '=', '1', '.', '0', '\">', '\\n', ' ', ' ', ' ', ' <', 'title', '>', 'My', ' Web', 'page', '</', 'title', '>', '\\n', ' ', ' ', ' ', ' <', 'style', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' .', 'container', ' {', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' max', '-', 'width', ':', ' 800', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' margin', ':', ' 20', 'px', ' auto', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' padding', ':', ' 0', ' 20', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' }', '\\n', ' ', ' ', ' ', ' </', 'style', '>', '\\n', '</', 'head', '>', '\\n', '<', 'body', '>', '\\n', ' ', ' ', ' ', ' <', 'header', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '1', '>', 'Welcome', ' to', ' My', ' Web', 'page', '</', 'h', '1', '>', '\\n', ' ', ' ', ' ', ' </', 'header', '>', '\\n', ' ', ' ', ' ', ' <', 'div', ' class', '=\"', 'container', '\">', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'About', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'This', ' is', ' a', ' sample', ' webpage', '.</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'Contact', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'You', ' can', ' reach', ' us', ' at', ' example', '@', 'email', '.', 'com', '</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' </']\n",
            "Tokenized answer: [' num']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6250</span><span style=\"font-weight: bold\">     Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.91</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | num|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m6250\u001b[0m\u001b[1m     Logit:  \u001b[0m\u001b[1;36m4.91\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | num|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 23.53 Prob: 43.35% Token: |body|\n",
            "Top 1th token. Logit: 22.65 Prob: 17.97% Token: |section|\n",
            "Top 2th token. Logit: 22.44 Prob: 14.60% Token: |h|\n",
            "Top 3th token. Logit: 22.29 Prob: 12.61% Token: |p|\n",
            "Top 4th token. Logit: 21.31 Prob:  4.73% Token: |div|\n",
            "Top 5th token. Logit: 20.34 Prob:  1.79% Token: |span|\n",
            "Top 6th token. Logit: 19.29 Prob:  0.63% Token: |li|\n",
            "Top 7th token. Logit: 18.96 Prob:  0.45% Token: |style|\n",
            "Top 8th token. Logit: 18.80 Prob:  0.38% Token: |head|\n",
            "Top 9th token. Logit: 18.71 Prob:  0.35% Token: |header|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' num'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6250</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' num'\u001b[0m, \u001b[1;36m6250\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "SUBFOLDER = f\"blocks.8.hook_resid_pre\"\n",
        "\n",
        "hook_point = sae_group.cfg.hook_point\n",
        "\n",
        "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
        "sae_out, feature_acts, loss, mse_loss, l1_loss, _ = sae(\n",
        "    cache[sae_group.cfg.hook_point]\n",
        ")\n",
        "\n",
        "with model.hooks(\n",
        "    fwd_hooks=[\n",
        "        (\n",
        "            hook_point,\n",
        "            partial(reconstr_hook, sae_out=sae_out),\n",
        "        )\n",
        "    ]\n",
        "): utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenized prompt: ['<|endoftext|>', '\\n', '<', '!', 'DO', 'CT', 'Y', 'PE', ' html', '>', '\\n', '<', 'html', ' lang', '=\"', 'en', '\">', '\\n', '<', 'head', '>', '\\n', ' ', ' ', ' ', ' <', 'meta', ' chars', 'et', '=\"', 'UTF', '-', '8', '\">', '\\n', ' ', ' ', ' ', ' <', 'meta', ' name', '=\"', 'view', 'port', '\"', ' content', '=\"', 'width', '=', 'device', '-', 'width', ',', ' initial', '-', 'scale', '=', '1', '.', '0', '\">', '\\n', ' ', ' ', ' ', ' <', 'title', '>', 'My', ' Web', 'page', '</', 'title', '>', '\\n', ' ', ' ', ' ', ' <', 'style', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' .', 'container', ' {', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' max', '-', 'width', ':', ' 800', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' margin', ':', ' 20', 'px', ' auto', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' padding', ':', ' 0', ' 20', 'px', ';', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' }', '\\n', ' ', ' ', ' ', ' </', 'style', '>', '\\n', '</', 'head', '>', '\\n', '<', 'body', '>', '\\n', ' ', ' ', ' ', ' <', 'header', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '1', '>', 'Welcome', ' to', ' My', ' Web', 'page', '</', 'h', '1', '>', '\\n', ' ', ' ', ' ', ' </', 'header', '>', '\\n', ' ', ' ', ' ', ' <', 'div', ' class', '=\"', 'container', '\">', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'About', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'This', ' is', ' a', ' sample', ' webpage', '.</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'section', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'h', '2', '>', 'Contact', ' Us', '</', 'h', '2', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' <', 'p', '>', 'You', ' can', ' reach', ' us', ' at', ' example', '@', 'email', '.', 'com', '</', 'p', '>', '\\n', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' </', 'section', '>', '\\n', ' ', ' ', ' ', ' </']\n",
            "Tokenized answer: [' num']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
              "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12379</span><span style=\"font-weight: bold\">    Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.05</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span><span style=\"font-weight: bold\">% Token: | num|</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Performance on answer token:\n",
              "\u001b[1mRank: \u001b[0m\u001b[1;36m12379\u001b[0m\u001b[1m    Logit:  \u001b[0m\u001b[1;36m2.05\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1m% Token: | num|\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 0th token. Logit: 22.64 Prob: 71.55% Token: |body|\n",
            "Top 1th token. Logit: 20.92 Prob: 12.81% Token: |div|\n",
            "Top 2th token. Logit: 20.84 Prob: 11.90% Token: |section|\n",
            "Top 3th token. Logit: 18.51 Prob:  1.15% Token: |p|\n",
            "Top 4th token. Logit: 17.62 Prob:  0.47% Token: |header|\n",
            "Top 5th token. Logit: 17.53 Prob:  0.43% Token: |html|\n",
            "Top 6th token. Logit: 17.09 Prob:  0.28% Token: |span|\n",
            "Top 7th token. Logit: 16.45 Prob:  0.15% Token: |block|\n",
            "Top 8th token. Logit: 16.28 Prob:  0.12% Token: |h|\n",
            "Top 9th token. Logit: 15.94 Prob:  0.09% Token: | body|\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' num'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12379</span><span style=\"font-weight: bold\">)]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' num'\u001b[0m, \u001b[1;36m12379\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "SUBFOLDER = f\"blocks.8.hook_resid_pre\"\n",
        "\n",
        "hook_point = sae_group.cfg.hook_point\n",
        "\n",
        "logits, cache = model.run_with_cache(example_prompt, prepend_bos=True)\n",
        "encoded, decoded = lora_sae(\n",
        "    cache[sae_group.cfg.hook_point]\n",
        ")\n",
        "\n",
        "with model.hooks(\n",
        "    fwd_hooks=[\n",
        "        (\n",
        "            hook_point,\n",
        "            partial(reconstr_hook, sae_out=decoded),\n",
        "        )\n",
        "    ]\n",
        "): utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fancy_einsum import einsum\n",
        "\n",
        "token = model.to_tokens(' np', prepend_bos=False)[0]\n",
        "\n",
        "base_sim = einsum(\n",
        "    'i j, j k -> i k',\n",
        "    sae.W_dec, model.W_U[:, token]\n",
        ")\n",
        "\n",
        "lora_sim = einsum(\n",
        "    'i j, j k -> i k',\n",
        "    lora_sae.W_dec, model.W_U[:, token]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_base_features = base_sim.argsort(dim=0, descending=True)[:10]\n",
        "bot_base_features = base_sim.argsort(dim=0, descending=False)[:10]\n",
        "\n",
        "top_lora_features = lora_sim.argsort(dim=0, descending=True)[:10]\n",
        "bot_lora_features = lora_sim.argsort(dim=0, descending=False)[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[21963],\n",
              "        [ 6804],\n",
              "        [ 8535],\n",
              "        [13321],\n",
              "        [10244],\n",
              "        [ 1233],\n",
              "        [ 6965],\n",
              "        [   67],\n",
              "        [14759],\n",
              "        [13384]], device='cuda:0')"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_lora_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[21963],\n",
              "        [ 6804],\n",
              "        [ 8535],\n",
              "        [13321],\n",
              "        [14615],\n",
              "        [14759],\n",
              "        [  722],\n",
              "        [ 1233],\n",
              "        [13384],\n",
              "        [10244]], device='cuda:0')"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "top_base_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([80770, 512]), torch.Size([24576, 128]))"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens['tokens'].shape, all_tokens.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 4853, 19120, 10236, 11945, 21030, 22418,  3030, 17487, 18573, 11640],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_delta = (lora_sae.W_dec - sae.W_dec).norm(dim=-1).argsort(descending=True)[:10]\n",
        "max_delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "534e94f366994c508a1c29c303c13e82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Forward passes to cache data for vis:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcd979f759864e75a02380db1aea884a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting vis data from cached data:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Task                                           </span>┃<span style=\"font-weight: bold\"> Time   </span>┃<span style=\"font-weight: bold\"> Pct % </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│ (1) Initialization                             │ 0.00s  │ 0.0%  │\n",
              "│ (2) Forward passes to gather model activations │ 0.15s  │ 1.3%  │\n",
              "│ (3) Computing feature acts from model acts     │ 10.42s │ 86.5% │\n",
              "│ (4) Getting data for tables                    │ 0.01s  │ 0.1%  │\n",
              "│ (5) Getting data for histograms                │ 0.01s  │ 0.1%  │\n",
              "│ (6) Getting data for sequences                 │ 1.44s  │ 11.9% │\n",
              "│ (7) Getting data for quantiles                 │ 0.01s  │ 0.1%  │\n",
              "└────────────────────────────────────────────────┴────────┴───────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTask                                          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTime  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mPct %\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│ (1) Initialization                             │ 0.00s  │ 0.0%  │\n",
              "│ (2) Forward passes to gather model activations │ 0.15s  │ 1.3%  │\n",
              "│ (3) Computing feature acts from model acts     │ 10.42s │ 86.5% │\n",
              "│ (4) Getting data for tables                    │ 0.01s  │ 0.1%  │\n",
              "│ (5) Getting data for histograms                │ 0.01s  │ 0.1%  │\n",
              "│ (6) Getting data for sequences                 │ 1.44s  │ 11.9% │\n",
              "│ (7) Getting data for quantiles                 │ 0.01s  │ 0.1%  │\n",
              "└────────────────────────────────────────────────┴────────┴───────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sae_vis.data_config_classes import SaeVisConfig\n",
        "from sae_vis.data_storing_fns import SaeVisData\n",
        "\n",
        "hook_point = sae_group.cfg.hook_point\n",
        "test_feature_idx_gpt = max_delta.cpu().tolist()\n",
        "\n",
        "feature_vis_config_gpt = SaeVisConfig(\n",
        "    hook_point=hook_point,\n",
        "    features=test_feature_idx_gpt,\n",
        "    batch_size=2048,\n",
        "    minibatch_size_tokens=128,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "sae_vis_data_gpt = SaeVisData.create(\n",
        "    encoder=sae,\n",
        "    model=model,\n",
        "    tokens=tokens[:1000],  # type: ignore\n",
        "    cfg=feature_vis_config_gpt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ed5d2f98add4d37a09478dcc136bdaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Saving feature-centric vis:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "filename = f\"lora_sae_features.html\"\n",
        "sae_vis_data_gpt.save_feature_centric_vis(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Eearly exiting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1024/1024 [00:18<00:00, 54.77it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from sae_lens.training.activations_store import ActivationsStore\n",
        "\n",
        "def get_tokens(\n",
        "    activation_store: ActivationsStore,\n",
        "    n_batches_to_sample_from: int = 2**10,\n",
        "    n_prompts_to_select: int = 4096 * 6,\n",
        "):\n",
        "    all_tokens_list = []\n",
        "    pbar = tqdm(range(n_batches_to_sample_from))\n",
        "    for _ in pbar:\n",
        "        batch_tokens = activation_store.get_batch_tokens()\n",
        "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
        "            : batch_tokens.shape[0]\n",
        "        ]\n",
        "        all_tokens_list.append(batch_tokens)\n",
        "\n",
        "    all_tokens = torch.cat(all_tokens_list, dim=0)\n",
        "    all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
        "    return all_tokens[:n_prompts_to_select]\n",
        "\n",
        "all_tokens = get_tokens(activation_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 64/64 [00:02<00:00, 29.10it/s]\n"
          ]
        }
      ],
      "source": [
        "sub_tokens = all_tokens[:1024]\n",
        "batch_size = 16\n",
        "activations = []\n",
        "\n",
        "for b in tqdm(range(0, len(sub_tokens), batch_size)):\n",
        "    with torch.no_grad():\n",
        "        _, cache = model.run_with_cache(sub_tokens[b:b+batch_size, :-1])\n",
        "    \n",
        "    activations.append(cache[sae_group.cfg.hook_point].cpu())\n",
        "    del cache\n",
        "\n",
        "activations = torch.cat(activations).reshape(-1, 768)\n",
        "labels = sub_tokens[:, 1:].reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_pred = []\n",
        "sae_bs = 4096\n",
        "\n",
        "for b in range(0, len(activations), sae_bs):\n",
        "    sae_out, features_act, *_ = sae(activations[b:b+sae_bs].to('cuda'))\n",
        "    token_pred.append(model.unembed(sae_out[:, None]).argmax(-1))\n",
        "\n",
        "token_pred = torch.cat(token_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_labels = (token_pred == labels).type(torch.int64)[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the logistic regression model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_size = sae.d_sae\n",
        "num_classes = 2\n",
        "\n",
        "# Create an instance of the logistic regression model\n",
        "lr = LogisticRegression(input_size, num_classes).to('cuda')\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(lr.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[62], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Print the loss every 10 epochs\u001b[39;00m\n",
            "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "sae_batch_size = 4096\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for b in range(0, len(activations), sae_batch_size):\n",
        "        # SAE run\n",
        "        with torch.no_grad():\n",
        "            sae_out, features_act, *_ = sae(activations[b:b+sae_bs].to('cuda'))\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = lr(features_act).softmax(-1)\n",
        "        loss = criterion(outputs, train_labels[b:b+sae_bs])\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Print the loss every 10 epochs\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QeZ5LhEnOLkz"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0693740e40a24488a3ca0234371532ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa3529c4cd554e25942d34bd5eec62af",
            "placeholder": "​",
            "style": "IPY_MODEL_600153686cde476cabadd0114faa1398",
            "value": " 18612/18612 [00:01&lt;00:00, 18453.93 examples/s]"
          }
        },
        "0812a958752b4de4a71dd7dba1ebc792": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c39fb16d834994af100894810f6c5b",
            "placeholder": "​",
            "style": "IPY_MODEL_40aafe6738cb4e079123559b5a4932eb",
            "value": " 41/41 [00:00&lt;00:00, 3599.36it/s]"
          }
        },
        "139dc730d2ad41eab5b5ab17d96905d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fae9b800e88143d49460d1ca498c8973",
            "placeholder": "​",
            "style": "IPY_MODEL_c59f5cc549eb4eac86617a0e448fa3f3",
            "value": "Map (num_proc=10): 100%"
          }
        },
        "1b21dedae2734ab7adc5bb3d3e7f6536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297b789b68f348f083cfaf498a605aa0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e1cb388a20549268f3aa71012a1269c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "329c6b46c8c04a699ba158ba3d4d0fed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a60b66c4d0e43f3b26c802bc1309441": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91f17e47477d4a65a12a81550a05b9dd",
            "placeholder": "​",
            "style": "IPY_MODEL_831c1f17dfac47ec9dfb96cda4911daf",
            "value": " 299/299 [00:00&lt;00:00, 696.96 examples/s]"
          }
        },
        "3a7136ac75864871977dd034ff3dac61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407afe40d7d143cd8165167aafb229a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91ffb8b7c9894feca396d6b8d6ff0e9b",
              "IPY_MODEL_7f3dd6294b7c46a78134730727781956",
              "IPY_MODEL_0812a958752b4de4a71dd7dba1ebc792"
            ],
            "layout": "IPY_MODEL_b0784141d3454c3b9b82af693d8ba899"
          }
        },
        "40aafe6738cb4e079123559b5a4932eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4544c1d6343c42c5ad2b3761e0efd929": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b71c6b371a4d7183b6e4953af28488",
            "placeholder": "​",
            "style": "IPY_MODEL_1b21dedae2734ab7adc5bb3d3e7f6536",
            "value": " 32/32 [00:01&lt;00:00, 30.69it/s]"
          }
        },
        "4a75b3f631fc432fbe8763157c032eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5526a859cee0475d904f8bba8864cf9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12353abc7a24f7db19908b0229cc426",
            "placeholder": "​",
            "style": "IPY_MODEL_a7ff8e34652b44c3a3b56828f9554c53",
            "value": " 10000/10000 [00:33&lt;00:00, 829.31 examples/s]"
          }
        },
        "55cdd74deb454f7f90f9739214e9742c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563bc1d0c6b04fa1a3eaba937c194da6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57901673f7fe49eaa8cdaad0475dc83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e3758ea61114fb5b098446c99bbd747",
            "max": 299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4b04465ea3b48f2bbf72c6c8db7fe92",
            "value": 299
          }
        },
        "5e442e6254504a1b9e79ed98d7047182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_951b4e5178ab496182c7db50979591be",
              "IPY_MODEL_dbc3481db4e44e8f80580d5fb286a3f7",
              "IPY_MODEL_0693740e40a24488a3ca0234371532ac"
            ],
            "layout": "IPY_MODEL_2e1cb388a20549268f3aa71012a1269c"
          }
        },
        "600153686cde476cabadd0114faa1398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65d634518c064f12acb341dc60945d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6976ccfee67d492399e41a575523a9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17bde7e01ed4fc7ac08010cbe5184ba",
              "IPY_MODEL_a32bf713d37b40488a97110387de2d29",
              "IPY_MODEL_4544c1d6343c42c5ad2b3761e0efd929"
            ],
            "layout": "IPY_MODEL_cd7f1897215c48b88e2fa0d83f575d2e"
          }
        },
        "7860088b47614c059ebcc628dcaec684": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f3dd6294b7c46a78134730727781956": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563bc1d0c6b04fa1a3eaba937c194da6",
            "max": 41,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4ae09a102c44ddda3f8558b1c741e31",
            "value": 41
          }
        },
        "831c1f17dfac47ec9dfb96cda4911daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c2fd0f69e6543f78de14dd73d710afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90f7325c67254feda6ca9f5af6570577": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_139dc730d2ad41eab5b5ab17d96905d1",
              "IPY_MODEL_f8feeb900cac434b8b3673b601fa3fe9",
              "IPY_MODEL_5526a859cee0475d904f8bba8864cf9d"
            ],
            "layout": "IPY_MODEL_55cdd74deb454f7f90f9739214e9742c"
          }
        },
        "91f17e47477d4a65a12a81550a05b9dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ffb8b7c9894feca396d6b8d6ff0e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a7136ac75864871977dd034ff3dac61",
            "placeholder": "​",
            "style": "IPY_MODEL_cd75ae16b65847558222e442683edc6d",
            "value": "Fetching 41 files: 100%"
          }
        },
        "951b4e5178ab496182c7db50979591be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35524b5844945e69c0e9671c55293aa",
            "placeholder": "​",
            "style": "IPY_MODEL_e7ffc23e2a52402d830a3e73eb3f1534",
            "value": "Map (num_proc=10): 100%"
          }
        },
        "9e3758ea61114fb5b098446c99bbd747": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17bde7e01ed4fc7ac08010cbe5184ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b4582ab7b64ece9851c9083b922f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_fe0acbf6ea334a27b510be7f69f5dd21",
            "value": "100%"
          }
        },
        "a32bf713d37b40488a97110387de2d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d686a3e6c6a34ef89089a81533f96b34",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5c342c18d004aa88bcac63af3f52024",
            "value": 32
          }
        },
        "a4b04465ea3b48f2bbf72c6c8db7fe92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7ff8e34652b44c3a3b56828f9554c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa3529c4cd554e25942d34bd5eec62af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0784141d3454c3b9b82af693d8ba899": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d0890bbc5d41eaa21ca28f9878f28e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f48396a6954f3d980a1b0e471299df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b59d8f3b484e467f911141af0b89e77d",
              "IPY_MODEL_57901673f7fe49eaa8cdaad0475dc83e",
              "IPY_MODEL_3a60b66c4d0e43f3b26c802bc1309441"
            ],
            "layout": "IPY_MODEL_329c6b46c8c04a699ba158ba3d4d0fed"
          }
        },
        "b59d8f3b484e467f911141af0b89e77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a75b3f631fc432fbe8763157c032eb8",
            "placeholder": "​",
            "style": "IPY_MODEL_8c2fd0f69e6543f78de14dd73d710afc",
            "value": "Map (num_proc=10): 100%"
          }
        },
        "b5c342c18d004aa88bcac63af3f52024": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8b71c6b371a4d7183b6e4953af28488": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9c39fb16d834994af100894810f6c5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c35524b5844945e69c0e9671c55293aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ae09a102c44ddda3f8558b1c741e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c59f5cc549eb4eac86617a0e448fa3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd75ae16b65847558222e442683edc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd7f1897215c48b88e2fa0d83f575d2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d686a3e6c6a34ef89089a81533f96b34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc3481db4e44e8f80580d5fb286a3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297b789b68f348f083cfaf498a605aa0",
            "max": 18612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7860088b47614c059ebcc628dcaec684",
            "value": 18612
          }
        },
        "e7ffc23e2a52402d830a3e73eb3f1534": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f12353abc7a24f7db19908b0229cc426": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b4582ab7b64ece9851c9083b922f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8feeb900cac434b8b3673b601fa3fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0d0890bbc5d41eaa21ca28f9878f28e",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65d634518c064f12acb341dc60945d1a",
            "value": 10000
          }
        },
        "fae9b800e88143d49460d1ca498c8973": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe0acbf6ea334a27b510be7f69f5dd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
