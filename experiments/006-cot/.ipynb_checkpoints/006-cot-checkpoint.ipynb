{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/workspace/huggingface'\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache, utils\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "tqdm.pandas()\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/asaparov/prontoqa.git\n",
    "cd prontoqa\n",
    "mkdir json\n",
    "unzip generated_ood_data.zip -d json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "data = load_json(\"prontoqa/json/1hop_ProofsOnly_random_noadj.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "labels = [\"is\", \"is not\"]\n",
    "\n",
    "def prepare_example(example, n_shots=3):\n",
    "    prompt = \"\"\n",
    "    \n",
    "    for i in range(n_shots):\n",
    "        change = randint(0, 1)\n",
    "        prompt += example[f\"in_context_example{i}\"]['question'] + \"\\n\"\n",
    "        query = example[f\"in_context_example{i}\"]['query']\n",
    "        \n",
    "        if \"is not\" in query:\n",
    "            label = \"True\" if change == 1 else \"False\"\n",
    "            query = query.replace(\"is not\", labels[change])\n",
    "        else:\n",
    "            label = \"True\" if change == 0 else \"False\"\n",
    "            query = query.replace(\"is\", labels[change])\n",
    "    \n",
    "        prompt += query.replace(\"Prove: \", \"True or False: \") + \" Think step-by-step.\" + \"\\n\\n\"\n",
    "    \n",
    "        for j, step in enumerate(example[f\"in_context_example{i}\"]['chain_of_thought']):\n",
    "            prompt += f\"({j+1}) {step}\\n\"\n",
    "        \n",
    "        prompt += f\"\\nAnswer: {label}\\n\\n\\n\"\n",
    "    \n",
    "    change = randint(0, 1)\n",
    "    prompt += example[\"test_example\"]['question'] + \"\\n\"\n",
    "    query = example[\"test_example\"]['query']\n",
    "    \n",
    "    if \"is not\" in query:\n",
    "        label = \"True\" if change == 1 else \"False\"\n",
    "        query = query.replace(\"is not\", labels[change])\n",
    "    else:\n",
    "        label = \"True\" if change == 0 else \"False\"\n",
    "        query = query.replace(\"is\", labels[change])\n",
    "    \n",
    "    prompt += query.replace(\"Prove: \", \"True or False: \") + \" Think step-by-step.\" + \"\\n\\n\"\n",
    "        \n",
    "    return prompt, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumpuses are numpuses. Impuses are jompuses. Each yumpus is not spicy. Every dumpus is mean. Lorpuses are snowy. Each lempus is not transparent. Numpuses are tumpuses. Numpuses are moderate. Every tumpus is luminous. Jompuses are not blue. Impuses are gorpuses. Every gorpus is not hot. Each dumpus is a yumpus. Every gorpus is a lempus. Lorpuses are sterpuses. Every impus is muffled. Every numpus is an impus. Gorpuses are rompuses. Polly is an impus. Polly is a lorpus.\n",
      "True or False: Polly is muffled. Think step-by-step.\n",
      "\n",
      "(1) Polly is an impus.\n",
      "(2) Every impus is muffled.\n",
      "(3) Polly is muffled.\n",
      "\n",
      "Answer: True\n",
      "\n",
      "\n",
      "Every lempus is a rompus. Each rompus is a jompus. Each jompus is a lorpus. Each rompus is a tumpus. Grimpuses are feisty. Jompuses are cold. Each dumpus is transparent. Each lempus is a dumpus. Rompuses are rainy. Vumpuses are gorpuses. Each tumpus is earthy. Every vumpus is sweet. Jompuses are grimpuses. Lempuses are angry. Alex is a rompus. Alex is a vumpus.\n",
      "True or False: Alex is rainy. Think step-by-step.\n",
      "\n",
      "(1) Alex is a rompus.\n",
      "(2) Rompuses are rainy.\n",
      "(3) Alex is rainy.\n",
      "\n",
      "Answer: True\n",
      "\n",
      "\n",
      "Sterpuses are tumpuses. Each sterpus is large. Vumpuses are zumpuses. Zumpuses are not spicy. Each vumpus is not slow. Each vumpus is a brimpus. Fae is a sterpus. Fae is a vumpus.\n",
      "True or False: Fae is not slow. Think step-by-step.\n",
      "\n",
      "(1) Fae is a vumpus.\n",
      "(2) Each vumpus is not slow.\n",
      "(3) Fae is not slow.\n",
      "\n",
      "Answer: True\n",
      "\n",
      "\n",
      "Gorpuses are sterpuses. Gorpuses are grimpuses. Every dumpus is a jompus. Every grimpus is a shumpus. Gorpuses are not small. Sterpuses are liquid. Every shumpus is not muffled. Dumpuses are bright. Each grimpus is a brimpus. Every grimpus is not cold. Wren is a dumpus. Wren is a grimpus.\n",
      "True or False: Wren is not cold. Think step-by-step.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts = [prepare_example(x) for x in data.values()]\n",
    "print(prompts[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f21c94ef577436a9b3db31237ed5558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('gemma-2b')\n",
    "\n",
    "model.eval()\n",
    "model.set_use_attn_result(True)\n",
    "model.set_use_attn_in(True)\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7cdf9683cae4565ad15a428f626999d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumpuses are numpuses. Impuses are jompuses. Each yumpus is not spicy. Every dumpus is mean. Lorpuses are snowy. Each lempus is not transparent. Numpuses are tumpuses. Numpuses are moderate. Every tumpus is luminous. Jompuses are not blue. Impuses are gorpuses. Every gorpus is not hot. Each dumpus is a yumpus. Every gorpus is a lempus. Lorpuses are sterpuses. Every impus is muffled. Every numpus is an impus. Gorpuses are rompuses. Polly is an impus. Polly is a lorpus.\n",
      "True or False: Polly is muffled.\n",
      "\n",
      "(1) Polly is an impus.\n",
      "(2) Every impus is muffled.\n",
      "(3) Polly is muffled.\n",
      "\n",
      "Answer: True\n",
      "\n",
      "\n",
      "Every lempus is a rompus. Each rompus is a jompus. Each jompus is a lorpus. Each rompus is a tumpus. Grimpuses are feisty. Jompuses are cold. Each dumpus is transparent. Each lempus is a dumpus. Rompuses are rainy. Vumpuses are gorpuses. Each tumpus is earthy. Every vumpus is sweet. Jompuses are grimpuses. Lempuses are angry. Alex is a rompus. Alex is a vumpus.\n",
      "True or False: Alex is not rainy.\n",
      "\n",
      "(1) Alex is a rompus.\n",
      "(2) Rompuses are rainy.\n",
      "(3) Alex is rainy.\n",
      "\n",
      "Answer: False\n",
      "\n",
      "\n",
      "Sterpuses are tumpuses. Each sterpus is large. Vumpuses are zumpuses. Zumpuses are not spicy. Each vumpus is not slow. Each vumpus is a brimpus. Fae is a sterpus. Fae is a vumpus.\n",
      "True or False: Fae is slow.\n",
      "\n",
      "(1) Fae is a vumpus.\n",
      "(2) Each vumpus is not slow.\n",
      "(3) Fae is not slow.\n",
      "\n",
      "Answer: False\n",
      "\n",
      "\n",
      "Gorpuses are sterpuses. Gorpuses are grimpuses. Every dumpus is a jompus. Every grimpus is a shumpus. Gorpuses are not small. Sterpuses are liquid. Every shumpus is not muffled. Dumpuses are bright. Each grimpus is a brimpus. Every grimpus is not cold. Wren is a dumpus. Wren is a grimpus.\n",
      "True or False: Wren is not cold.\n",
      "\n",
      "\u001b[1m(1) Wren is a dumpus.\n",
      "(2) Every grimpus is a brimpus.\n",
      "(3) Wren is not cold.\n",
      "\n",
      "Answer: True\n",
      "\n",
      "\n",
      "Impuses are jompuses. Each jompus is not spicy. Every dumpus is a jompus. Every jomp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer():\n",
    "    pattern = r'Answer:\\s*(.*)'\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        answer = match.group(1)\n",
    "    else:\n",
    "        answer = \"NaN\"\n",
    "\n",
    "    return answer\n",
    "\n",
    "for i in range(100):\n",
    "    prompt, label = prompts[i]\n",
    "    out = model.generate(prompt, 64, temperature=0)\n",
    "    \n",
    "    \n",
    "print(prompt[0], sep='', end='')\n",
    "print('\\033[1m' + out[len(prompt):] + '\\033[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats-interp",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
