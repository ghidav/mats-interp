{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('gpt2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', '{', '\\n', ' ', ' ', ' ', ' \"', 'question', '\":', ' \"', 'What', \"'s\", ' the', ' capital', ' of', ' France', '?\",', '\\n', ' ', ' ', ' ', ' \"', 'answer', '\":', ' Paris']\n",
      "Tokenized answer: [' }']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">       Logit:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.61</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.44</span><span style=\"font-weight: bold\">% Token: | }|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m15\u001b[0m\u001b[1m       Logit:  \u001b[0m\u001b[1;36m9.61\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m0.44\u001b[0m\u001b[1m% Token: | \u001b[0m\u001b[1m}\u001b[0m\u001b[1m|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 13.92 Prob: 33.17% Token: |,|\n",
      "Top 1th token. Logit: 12.81 Prob: 10.95% Token: |ian|\n",
      "Top 2th token. Logit: 12.18 Prob:  5.85% Token: |.|\n",
      "Top 3th token. Logit: 11.87 Prob:  4.29% Token: |\n",
      "|\n",
      "Top 4th token. Logit: 11.72 Prob:  3.68% Token: | (|\n",
      "Top 5th token. Logit: 11.07 Prob:  1.91% Token: | ,|\n",
      "Top 6th token. Logit: 11.00 Prob:  1.79% Token: |ians|\n",
      "Top 7th token. Logit: 10.71 Prob:  1.33% Token: | \"|\n",
      "Top 8th token. Logit: 10.29 Prob:  0.88% Token: |-|\n",
      "Top 9th token. Logit: 10.15 Prob:  0.77% Token: | {|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' }'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' \u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformer_lens.utils import test_prompt\n",
    "\n",
    "test_prompt(\"\"\"{\n",
    "    \"question\": \"What's the capital of France?\",\n",
    "    \"answer\": Paris\"\"\", \"}\", model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7fbbff6cdf4068827e0f8941b93e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 41 files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "REPO_ID = \"jbloom/GPT2-Small-SAEs-Reformatted\"\n",
    "path = snapshot_download(repo_id=REPO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "  8%|▊         | 1/12 [00:08<01:29,  8.09s/it]/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/ghilardi/miniconda3/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      " 17%|█▋        | 2/12 [00:15<01:14,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:22<01:07,  7.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:30<01:01,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:37<00:52,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:45<00:46,  7.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:53<00:38,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 8/12 [01:00<00:29,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [01:08<00:22,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [01:15<00:14,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [01:23<00:07,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:31<00:00,  7.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from sae_lens import LMSparseAutoencoderSessionloader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "saes = []\n",
    "\n",
    "for l in tqdm(range(model.cfg.n_layers)):\n",
    "    model, sae_group, activation_store = LMSparseAutoencoderSessionloader.load_pretrained_sae(\n",
    "        path = os.path.join(path, f\"blocks.{l}.hook_resid_pre\"), device=device\n",
    "    )\n",
    "    sae_group.eval()\n",
    "    saes.append(sae_group[f'blocks.{l}.hook_resid_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_text = \"\"\"{\n",
    "    \"question\": \"What's the capital of France?\",\n",
    "    \"answer\": Paris\n",
    "    }\"\"\"\n",
    "\n",
    "non_json_text = [\n",
    "    \"\"\"What's the capital of France?\n",
    "Paris\"\"\",\n",
    "    \"\"\"These are the things I love:\n",
    "1. Food,\n",
    "2. Sea,\n",
    "3. Friends\"\"\",\n",
    "    \"\"\"An old man once told me: \"You will succeed in life\".\n",
    "I hope him to be true.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {l: [] for l in range(model.cfg.n_layers)}\n",
    "\n",
    "with open(\"json_features.txt\", \"r\") as f:\n",
    "    features = f.readlines()\n",
    "\n",
    "for f in features:\n",
    "    f = f.strip().split('-')\n",
    "    layer = int(f[0])\n",
    "    features_dict[layer].append(f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_act_dict = {\n",
    "    'L': [],\n",
    "    'N': [],\n",
    "    'JSON Activation': [],\n",
    "    'Non-JSON Activation': []\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, json_cache = model.run_with_cache(model.to_tokens(json_text))\n",
    "    _, non_json_cache = model.run_with_cache(model.to_tokens(non_json_text[2]))\n",
    "\n",
    "for l in range(model.cfg.n_layers):\n",
    "    json_activations = json_cache[f'blocks.{l}.hook_resid_pre'] # [1 p dm]\n",
    "    non_json_activations = non_json_cache[f'blocks.{l}.hook_resid_pre'] # [1 p dm]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, json_features_act, *_ = saes[l](json_activations)\n",
    "        _, non_json_features_act, *_ = saes[l](non_json_activations)\n",
    "\n",
    "    for f in features_dict[l]:\n",
    "        f = int(f)\n",
    "        features_act_dict['L'].append(l)\n",
    "        features_act_dict['N'].append(f)\n",
    "        val, ix = json_features_act[0, :, f].max(0)\n",
    "        features_act_dict['JSON Activation'].append([val.item(), ix.item()])\n",
    "        val, ix = non_json_features_act[0, :, f].max(0)\n",
    "        features_act_dict['Non-JSON Activation'].append([val.item(), ix.item()])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>N</th>\n",
       "      <th>JSON Activation</th>\n",
       "      <th>Non-JSON Activation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23622</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5310</td>\n",
       "      <td>[20.185184478759766, 8]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10521</td>\n",
       "      <td>[25.650108337402344, 8]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21672</td>\n",
       "      <td>[3.7655177116394043, 9]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8148</td>\n",
       "      <td>[1.687551736831665, 18]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5682</td>\n",
       "      <td>[24.25801658630371, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3596</td>\n",
       "      <td>[21.313154220581055, 2]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>13428</td>\n",
       "      <td>[0.9894517660140991, 8]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>2164</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>20690</td>\n",
       "      <td>[25.253623962402344, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>8693</td>\n",
       "      <td>[2.6024036407470703, 6]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>2568</td>\n",
       "      <td>[31.663217544555664, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>21507</td>\n",
       "      <td>[0.7290031313896179, 6]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>19802</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>[32.37556457519531, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>5486</td>\n",
       "      <td>[7.141540050506592, 16]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>10955</td>\n",
       "      <td>[37.13043975830078, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>20084</td>\n",
       "      <td>[10.953446388244629, 21]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>13988</td>\n",
       "      <td>[41.046669006347656, 23]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>17223</td>\n",
       "      <td>[19.30836296081543, 6]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>5989</td>\n",
       "      <td>[57.765098571777344, 1]</td>\n",
       "      <td>[0.0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     L      N           JSON Activation Non-JSON Activation\n",
       "0    0  23622                  [0.0, 0]            [0.0, 0]\n",
       "1    1   5310   [20.185184478759766, 8]            [0.0, 0]\n",
       "2    2  10521   [25.650108337402344, 8]            [0.0, 0]\n",
       "3    4  21672   [3.7655177116394043, 9]            [0.0, 0]\n",
       "4    4   8148   [1.687551736831665, 18]            [0.0, 0]\n",
       "5    6   5682   [24.25801658630371, 23]            [0.0, 0]\n",
       "6    6   3596   [21.313154220581055, 2]            [0.0, 0]\n",
       "7    6  13428   [0.9894517660140991, 8]            [0.0, 0]\n",
       "8    6   2164                  [0.0, 0]            [0.0, 0]\n",
       "9    7  20690  [25.253623962402344, 23]            [0.0, 0]\n",
       "10   7   8693   [2.6024036407470703, 6]            [0.0, 0]\n",
       "11   8   2568  [31.663217544555664, 23]            [0.0, 0]\n",
       "12   8  21507   [0.7290031313896179, 6]            [0.0, 0]\n",
       "13   8  19802                  [0.0, 0]            [0.0, 0]\n",
       "14   9     80   [32.37556457519531, 23]            [0.0, 0]\n",
       "15   9   5486   [7.141540050506592, 16]            [0.0, 0]\n",
       "16  10  10955   [37.13043975830078, 23]            [0.0, 0]\n",
       "17  10  20084  [10.953446388244629, 21]            [0.0, 0]\n",
       "18  11  13988  [41.046669006347656, 23]            [0.0, 0]\n",
       "19  11  17223    [19.30836296081543, 6]            [0.0, 0]\n",
       "20  11   5989   [57.765098571777344, 1]            [0.0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(features_act_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '<|endoftext|>'),\n",
       " (1, '{'),\n",
       " (2, '\\n'),\n",
       " (3, ' '),\n",
       " (4, ' '),\n",
       " (5, ' '),\n",
       " (6, ' \"'),\n",
       " (7, 'question'),\n",
       " (8, '\":'),\n",
       " (9, ' \"'),\n",
       " (10, 'What'),\n",
       " (11, \"'s\"),\n",
       " (12, ' the'),\n",
       " (13, ' capital'),\n",
       " (14, ' of'),\n",
       " (15, ' France'),\n",
       " (16, '?\",'),\n",
       " (17, '\\n'),\n",
       " (18, ' '),\n",
       " (19, ' '),\n",
       " (20, ' '),\n",
       " (21, ' \"'),\n",
       " (22, 'answer'),\n",
       " (23, '\":'),\n",
       " (24, ' Paris'),\n",
       " (25, '\\n'),\n",
       " (26, ' '),\n",
       " (27, ' '),\n",
       " (28, ' '),\n",
       " (29, ' }')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(model.to_str_tokens(json_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
